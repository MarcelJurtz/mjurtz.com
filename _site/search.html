<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Marcel Jurtz</title>
  <meta name="description" content="A software developers blog.
">
  
  <meta name="author" content="Marcel Jurtz">
  <meta name="copyright" content="&copy; Marcel Jurtz 2018">
  

  <!-- External libraries -->
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/monokai-sublime.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/css/lightbox.css">

  <!-- Favicon and other icons (made with http://www.favicon-generator.org/) -->
  <link rel="shortcut icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
  <link rel="manifest" href="/assets/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  

  

  

  <!-- Site styles -->
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://blog.mjurtz.com/search.html">
  <link rel="alternate" type="application/rss+xml" title="Marcel Jurtz" href="http://blog.mjurtz.com/feed.xml" />
</head>


  <body>

    <header class="navigation" role="banner">
  <div class="navigation-wrapper">
    <!--
    <a href="/" class="logo">
      
      <span>Marcel Jurtz</span>
      
    </a>
  -->
    <a href="javascript:void(0)" class="navigation-menu-button" id="js-mobile-menu">
      <i class="fa fa-bars"></i>
    </a>
    <nav role="navigation">
      <!--
      <ul id="js-navigation-menu" class="navigation-menu show">
        
          
          <li class="nav-link"><a href="/about/">About</a>
          
        
          
        
          
        
          
        
          
          <li class="nav-link"><a href="/posts/">Posts</a>
          
        
          
        
          
          <li class="nav-link"><a href="/typography/">Typography</a>
          
        
          
          <li class="nav-link"><a href="/tag/gamedev/">gamedev</a>
          
        
          
          <li class="nav-link"><a href="/tag/unity/">unity</a>
          
        
          
          <li class="nav-link"><a href="/tag/git/">git</a>
          
        
          
          <li class="nav-link"><a href="/tag/programming/">programming</a>
          
        
          
          <li class="nav-link"><a href="/tag/tools/">tools</a>
          
        
          
          <li class="nav-link"><a href="/tag/android/">android</a>
          
        
          
          <li class="nav-link"><a href="/tag/app/">app</a>
          
        
          
          <li class="nav-link"><a href="/tag/baseball/">baseball</a>
          
        
          
          <li class="nav-link"><a href="/tag/development/">development</a>
          
        
          
          <li class="nav-link"><a href="/tag/editor/">editor</a>
          
        
          
          <li class="nav-link"><a href="/tag/bitcache/">bitcache</a>
          
        
          
          <li class="nav-link"><a href="/tag/bitcoin/">bitcoin</a>
          
        
          
          <li class="nav-link"><a href="/tag/cryptocurrency/">cryptocurrency</a>
          
        
          
          <li class="nav-link"><a href="/tag/dotnet/">dotnet</a>
          
        
          
          <li class="nav-link"><a href="/tag/asp-dotnet/">asp-dotnet</a>
          
        
          
          <li class="nav-link"><a href="/tag/csharp/">csharp</a>
          
        
          
          <li class="nav-link"><a href="/tag/rest/">rest</a>
          
        
          
          <li class="nav-link"><a href="/tag/servicestack/">servicestack</a>
          
        
          
          <li class="nav-link"><a href="/tag/software/">software</a>
          
        
          
          <li class="nav-link"><a href="/tag/windows/">windows</a>
          
        
          
          <li class="nav-link"><a href="/tag/efficiency/">efficiency</a>
          
        
          
          <li class="nav-link"><a href="/tag/productivity/">productivity</a>
          
        
          
          <li class="nav-link"><a href="/tag/network/">network</a>
          
        
          
          <li class="nav-link"><a href="/tag/p2p/">p2p</a>
          
        
          
          <li class="nav-link"><a href="/tag/syncthing/">syncthing</a>
          
        
          
          <li class="nav-link"><a href="/tag/xamarin/">xamarin</a>
          
        
          
          <li class="nav-link"><a href="/tag/clean-code/">clean-code</a>
          
        
          
          <li class="nav-link"><a href="/tag/design/">design</a>
          
        
          
          <li class="nav-link"><a href="/tag/layout/">layout</a>
          
        
          
          <li class="nav-link"><a href="/tag/sideproject/">sideproject</a>
          
        
          
          <li class="nav-link"><a href="/tag/dotnet-core/">dotnet-core</a>
          
        
          
          <li class="nav-link"><a href="/tag/linux/">linux</a>
          
        
          
          <li class="nav-link"><a href="/tag/3d-printing/">3d-printing</a>
          
        
          
          <li class="nav-link"><a href="/tag/raspberry-pi/">raspberry-pi</a>
          
        
          
          <li class="nav-link"><a href="/tag/email/">email</a>
          
        
          
          <li class="nav-link"><a href="/tag/encryption/">encryption</a>
          
        
          
          <li class="nav-link"><a href="/tag/self/">self</a>
          
        
          
          <li class="nav-link"><a href="/tag/blog/">blog</a>
          
        
          
          <li class="nav-link"><a href="/tag/web/">web</a>
          
        
          
          <li class="nav-link"><a href="/tag/ruby/">ruby</a>
          
        
          
          <li class="nav-link"><a href="/tag/javascript/">javascript</a>
          
        
          
          <li class="nav-link"><a href="/tag/jekyll/">jekyll</a>
          
        
          
          <li class="nav-link"><a href="/tag/motivation/">motivation</a>
          
        
          
          <li class="nav-link"><a href="/tag/discipline/">discipline</a>
          
        
          
          <li class="nav-link"><a href="/tag/fitness/">fitness</a>
          
        
          
          <li class="nav-link"><a href="/tag/asp-net/">asp.net</a>
          
        
          
          <li class="nav-link"><a href="/tag/css/">css</a>
          
        
          
          <li class="nav-link"><a href="/tag/html/">html</a>
          
        
          
          <li class="nav-link"><a href="/tag/tfs/">tfs</a>
          
        
          
          <li class="nav-link"><a href="/tag/svn/">svn</a>
          
        
          
          <li class="nav-link"><a href="/tag/docker/">docker</a>
          
        
          
          <li class="nav-link"><a href="/tag/containers/">containers</a>
          
        
          
          <li class="nav-link"><a href="/tag/book/">book</a>
          
        
          
          <li class="nav-link"><a href="/tag/review/">review</a>
          
        
          
          <li class="nav-link"><a href="/tag/ferriss/">ferriss</a>
          
        
          
          <li class="nav-link"><a href="/tag/life/">life</a>
          
        
          
          <li class="nav-link"><a href="/tag/business/">business</a>
          
        
          
          <li class="nav-link"><a href="/tag/methodology/">methodology</a>
          
        
          
          <li class="nav-link"><a href="/tag/scrum/">scrum</a>
          
        
          
          <li class="nav-link"><a href="/tag/management/">management</a>
          
        
          
          <li class="nav-link"><a href="/tag/agile/">agile</a>
          
        
          
          <li class="nav-link"><a href="/tag/project/">project</a>
          
        
          
          <li class="nav-link"><a href="/tag/kanban/">kanban</a>
          
        
          
          <li class="nav-link"><a href="/tag/pattern/">pattern</a>
          
        
          
          <li class="nav-link"><a href="/tag/ioc/">IoC</a>
          
        
          
          <li class="nav-link"><a href="/tag/di/">DI</a>
          
        
          
          <li class="nav-link"><a href="/tag/csharp/">CSharp</a>
          
        
          
          <li class="nav-link"><a href="/tag/learn/">learn</a>
          
        
          
          <li class="nav-link"><a href="/tag/prototyping/">prototyping</a>
          
        
          
          <li class="nav-link"><a href="/tag/typescript/">typescript</a>
          
        
          
          <li class="nav-link"><a href="/tag/cross-platform/">cross-platform</a>
          
        
          
          <li class="nav-link"><a href="/tag/self-disciplin/">self-disciplin</a>
          
        
          
          <li class="nav-link"><a href="/tag/sports/">sports</a>
          
        
          
          <li class="nav-link"><a href="/tag/running/">running</a>
          
        
          
          <li class="nav-link"><a href="/tag/challenge/">challenge</a>
          
        
          
          <li class="nav-link"><a href="/category/game-development/">game-development</a>
          
        
          
          <li class="nav-link"><a href="/category/tools/">tools</a>
          
        
          
          <li class="nav-link"><a href="/category/android/">android</a>
          
        
          
          <li class="nav-link"><a href="/category/cryptocurrency/">cryptocurrency</a>
          
        
          
          <li class="nav-link"><a href="/category/csharp/">CSharp</a>
          
        
          
          <li class="nav-link"><a href="/category/csharp/">csharp</a>
          
        
          
          <li class="nav-link"><a href="/category/productivity/">productivity</a>
          
        
          
          <li class="nav-link"><a href="/category/tips/">tips</a>
          
        
          
          <li class="nav-link"><a href="/category/xamarin/">xamarin</a>
          
        
          
          <li class="nav-link"><a href="/category/hobby/">hobby</a>
          
        
          
          <li class="nav-link"><a href="/category/security/">security</a>
          
        
          
          <li class="nav-link"><a href="/category/linux/">linux</a>
          
        
          
          <li class="nav-link"><a href="/category/blog/">blog</a>
          
        
          
          <li class="nav-link"><a href="/category/windows/">windows</a>
          
        
          
          <li class="nav-link"><a href="/category/life/">life</a>
          
        
          
          <li class="nav-link"><a href="/category/web/">web</a>
          
        
          
          <li class="nav-link"><a href="/category/programming/">programming</a>
          
        
          
          <li class="nav-link"><a href="/category/development/">development</a>
          
        
          
          <li class="nav-link"><a href="/category/books/">books</a>
          
        
          
          <li class="nav-link"><a href="/category/learn/">learn</a>
          
        
          
          <li class="nav-link"><a href="/category/running/">running</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      </ul>
    -->
      <ul id="js-navigation-menu" class="navigation-menu-show">
        <li class="nav-link"><a href="/">Home</a></li>
        <li class="nav-link"><a href="/about/">About</a></li>
        <li class="nav-link"><a href="/posts/">Posts</a></li>
        <li class="nav-link"><a href="/feed.xml">RSS</a></li>
      </ul>
    </nav>
  </div>
</header>


    <div class="page-content">
        <div class="home">

<div class="site-header-container has-cover" style="background-image: url(/assets/header_image.jpg);">
  <div class="scrim has-cover">
    <header class="site-header">
      <h1 class="title">Marcel Jurtz</h1>
      <p class="subtitle">A software developers blog</p>
    </header>
  </div>
</div>

<div class="wrapper">    

<form action="/search.html" method="get">
  <label for="search-box">Search</label>
  <input type="text" id="search-box" name="query">
  <input type="submit" value="search">
</form>

<ul style="list-style: none" id="search-results"></ul>

</div>

<script>
  window.store = {
    
      "2018-09-getting-started-with-running": {
        "title": "Getting Started With Running",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "If you had told me a year ago that I would run an entire Tough Mudder in a year, I probably would have made fun of you. Well, to be honest, I didn’t even know about the existence of obstacle course races (OCR) of this kind at the time. If that were the case, I would certainly have been able to motivate myself quickly.Briefly to my prehistory: I am in my early 20s and have tried various sports since my childhood. Athletics, rowing, climbing, mountain biking, snowboarding, baseball, squash - again and again I tried different things that seemed interesting. Some of them I still do today, but in October 2017 I decided to take up a new challenge.During my school time I had to face - like all my friends - long distance races. However, long distance is actually already exaggerated. We could choose between a 12-minute and a 30-minute variant, the distance reached was graded. I always liked sports, but I hated endurance running. And until the end of last year, nothing changed in this regard.Last year I was then looking for a challenge. So what could be more obvious than to face the enemy of my youth? I came across a video of the NYC marathon on YouTube and decided for myself: I want to run this race for once. And the goal was set. Thanks Casey.In my article today I show you my way last year, how I pursue my goal and what has happened since then. And who knows, maybe the article will help you with your goals.The First Two Months - C25KI repeatedly tried to enjoy running. And yes, I always failed miserably. My problems were consistency on the one hand, but on the other hand the lack of an overall goal.So I started by looking for introductions and guides on how best to start. At some point I came across the C25K training plan. The idea behind it is to build stamina over an eight-week program, which is intended for absolute beginners. The goal of the program after 8 weeks is to run a distance of 5 kilometers in 30 minutes completely (without walking). The individual runs alternate between walking and running intervals, whereby the running intervals are constantly increased.With this concept I have completed the two months and finished the program in December 2017. At this point I would also like to thank the C25K Subreddit. The community is very supportive and enthusiastic. If you lack motivation or have any other problem - they build up and motivate each other.There is a follow-up plan that continues the concept and has a target distance of 10 kilometers in 60 minutes. I started this plan, but I stopped it quite early. I noticed that my second big problem - the lack of consistency - solved itself and I decided to continue running without any help.After the two months I was at a point where running was fun for me. So I didn’t have to torture myself out of the house anymore, but looked forward to the training sessions. The first milestone was thus reached.My first 10K &amp; Discovering OCRJanuary and February 2018 didn’t go as planned, to be honest. Due to a quite intense cold I had to take a longer break and had a hard time getting back into my routine. However, I had already told my uncle, who also runs, about my goal, who now wanted to run with me. In order to put pressure on myself, I registered for my first 10 KM run in the neighbouring town at the beginning of March. And I quickly regretted the registration.But giving up is not an option, so I started training again. There was enough time until the run in May, but I rarely managed to really train longer than 5 KM. When the run was just around the corner, my personal record was a distance of 8 KM at a time and I really thought that the registration was a terrible idea. But with the large group of runners I was able to get myself to run through the two laps of 5 KM each without a break and finish my first competition with a time of 56:22.By chance I came across the obstacle courses at some point and saw that there was one in the surrounding area. I decided to sign up for it and have been highly motivated ever since. The additional challenge felt just right and the short distance of 8 KM seemed quite feasible. In July 2018 the time had come and I finished the Mudiator in Ulm together with my cousin with a time of 1:01:41.The run itself was great, but I was a little disappointed by the obstacles. For me these were simply not really challenging. But it was fun anyway and we started looking for more runs.In the meantime I was able to convince a former fellow student to try the C25K program (check out his blogpost here!). He started with the same attitude to running as I did and I needed some persuasion to get him to start. At this point a lot changed again. I have decided to run together with him. Although I had already completed the program, I found running together helpful for both of us.And the difference was immense: Until then (apart from the competitions) I always ran alone. But now I had a training partner and had to really keep to the training sessions. Excuses not to run on an agreed day were unacceptable. We got each other to keep on running and running longer and further than the training plan provided. It was certainly helpful here to have a goal in mind: At the beginning of the program we signed up for the Tough Mudder Half - from now on my buddy had two months to prepare for the 8 km course.The 8 weeks flew by and one week before the race the track was published. We originally assumed that the Tough Mudder Full (16 KM) would simply consist of two laps. But now we saw that many of the obstacles we were looking forward to wouldn’t be on the short track at all.This is especially the case for Funky Monkey and Arctic Enema. I spontaneously suggested to update our tickets to the full distance. However, the idea was rejected, as 16 kilometres seemed to be far too long.On the day of the race we then threw all rationally made decisions regarding the track overboard and decided on the full distance. At this point, for those of you who don’t know the Tough Mudder, I’d like to briefly mention that the event is not a classic race. There is no time keeping and the focus is on teamwork and the collective mastering of the course. Accordingly, it was no problem to wait at some obstacles for a short time, because time doesn’t really play a role. Due to the resulting breaks, the 16 KM were really doable. And in retrospect I would have been really disappointed if we had only run the short distance.Beside the Tough Mudder there is meanwhile a large selection of similar events, and the run was certainly not our last. My next milestone is a half marathon in December and hopefully a complete one in May 2019.Conclusion  If you plan to go running after school or work, put your clothes aside in the morning and start running as soon as you get home. Don’t give yourself a break when you get home, that makes it a lot harder to get your ass up again.  Go running after work and you will have new energy for the rest of the day. Search for routes in nature and enjoy the time to clear your head.  Find yourself a running partner. It certainly makes sense to start alone to find your own pace. Nevertheless, it is so much easier to motivate yourself to run when you know that others rely on you.  Screw your pace. Try to run as long as possible and increase this distance. Your speed will improve all by itself.  If running seems too boring to you, look around for obstacle course races in your area.All beginnings are difficult. If you decide to train with the C25K program, be prepared to have some self-discipline for the first two weeks. Nevertheless, it was the case with me afterwards that you integrated it into your daily routine in such a way that you want to continue on your own.",
        "url": "/2018/09/getting-started-with-running"
      }
      ,
    
      "2018-09-dotnet-garbage-collection": {
        "title": "Garbage Collection in .NET",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Today I would like to give you an overview of how the garbage collector of the .NET framework works. Knowledge of it makes a lot of sense to improve your programming skills regarding object creation and lifetime.Garbage Collection in GeneralI want to start with some general theory - what is garbage collection and what do I need it for? Garbage collection (GC) is basically a feature that relieves developers of the work of allocating and deallocating memory for their objects.In low-level programming languages, you as the developer have to take care of this allocation and deallocation. If you want the computer to remember an object, you allocate memory for that object. When the object is no longer needed, you have to free up the memory.Although this concept leads to very efficient programs, it is also error-prone. For example, if your program doesn’t free memory, but asks for more and more, this can lead to a memory leak, which in turn can lead to the consumption of your computer’s entire memory. Alternatively, the program simply no longer responds to user interaction. Another source of errors are bugs that cause your program to attempt to access a memory section that has not yet been allocated. In this case, the operating system will terminate your program immediately.There are more fragile issues, but they are too many to list. The concept of higher-level programming languages in this respect is identical: when you need an object, you request an instance of the respective class. This instance is then used in your program, and as long as there is a reference to the instance, memory is reserved for it. As soon as nothing in your code refers to the instance anymore, the corresponding memory will be freed again.Basically, you can memorize that programming languages with GC are usually less efficient than those without. This is due to the fact that the cleanup process is usually performed at regular intervals. For this reason, there is a potential for wasted memory between operations. For data-intensive applications, there is also the possibility that many (de)allocations may occur, which is why the program looks as if it is not responding.Garbage Collection in .NETIn general, garbage collection in .NET works as described above. However, I’d like to cover the topic in a bit more detail.Memory Allocation in .NETIn the .NET framework, each process has a virtual address space. As an application developer, you never access physical memory, but always an abstraction level of it. The garbage collector takes care of the allocation and deallocation of virtual memory on the managed heap.Blocks of the virtual memory are always in one of three states:  Free: There are no references to this block, it is ready for referencing.  Reserved: The memory block is free, but reserved for a request and cannot be used by other applications. Until the memory area is assured, no data can be stored.  Assured: The memory block is directly assigned to a physical memory.Gaps can occur in virtual memory. When memory is requested, a suitable space is searched in which the memory is completely available. For example, if you need 100 MB of memory in the working memory, the search will continue until a single free block of at least 100 MB memory is found. Smaller blocks will be skipped.You may be familiar with the principle of swap files, especially when you are at home in the Linux world. If available memory becomes too small, it can be swapped out to disk, so called swap files are created. .NET uses this concept, but can also swap out under certain conditions, even if the memory is not full.Triggering the Garbage CollectionThere are several different ways in which exactly the garbage collection can be triggered. Firstly, of course, if the system has little physical memory. This is usually recognized by a message from the operating system. Another possibility is to exceed a limit value of the memory used by objects in the heap. This limit depends on the program and is adjusted at runtime.A third method is to manually call the GC.Collect() method. However, you will hardly need this case (except perhaps for testing the functionality of the garbage collector).Managed HeapI have already mentioned the managed heap several times, but have not explained it further. The Managed Heap describes a memory area of the physical memory, which was reserved by the garbage collector after its instantiation by the CLR for the administration of objects. The operating system manages a system heap in parallel.The reservation and release of memory segments is done by the Win32 methods VirtualAlloc() and VirtualFree().The more objects there are on the heap, the more complex is the garbage collection process. When releasing memory, active objects are pushed together. This reduces the required memory space, but the objects retain their locality (jointly instantiated objects lie next to each other).The size of the memory usage also determines the frequency and size of the individual GC operations.GenerationsThe heap is built in generations to describe the lifetime of objects. Garbage collection usually takes the form of releasing short-lived objects that occupy only a small part of the working memory. A distinction is made between three generations:Generation 0 is the most recent generation. It contains short-lived objects such as local variables.Generation 1 also contains short-lived objects, but serves as a buffer between short-lived and long-lived objects.Generation 2 finally contains the long-lived objects. These are, for example, objects with static data that are retained throughout the entire application runtime.A garbage collection always takes place for a particular generation, if the appropriate conditions are met. The collection within a generation always contains the younger generations. A collection in generation 2 is therefore also referred to as a complete collection because it cleanses all objects in the managed heap.Objects that still exist after a garbage collection are moved up the generation hierarchy. If the garbage collector recognizes that this number is very high in a generation, the threshold value for memory allocations for this generation is increased. It is always weighed between two priorities: The size of the memory used by an application and the amount of garbage collection required.GC more often takes place in younger generations. If more working memory is required, the older generations (including those below them) are cleaned.Garbage collection procedureAt the start of a GC, a list of active objects is created. The objects to be compressed (active objects moved together) are then reassigned. Storage space for inactive objects is released. Objects are now promoted in their generation.GC in practiceYou have probably already worked with unmanaged resources. In this case, the IDisposable interface can be used to share manually used memory of unmanaged resources. This is usually seen in the form of file access. The construction of a corresponding code snippet is usually based on the construction of a using block. After finishing the code of this block, the Dispose() method is called, which releases the resources again. IDisposable in itself has nothing directly to do with Garbage Collection. However, manual release is required when objects access unmanaged resources, as in the following example: If managed objects refer to unmanaged objects, these must first be released manually so that the managed objects can be cleaned up.The following example creates and releases a StreamReader instance: using (StreamReader s = new StreamReader(\"file1.txt\"))) {     // … } The using block does not have to be used, alternatively Dispose() can be called within a finally block. Dispose itself does not belong to the garbage collection, so it is not called in a collection! This construct can be used for any class that implements IDisposable.You should also not rely on the garbage collector. It’s good style to close database connections or the like by yourself, instead of leaving this task to the GC.Also, you should have little reason to initiate the GC yourself. Exceptions occur when you have reason to believe that there is a large number of objects in generations 1 and 2 that are ready to be cleaned up. This may be the case, for example, if you have just closed a large form whose controls are all no longer needed.ConclusionI hope that this article has given you a rough insight into how the Garbage Collection works in C#. But the topic itself gives enough theory for a whole book, so I recommend to the inclined reader to read more detailed articles. Microsoft’s own documentation on the subject is certainly a good starting point, have fun with it!",
        "url": "/2018/09/dotnet-garbage-collection"
      }
      ,
    
      "2018-09-xamarin-forms-dialogs": {
        "title": "Dialogs in Xamarin.Forms",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "If you already have a little experience in cross-platform development with Xamarin.Forms, you probably know the problem: Navigation between different pages works very well, but there is no easy solution to display dialog boxes overlaying an active page.Today I want to show you how you can implement this feature in your Xamarin.Forms application. I have created an example project for this purpose, which you can download from my GitHub site.SetupI first create a new Cross-Platform project in Visual Studio. I start without a template (blank) and use .NET standard for the shared code base. After the project is initialized, I add the plugin for the dialogs to all projects. You can find it via Nuget. The project is also open source on GitHub. To add a Nuget package to your projects, mark the project (or solution) and select the entry Manage NuGet Packages. Select all projects of your solution to install the package.The first thing to do is to initialize the package. This takes place in the platform-specific projects. For Android, open the MainActivity.cs file and add the following to your OnCreate() method:protected override void OnCreate(Bundle bundle){    base.OnCreate(bundle);    Rg.Plugins.Popup.Popup.Init(this, bundle);            Xamarin.Forms.Forms.Init(this, bundle);    LoadApplication (new App ());}The same goes for iOS: Add the following snippet to your FinishedLaunching()-Method inside the AppDelegate.cs file.public override bool FinishedLaunching(UIApplication app, NSDictionary options){    Rg.Plugins.Popup.Popup.Init();          global::Xamarin.Forms.Forms.Init ();    LoadApplication (new App ());    return base.FinishedLaunching (app, options);}If you want to support UWP, the relevant code goes inside the App-class:Rg.Plugins.Popup.Popup.Init();Xamarin.Forms.Forms.Init (e);if (e.PreviousExecutionState == ApplicationExecutionState.Terminated){  // ...}More detailed information about initializing the plugin can be found in the projects documentation.Integrating DialogsNow add a new Content Page to the .NET standard project. This is generated with predefined code, which must be adjusted as follows:&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;pages.PopUpPage xmlns=\"http://xamarin.com/schemas/2014/forms\"              xmlns:x=\"http://schemas.microsoft.com/winfx/2009/xaml\"             xmlns:pages=\"clr-namespace:Rg.Plugins.Popup.Pages;assembly=Rg.Plugins.Popup\"             x:Class=\"PopupDemo.Dialog\"&gt;    &lt;/pages.PopUpPage&gt;This is the foundation of the dialog. I just removed the sample content and added the namespace for the plugin. Finally I changed the root element of the page from ContentView to PopUpPage. These changes are also required in the code-behind file. All you have to do here is change the inheritance from ContentView to PopUpPage.Next, I design the content of the dialog window. I want to show the user a simple login dialog, so I need input fields for username and password, as well as a button to confirm the input.&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;pages:PopupPage xmlns=\"http://xamarin.com/schemas/2014/forms\"              xmlns:x=\"http://schemas.microsoft.com/winfx/2009/xaml\"             xmlns:pages=\"clr-namespace:Rg.Plugins.Popup.Pages;assembly=Rg.Plugins.Popup\"             xmlns:animations=\"clr-namespace:Rg.Plugins.Popup.Animations;assembly=Rg.Plugins.Popup\"             x:Class=\"PopupDemo.Dialog\"&gt;    &lt;pages:PopupPage.Animation&gt;        &lt;animations:ScaleAnimation DurationIn=\"200\"                                   DurationOut=\"300\"                                   EasingIn=\"SinIn\"                                   EasingOut=\"SinInOut\"                                   HasBackgroundAnimation=\"True\"                                   PositionIn=\"Top\"                                   PositionOut=\"Bottom\"                                   ScaleIn=\"1.2\"                                   ScaleOut=\"0.8\"/&gt;    &lt;/pages:PopupPage.Animation&gt;        &lt;StackLayout        Margin=\"12\"        Padding=\"24\"        Spacing=\"24\"        BackgroundColor=\"White\"        HorizontalOptions=\"Center\"        VerticalOptions=\"Center\"&gt;        &lt;StackLayout&gt;            &lt;Label                Text=\"Username\"/&gt;            &lt;Entry                FontSize=\"Large\"                Text=\"me@example.com\" /&gt;        &lt;/StackLayout&gt;        &lt;StackLayout&gt;            &lt;Label                Text=\"Password\"/&gt;            &lt;Entry                FontSize=\"Large\"                IsPassword=\"True\"                Text=\"1234\" /&gt;        &lt;/StackLayout&gt;        &lt;StackLayout&gt;            &lt;Button                Clicked=\"Button_Clicked\"                BackgroundColor=\"Orange\"                FontSize=\"Large\"                Text=\"Submit\"                TextColor=\"White\"/&gt;        &lt;/StackLayout&gt;    &lt;/StackLayout&gt;&lt;/pages:PopupPage&gt;Now there is missing only one possibility to display the dialog. I added a simple button to my main page and linked it to an event handler that opens the dialog. In real applications, you would do this by adding bindings to the ViewModel, but I decided to use the quick and dirty variant to keep the example as simple as possible.Calling the dialog probably reminds you syntactically of the normal navigation between the pages. Closing the dialog works analogously, I wired this part with the EventHandler in the code-behind file of the dialog.// Open DialogPopupNavigation.Instance.PushAsync(new Dialog());// Close DialogPopupNavigation.Instance.PopAsync();AnimationsIf you now start the application on a device or emulator of your choice, everything should already work. Besides the pure dialog functionality, the plugin offers the possibility to animate the dialogs. The animation is defined in the XAML code of the dialog. You can also find complete documentation for this on the projects website. Here it’s a good idea to just play around with the available possibilities, but finally you’ll find a small example:&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;pages:PopupPage xmlns=\"http://xamarin.com/schemas/2014/forms\"              xmlns:x=\"http://schemas.microsoft.com/winfx/2009/xaml\"             xmlns:pages=\"clr-namespace:Rg.Plugins.Popup.Pages;assembly=Rg.Plugins.Popup\"             xmlns:animations=\"clr-namespace:Rg.Plugins.Popup.Animations;assembly=Rg.Plugins.Popup\"             x:Class=\"PopupDemo.Dialog\"&gt;    &lt;pages:PopupPage.Animation&gt;        &lt;animations:ScaleAnimation DurationIn=\"200\"                                   DurationOut=\"300\"                                   EasingIn=\"SinIn\"                                   EasingOut=\"SinInOut\"                                   HasBackgroundAnimation=\"True\"                                   PositionIn=\"Top\"                                   PositionOut=\"Bottom\"                                   ScaleIn=\"1.2\"                                   ScaleOut=\"0.8\"/&gt;    &lt;/pages:PopupPage.Animation&gt;        &lt;StackLayout\t…",
        "url": "/2018/09/xamarin-forms-dialogs"
      }
      ,
    
      "2018-09-typescript-up-and-running-in-10-minutes": {
        "title": "TypeScript - Up and Running in 10 Minutes",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "You are aware of JavaScript, but have never really made friends with the language? Today I would like to show you a first insight into the JS-SuperSet TypeScript, so perhaps you can give JavaScript a second chance.TypeScript is a SuperSet of JavaScript. SuperSet means that all functionalities of JS are both supported and extended. As the name suggests, the main feature of TypeScript are strongly typed variables. But more on this in a moment.TypeScript is developed by Microsoft and was initiated by MS employee Anders Hejlsberg, who had already designed C#. TypeScript files typically end with the extension .ts and can be converted to JavaScript using the TypeScript Compiler (tsc). Did I also mention that TypeScript is completely open source?SetupI use Visual Studio code to design the example in this article. Of course you can use any other editor as well. My application is also based on NodeJS, which you can download from the project’s website or via the package manager of your choice.In short, NodeJS is a way to run JavaScript on the server side. This allows you to use your applications without a browser. After you have installed Node, you should install the typescript package, which gives you access to the TS compiler. You can use the Node Package Manager (npm) to install packages. To do so, open a terminal window of your choice and enter the command npm install -g typescript.The -g flag specifies that the package should be installed globally instead of only in the current directory, so that the TS compiler is now available to you from anywhere.Hello World!Let’s start with an example. How could it be otherwise, we will develop our Hello World application in TypeScript. Next snippet is all we need:var msg:string = \"Hello World!\";console.log(msg);As you can see, variables are declared with the keyword var as in JavaScript. However, the type of variable follows the name of the variable, separated by a colon. TypeScript provides three basic types: string for strings, number for numeric values (always represented by a 64-bit floating point number) and boolean for logical values. Here, too, we will go into more detail in a moment, but now we would like to know how to get our program up and running.Currently you should have a directory containing a single .ts file. To generate a JavaScript file from it, we call the TS compiler from a terminal and pass our script to it. In my case it looks like this: tsc main.ts.If everything is ok, a new file will be created with the same name as our .ts file. Now, however, with the.js extension. The new file contains the following content:var msg = \"Hello World!\";console.log(msg);Admittedly, there is hardly any difference here. You can see, however, that the typing is no longer applied. The new JavaScript file can now be used with Node. Here, too, the terminal is used to invoke the program: node main.js.This creates the “Hello World!” output we are looking for.The TypeScript compiler also helps you to avoid errors. For example, if you try to assign a text to a variable of type number, you will receive the following error message when compiling:main.ts(3,5): error TS2322: Type '\"test\"' is not assignable to type 'number'.Depending on which editor or plugins you are using, you will be notified during development. VS code, for example, shows you directly the displays the corresponding error message.Of course, this is only the tip of the iceberg, but we want to start small.Your first piece of TypeScript is ready - but you certainly can’t do too much with it yet. My goal for this article was to give you a basic idea of TypeScript and give the language a chance. With Microsoft in the background, TypeScript has a strong backing company and offers great potential, especially for C# developers, since learning the language should be much easier than using JavaScript directly.If you would like to learn more about TypeScript, the language has extensive documentation. I have also planned a follow-up article for the next steps.",
        "url": "/2018/09/typescript-up-and-running-in-10-minutes"
      }
      ,
    
      "2018-08-mvp-youre-doing-it-wrong": {
        "title": "Building an MVP - You are doing it wrong",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "The term MVP - Minimum Viable Product is no longer a new word. The term was first coined by Frank Robinson in 2001 and is now used very frequently.The basic idea of an MVP is to make a version of a product available to the customer as quickly as possible. The goal is not to generate sales, but to learn. Of course it’s not a bad idea and it’s also the intention to earn money with your product, but the idea here is to put yourself in the customer’s shoes and better understand their needs and requirements. This allows you to use early feedback and improve the quality of your product.As you can see, the concept is very simple. But the problem arises during implementation. When we develop a product, we usually already have a fairly clear idea of what the final result should look like. To define how the associated MVP should look, we start cutting features at various points.The result of this process is then certainly minimal, but is it also viable? Many teams forget this point and develop a prototype with limited functionality, which is simply not usable. As I mentioned in my article about Scrum, the goal of every sprint is to add a working increment to the product. After each iteration the user should have a basic version of his product, enhanced by features of the last sprint.The easiest way to illustrate this is with an example: If you want to sell a vehicle to someone, there are (in theory) different levels, each working standalone. From a scooter, a bicycle and a motorcycle to a car, each level has its own functionality that offers the customer added value. Also, each level adds features and functionality to the previous version.The approach, which you might find in practice however, could look more like this: The customer receives the tires first, then the mounted underbody, through the body to the fully assembled car. So you can only really do something with the end product.So when developing a prototype, keep the goal of adding value in mind. Updates should complement and improve the functionality, but the original product should already be usable.",
        "url": "/2018/08/mvp_youre_doing_it_wrong"
      }
      ,
    
      "2018-08-dockerizing-net-core": {
        "title": "Dockerizing .NET Core Apps",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "I have already written two articles about the basics of Docker. While these should provide a general overview of you technology, I would like to illustrate a concrete application example today. I will show you the whole process, from writing a simple application to using it in the form of a Docker Container.If you haven’t read my previous articles, you may not have the idea why you should use Docker at all. For a full explanation, I refer to my other articles which you can check out here and here. However, I would still like to comment briefly on the idea. Imagine you are writing a.NET application. To use your application you now need a special version of the.NET framework, as well as possibly a suitable database and other dependencies.For larger applications it may well be that just installing and setting up the environment is not a trivial task. Over the years, this concept has become simpler, partly through the use of VMs and installation. Nevertheless, according to this approach, an application requires a complete VM, which is not really resource-saving.Docker allows you to map all dependencies in the form of a docker image. This image can later be instantiated as a container, which forms a self-contained, isolated unit. You can imagine a container like a VM, but the Docker container does not have its own operating system. Starting and stopping a container does not require a complete startup and shutdown of an operating system, which significantly reduces the loading times.So far so good. Please install Docker first, if you haven’t already done so. You will find instructions on how to do this here.You have now successfully installed Docker and are ready to go. Before we write our own images, I would like to go into the general usage. Docker is available from the command line. So on Windows you can use the CMD, Powershell or a counterpart of a third party.Docker commands are initiated with the keyword docker. If only this is entered without a subsequent command, a list of available commands is displayed.Docker version gives you information about the installed version of Docker. You see two entries here,a server and a client version. The server version will mention a Linux-OS. During installation you could choose between Linux and Windows containers. The Linux containers are selected by default, in this case the containers use the Linux kernel of the host operating system. If you are using Windows, Docker will create a minimal Linux VM to serve as host. You can see this when you open the HyperV Manager, there you will see an entry with the name MobyLinuxVM.You can also change your choice of container technology later by selecting the Docker icon in the system tray. The context menu that appears contains an entry for switching from Linux to Windows (and vice versa). However, Linux containers are the usual variant and I recommend that you use them, unless you have a special reason for changing.The docker info command lists information about the installed images and instantiated containers. This list is currently empty because Docker has just been installed. The docker run hello-world command starts the image named hello-world. The procedure here is as follows:  The Docker Client first contacts the Docker Engine (also called Docker Daemon), which determines that the image is not locally available.  It then searches the Docker Hub (a platform for exchanging Docker images) and downloads the appropriate image.  The engine then creates a container containing an application that outputs “Hello World”.  This output is sent to the Docker Client, which outputs the text in the console.Downloaded images are kept locally. If you run it again, no new download takes place, the local image is reinstantiated. Images can also be downloaded without being executed immediately. Use the command docker pull imagename to do so.With the command docker ps you can view the running containers. Here, however, you must note that some containers are started, fulfill a task and are then ended again. Other containers run passively in the background and are not terminated automatically. Examples are web servers or database management systems.To also display paused and stopped containers, use the flag -a. You can in general interact directly with specific containers. The basis for this is always the container ID, an alphanumeric character string with which the container can be uniquely identified. However, you do not have to enter the entire ID, the first digits are sufficient until no more mix-ups are possible.Images are usually tagged. Tags are used to specify a version of an image. If no tag is specified, the latest version is used by default. However, this is not recommended, as it can lead to problems with later releases. So always try to use a specify a version of images you use. To do that, simply add a colon, followed by the version after the name of the image.I think that’s enough for now with the basics. Now we will develop our own application with Docker support. I am using Visual Studio Code, so the approach will work on all major operating systems.With the command dotnet new console I instantiate a new console application. The template creates a Hello-World application, which can be started with the command dotnet run. Next, we’ll take care of linking to Docker.First, a dockerfile must be created. Dockerfiles describe the structure of an image and are usually based on other images. My application is based on the microsoft/dotnet:2.1-sdk image. The dockerfile is created without a file extension with the name dockerfile on csproj file level and it contains the following content:FROM microsoft/dotnet:2.1-sdkWORKDIR /appCOPY /bin/debug/netcoreapp2.1/ .ENTRYPOINT [\"dotnet\",\"NET_CORE_Docker.dll\"]NET_CORE_Docker is the name of the project. Now an image must be built based on the docker file. This can be done with the command docker built -t net_core_docker ..The dot at the end defines the current directory as the starting point. Net_core_docker is the name of the image, only lowercase letters are allowed.The image can now be instantiated with docker run net_core_docker and the container will be started automatically. As expected, the output is Hello World! Our first project is running!Of course you can also work with Visual Studio instead of VS Code. Docker support is already implemented here and you can add it to your project by simply right-clicking on the project and selecting Add Docker Support. The docker file is then created automatically.Our first.NET core application now runs with Docker. Of course, this is not limited to console applications, you can also create an ASP.NET core application with Docker support, for example. However, this article has shown you how to integrate Docker into the development of.NET Core. In addition to deployment, Docker is ideal for test and development environments because you can set up other databases or the like without complex installations and compatibility problems with software already installed. Containers can be installed in parallel without any problems and thus have access to different options.",
        "url": "/2018/08/dockerizing-net-core"
      }
      ,
    
      "2018-08-automated-testing": {
        "title": "Automated Testing",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Todays focus is on how you can test your applications automatically to detect bugs early and improve your code quality.I want to introduce you to the concept of automated testing. In order to make the content accessible to as many users as possible, I will not use code examples and concentrate purely on the underlying idea instead. Once you understand them, you will have no problems implementing the concept in the programming language of your choice.First of all: What is automated testing and what advantages does it offer?Automated testing describes writing code that tests your actual code. Your source code consists of the production code and test code.Think of how you may test the functionality of your software. You start the application and log in with your user account if necessary. You navigate to the feature you are working on and perform your tests. You repeat that for different possibilities.You can see from the short description that the whole process is quite time-consuming. Each change requires a new run through the procedure and new functions increase the time exponentially. And this is exactly where automation comes into play.Automated tests can be performed at the push of a button and repeated as often as required. In addition, they run much faster than manual tests. The repeatability means that no more time is required to test existing functionality when adding new features. Basically, bugs are better found because no test scenarios are forgotten, this procedure strengthens confidence in deployment and allows calmer weekends when a release is to be rolled out on Fridays.The repeatability of such tests brings another advantage that only becomes apparent at second glance: refactoring, i.e. changing code without influencing its functionality, is also easier to do. Possible effects of changes on other components of the application can thus be identified directly.Finally, you automatically think more about the quality of your code as you write it, for example, to handle invalid input.In general, tests are divided into three different categories:Unit tests test individual entities without external dependencies. For example, a single function is tested, but things like database connections etc. are not considered. It is only necessary to validate the correctness of the implementation. Unit tests are cheap to write and quick to test, but do not provide complete confidence by ignoring dependencies.Integration tests test an application under consideration of dependencies. These tests are often slower because, external resources may have to be accessed, but these tests also provide more confidence in the application.The last category is end-to-end testing. These describe the direct execution of an application via its graphical interface. By imitating human behavior, the tests are correspondingly slow and can already be broken by minor changes in the source code.So much for that. But what exactly is to be tested now? To put it briefly - everything. But you should be aware of the so-called test pyramid. From bottom to top you should focus on unit tests, then integration tests and finally end-to-end tests. The latter, for example, does not make sense for examining borderline cases, but only for core elements of the application. Unit tests, on the other hand, are ideal for testing conditions and functional results. At this point, however, there are often applications that contain little actual logic and, for example, only serve as an intermediate layer between UI and database. In this case, integration tests are preferred.The basic rule is: deal with gaps in your unit tests with integration tests and use end-to-end tests sparingly. However, the exact balance of the three categories always depends on the project.The approach of implementing automated tests in software projects is usually similar. First you are looking for a testing framework for the programming language of your choice. For my part I mostly use C#, well-known representatives are MSTest, NUnit or XUnit. But you better focus on the basics, not on a special tool.Tests are usually written in their own functions, which are executed and evaluated by a Test Runner integrated in the test framework. The functions are usually based on the Triple-A pattern (Arrange-Act-Assert) and are named according to a constant scheme. This schema usually contains the method name of the function to be tested as well as input parameters or expected result values.Detailed information on the design of tests can be found on the Internet in sufficient detail for the language relevant to you.I would like to conclude, however, by referring to a concept based fundamentally on the use of automated tests: Test Drive Development (TDD).TDD describes a programming concept according to which tests are written before the actual code. The idea is to write a test that tests imaginary source code. Since this is not yet available, the test will fail (or not compile at all, depending on the language). Then the minimum code is written with which the test runs successfully. If required, refactoring takes place afterwards. The advantage of this concept is testable source code right from the start, as well as full code coverage (proportion of code covered by tests). Due to the concept of minimalism, TDD often results in a simpler implementation.You now have a general overview of the idea behind automated tests in software development and I hope I have given you enough motivation to try out the concept. And if you’re working on the details, the keyword ‘mock’ might also help. Mocks are representatives of components of an application that, for example, simulate a database connection and thus facilitate integration tests. Happy testing!",
        "url": "/2018/08/automated-testing"
      }
      ,
    
      "2018-07-learn-anything-quickly": {
        "title": "How I Learn Anything Quickly",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "As a software developer, you are probably well aware of the feeling: You are overwhelmed by the amount of interesting stuff you want to test and learn. But I’m sure that this problem is also very common in other fields.If you feel like me, you may read and watch various books, blog articles or online courses, but you won’t really keep much of their contents.In today’s article, I’d like to help you to learn more effectively about the topics that really interest you, wasting less time.I apologize in advance for all my personal examples coming from my projects as a software developer, but I’m sure you can draw parallels and transfer my experience to your own even without the appropriate knowledge.Before we dive in, I would like to introduce you to a tool that has often helped me when I was looking for an initial idea of a topic: learn-anything.xyz is a website that lists sources based on a keyword that offers you learning materials. There are many different topics and it can’t hurt to drop by here.Before I restructured my learning flow, I used to google for “How to learn XY” and work through the first tutorial I could find. You can certainly imagine that this is not really effective. Often the contents are outdated, incomplete or just incorrect. Another problem I often had is watching video tutorials without trying out the acquired skills directly. Based on the idea “That looks easy” I watched the whole video and didn’t even get a simple “Hello World” application to run afterwards.I have fundamentally revised my process of learning new things. My new concept can be described in a single sentence:Don’t learn without a reasonDon’t learn anything just because it’s hip or because everyone else seems to use it. Learn something because you are enthusiastic about it and, more importantly, because you have a real application for it. Vice versa, of course, if you have an idea for something, you can also use this opportunity to learn something new, i.e. to implement it with a different technology or something similar.For example, I had the idea to write a simple app to manage lists. The application should only be able to manage shopping lists, for example, as efficiently and uncomplicatedly as possible. The apps I found on this topic were simply too bulky and cumbersome for my application, which is why I decided to write my own.I took the opportunity to improve my knowledge in Android development. I’ve hardly ever worked with the integrated SQLite database on Android, and I’ve decided to try an OR mapper that I’ve only read a little about so far (For everyone who’s interested: Room for Android, I’ve got a post on the topic here. For those who don’t know: an OR mapper is used to transfer data records between an application and a database).You can see the result here.So come up with an idea you need to learn what you’re interested in. Then learn exactly what you need to get ahead with the implementation. This gives you the best opportunity to apply what you have learned and to check immediately whether you have really understood it. At the same time, you have a concrete goal in mind as you learn so that you are able to improve measureming your progress.TL;DRMy concept of learning things quickly and effectively can be summed up in one sentence: Don’t study without a reason.  Set yourself a specific goal to work towards  Break down your goal into small work units  Start with the seemingly simple things  Learn something when you need it and can put it into practice right awayIf you can’t think of anything to take as your goal, you can also simply just recreate existing things.Finally, you don’t have to learn every facet of something. The important thing - which you will also learn through this concept - is the ability to ask the right questions. In most cases you will be able to find details within a very short time that you don’t have in mind.",
        "url": "/2018/07/learn-anything-quickly"
      }
      ,
    
      "2018-07-dependency-injection-overview-and-implementation": {
        "title": "Dependency Injection - Overview and Implementation",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Especially when you are at the beginning of your career as a software developer, you probably know that: You have already picked up the term “Dependency Injection”, but can’t do anything with it directly? Then today’s post is for you!I will introduce you to the principle, functionality and the types of dependency injection. Finally, I’ll show you how to write a simple IoC container. And don’t worry if you are unfamiliar with the different terms, I will explain everything, you don’t need any previous knowledge. However, certain basic knowledge in software development is definitely an advantage today. My code examples are written in C#, but you will have no problems understanding them if you are used to another programming language.What is Dependency Injection?Dependency Injection (DI) is a term from the topic area “Inversion of Control” (IoC). IoC is a fundamental concept, DI is its implementation. An IoC container is a framework for dependency injection.DI is the last point of Robert Martin’s SOLID principle. Martin defines that high-level modules should not depend on low-level modules, instead an abstraction level should be used. The easiest way to get a grasp on the concept is to look at an example: Let’s think of a program which processes input from the keyboard and sends it to a printer. This can be implemented by combining a class “printer” and “keyboard”. So far, so good. However, this approach becomes problematic if the code should be extended, for example to support other input or output devices.Martin’s solution is to use abstraction layers that could be implemented as follows: Instead of the communication between the concrete classes “printer” and “keyboard”, the abstractions “reader” and “writer” are used. These can be base classes, from which the concrete classes then inherit. The program flow only requires access to the base class, the implementation details are irrelevant. Changes and extensions are now possible without any problems.And what is Inversion of Control?IoC is the underlying concept behind DI. As the name suggests, there is a inversion of control flow in the program. Different use cases are imaginable, for example inversion of control over the flow of the application, but also inversion of control over instantiation and binding of dependencies.The first of these cases can be thought of as a comparison between a typical console application and a GUI application. The console application determines the process flow and waits for user interaction, while the user determines the process flow for the GUI application.The second case aims to create required elements before they are required. In concrete terms, this means that objects are not created in the class in which they are needed, but before. They are then bound using constructor parameters or property setters, for example.Other techniques that follow this approach include the factory pattern or the service locator pattern.DI in ActionEnough theory. The best way to understand the concept is to use examples. There are three types of dependency injection that I want you to understand:Constructor Injection is probably the most commonly used type. A class is created and passed to the dependent class using constructor parameters instead of being instantiated in the dependent class itself.The following example illustrates this with the class User, which accepts a constructor parameter of type IContactOption. The instance of an implementation of the interface is not created in the class itself, but is specified externally. The interface only has a SendMessage method.public class User{    private IContactOption _primaryContact;    public User(IContactOption contactOption)    {        _primaryContact = contactOption;    }}// …IContactOption contactOption = new EMailContact();User marcel = new User(contactOption);The second category is the Setter Injection. No constructor parameter is used, but a property, which is set from the outside.public class User{    public IContactOption PrimaryContact;}// …IContactOption contactOption = new EMailContact();User marcel = new User();marcel.PrimaryContact = contactOption;The last category is a little bit more complicated, you will find this form in the real world much rarer than the other two. Interface injection is based on the dependent class implementing an interface for setting a variable.public interface IDependOnContactOption{  void Inject(IContactOption contactOption);}public class User : IDependOnContactOption{  private IContactOption _primaryContact;  public void Inject(IContactOption contactOption)  {    _primaryContact = contactOption;  }}// …IContactOption contactOption = new EMailContact();User marcel = new User();marcel.Inject(contactOption);Well, that’s actually it. The implementation of the concept is far less complicated than the theory. However, we still lack the concrete application in our project, which will be discussed next. But first, I would like to issue a warning:DI has a lot of advantages, but you should be careful with its use. DI leaks implementation details of your classes and thus contradicts the principle of encapsulation. In addition, the corresponding objects are always created before they are even needed. Here you should keep an eye on the performance of your application and decide when you really need the approach. DI also partially obscures problems in the structure of your classes. Testing your applications will be much easier because you can easily pass mocks, but you may overlook indications that a class should be divided into two or more components.Structure of an IoC ContainerAn IoC container is a framework for implementing dependency injection. The basic feature here is the automatic resolution of dependencies via an overall class, the so-called resolver. Let’s look at the following implementation:public class Resolver{    public IContactOption ResolveContactOption()    {        return new EMailContact();    }}This very simple example returns an EMailContact object for the IContactOption request. In practice, of course, you will have several options here, but there is already a problem with this implementation: it cannot be extended. Each interface I want to support requires its own method. I would prefer an implementation that allows something like: IContactOption contactOption = resolver.Resolve();And that is exactly what we want to implement now. This can be achieved by creating a Dictionary&lt;Type, Type&gt; to link the interfaces with the appropriate values. The entries must be accessible from the outside. Then, when requesting an implementation by calling resolve with its interface as argument, I will receive an instance of the concrete class.To be able to test this more easily, I have adapted my previous classes as follows:public interface IContactOption{    void SendMessage(String message);}public class EMailContact : IContactOption{    public void SendMessage(String message)    {        Console.WriteLine(\"An email has been sent!\");    }}public class User{    private IContactOption _primaryContact;       public User(IContactOption contactOption)    {        _primaryContact = contactOption;    }    public void Contact(String message)    {        _primaryContact.SendMessage(message);    }}The resolver is implemented as follows: I’ve created  a method for registering classes and interfaces. The resolve-part is done by implementing a method that allows instances to be retrieved using the predefined matching rules. The resolving process is as follows: The system first checks whether a suitable entry is stored in the dictionary. If this is the case, the system checks whether the stored type has constructor parameters that must be instantiated. In the case of a default constructor without parameters, the type is instantiated and this instance is returned. Otherwise, the constructor parameters are collected and also instantiated. Here, too, the new instance is returned. This way, I’m able to support nested objects.public class Resolver{    private Dictionary&lt;Type, Type&gt; _registrations;    public Resolver()    {        _registrations = new Dictionary&lt;Type, Type&gt;();    }    public void Register&lt;TKey, TValue&gt;()    {        _registrations.Add(typeof(TKey), typeof(TValue));    }    public T Resolve&lt;T&gt;()    {        return (T)Resolve(typeof(T));    }    private object Resolve(Type typeToResolve)    {        Type resolvedType = null;        try        {            resolvedType = _registrations[typeToResolve];        }        catch(KeyNotFoundException)        {            throw;        }        var constructor = resolvedType.GetConstructors().First();        var constParams = constructor.GetParameters();        if (constParams.Count() == 0)            return Activator.CreateInstance(resolvedType);        IList&lt;object&gt; parameters = new List&lt;object&gt;();        foreach(var parameter in constParams)        {            parameters.Add(Resolve(parameter.ParameterType));        }        return constructor.Invoke(parameters.ToArray());    }}To be able to use the container now, only the registration of the relevant types is necessary. This may look like this:resolver.Register&lt;User, User&gt;();resolver.Register&lt;IContactOption, EMailContact&gt;();User marcel = resolver.Resolve&lt;User&gt;();marcel.Contact(\"Hello World!\");The parameter IContactOption for User is automatically instantiated and assigned as EMailContact by the mapping. The call in the last line accordingly outputs the text “An email has been sent”.RésuméIn a real application you will hardly implement your own IoC container, but use existing solutions. Nevertheless, I found the own implementation very helpful in order to be able to better understand the actual concept.If you want to look at the available solutions, Unity (not the gaming engine), Castle Windsor and Ninject are probably the most widely used products (for C#). However, the way this works is all similar (though not quite as primitive) to our own implementation.",
        "url": "/2018/07/dependency-injection-overview-and-implementation"
      }
      ,
    
      "2018-07-agile-get-started-with-kanban": {
        "title": "Agile - Get Started with Kanban",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "After I introduced Scrum in my last article, today will be about Kanban. Like Scrum, Kanban is an agile software development methodology and I have to say that I apply the principles I present today to most of my personal side projects.Kanban is Japanese and can be translated as “billboard”. Kanban was first introduced by Toyota in the automotive industry and is now mostly associated with just-in-time concepts. But I don’t want to bore you with historical details, I want to show you the usage in software development.Before we start, you will certainly want to know what advantages Kanban can offer you: Kanban helps you to increase quality and speed up the realisation of tasks as well as to identify and eliminate bottlenecks. This is done by minimizing the time that tasks spend in queues.There are two basic concepts on which Kanban is based: On the one hand this is visualization, on the other hand the limitation of parallel work (Work in Progress, WIP).The visualization of the work offers various advantages. Tasks are not forgotten, which can reduce stress and make it easier to make good decisions. It also simplifies the estimation of how long a task will take to complete.Limiting parallel work reduces the waiting time of tasks and thus increases the flow of the process. At this point I would like to define two key indicators: Lead time and cycle time.Lead time describes the period from receipt of a request to delivery of an associated feature. It is therefore the time period that is visible to the user. Cycle time describes the duration of a task, starting from the beginning of the work until its result is ready for delivery.The goal of Kanban is to reduce the response time of a system. This can be achieved in two ways: Increasing the throughput of the system or reducing parallel work and thus reducing the time of tasks in queues.Let us illustrate this with an example. The workflow of a software company is as follows:  After a problem is reported (1), it remains in the ticket list until the next meeting (2).  At this meeting the relevance of the problem is prioritized, in the following days the solution will be implemented by a developer (3)  Next comes the test of the implementation (4), planning of the release (5) and finally the deployment (6)  There are always periods of time between these individual stations that are not used to add valueThe following key figures result for this process:\t• Total time (value adding): 6 h 15 min\t• Total waiting time: 20 days\t• Lead Time: 485.25 hours\t• Efficiency: Time (value-adding) / Lead Time = 6.25 / 485.25 = 1.29\t• WIP = Lead Time / Time (value-adding) = 485.25 / 6.25 = 77.64As you can see, the efficiency is anything but great. According to Littles Law, there is a WIP of about 78 elements. By reducing this to half, the time required could also be reduced to half.But now really to software development: The idea to use Kanban in software development is to establish a Kanban board to organize tasks. Such boards are divided into different columns that define the corresponding stages of a task. Typically these are things like “In planning”, “Development”, “Test”, “Deployment”. You can see an example of such a board in the following screenshot:Different tasks are then moved into these columns, with each task going through the development process from left to right. As already mentioned, an important principle of Kanban is the limitation of parallel work. That is why each column may only contain a certain predefined maximum number of elements. If a task spends too long in a certain column, problems with the specific task or bottlenecks in the process can be identified. These are then solved as a team, keeping the stress of the people involved at the appropriate points as low as possible.The conversion of a kanban board can be carried out both physically and by software. With a physical kanban board, the tasks can be displayed with post-items. The advantage here is the ubiquity of the board, each team member is always aware of the current status. Alternatively, software solutions such as Trello or Jira offer themselves, which follow exactly the same principle, whereby tasks can be provided here with task assignments, checklists, deadlines and comments.When transferring tasks from one area to the next, it is important to establish a pull system. Completed tasks should therefore not be pushed to the next level by the people who have completed them. Instead, the employees there should pull the task to themselves.Kanban and ScrumNow that you have a rough idea what Kanban is, let’s compare the methodology briefly with Scrum.Both are concepts of agile software development, but what is the best solution for which purpose?Both concepts are based on a pull system. Kanban uses this to move tasks to the next area, Scrum using the agreement of user stories for the sprint backlog. Both concepts are based on transparency and aim to reduce parallel work to a minimum. Scrum implements this rather indirectly, since the requirements that are implemented within a single sprint are clearly defined.The product is also constantly being updated and kept release-ready in both approaches. The self-organization of the team also plays an important role in both Scrum and Kanban and both concepts require the division of requirements into as small subtasks as possible.But of course there are also various differences. Kanban does without the iterative model of Scrum, for example, tasks run through the entire cycle individually. A Scrum team agrees before each sprint which tasks are to be implemented. Kanban, on the other hand, makes these commitments optional.Kanban does not prescribe roles like the division into Scrum Master, Product Owner and Team as known from Scrum.It is difficult to define exactly when which methodology should be used. As in the previous article, it is often the case that none of the methodologies is used in its pure form, but a mixed version according to the team’ s requirements.Kanban is suitable for various IT use cases. In my opinion, Kanban is a more flexible way of dealing with requirements than Scrum is.The concept makes sense here for applications where malfunctions and short-term maintenance are to be expected more frequently.Here, the interval cycles of Scrum are simply too long. In addition, Kanban may be easier to implement in corporate structures that still work with the waterfall model, since Kanban allows a slow changeover.One last thingFinally, in my opinion, Scrum is also excellently suited for the realization of own projects, in principle in the form of a function-enhanced TODO list. You can then combine the tasks for yourself with the Pomodoro technique, for example, to really make efficient use of your private time.",
        "url": "/2018/07/agile-get-started-with-kanban"
      }
      ,
    
      "2018-07-agile-get-started-with-scrum": {
        "title": "Agile - Get Started with Scrum",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "As a software developer you are certainly aware of Scrum. You may have already used Scrum or heard about it only marginally. With this article I would like to give you an overview of what Scrum is and how you can apply this methodology. Plus: You can also use many of the principles even for working on your side projects alone or in a small group.Scrum is probably the best known process model of agile software development. It is a collection of definitions and tools for managing projects. Scrum is not a rigid structure, but a flexible toolbox. A scrum project team consists of three parties: the product owner, who determines what is to be developed in the next sprint, i.e. the next iteration, the development team itself, who is responsible for the implementation and presentation of the results, and the Scrum Master, who guarantees the smooth running of the project. Scrum is designed for small, self-organized teams.As already mentioned, the project implementation according to Scrum consists of several iterations, so-called sprints. A sprint typically lasts between one and four weeks and is used to prioritize selected user stories (formulated system requirements formulated from the user’s perspective) from the product backlog (all requirements for the project), transfer a selection of these into the sprint backlog (collection of requirements for processing in the current sprint) and implement them.This prioritization and selection of requirements is called Sprint Planning. Although the requirements are set by the product owner, they are agreed with the team during the planning phase. This should ensure that the planned requirements are also realistic and feasible.During the sprint the Daily Scrum takes place daily, a short meeting to discuss the current status and to clarify possible problems.After a sprint has been completed, the sprint review takes place in which the team, together with the product owner, validates the various requirements and checks their fulfillment. This is followed by the Sprint Retrospective, in which the Scrum team discusses the cooperation with the Scrum Master and defines suggestions for improvement. The result of the sprint is delivered as an “increment” and the process starts again.To summarize the most important terms in a nutshell:  Scrum is a collection of agile software development methods for project planning and implementation  The product owner defines the goals of the project and validates their achievement  User Stories are the requirements described by the product owner, which are defined from the customer’s point of view  The Scrum Master is a member of the team, which deals with the elimination of problems and thus enables the team to work with the best possible efficiency.  The product backlog contains a collection of all project requirements  The Sprint Backlog contains a selection of these requirements that are to be implemented in the current sprint. Prioritization and selection is made by the product owner, the team agrees to the selection  Daily Scrum is the daily briefing of the team to discuss possible problems and obstacles.  Sprint planning is the planning of the sprint before its execution, which usually takes a complete day (so much for “Agile software development does without extensive planning”)  Sprint Review is the final discussion and presentation of results after a sprint with the product owner  The Sprint Retrospective takes place after the Sprint Review and serves as an agreement within the team regarding points for improvement  An increment is the result of a sprint, which is part of the project result, i.e. the productSo much for the rough plan. But what does Scrum have to offer? And why should I use Scrum and not another agile development methodology? First of all: Most teams do not work strictly according to a specific agile methodology such as Scrum or Kanban, but roughly follow one and adapt it to the individual needs. So if you choose to use Scrum, that doesn’t mean you can’t make customizations or add your own tools.In general, working according to agile principles does not always make sense. The resulting self-responsible way of working does not suit every team and does not make sense for all tasks. Nevertheless, there are also many scenarios where the application of the appropriate methodology can make sense.There are some disadvantages of agile methodology, which I would now like to discuss. Agile methods require a strong involvement of the customer. The product owner is usually an employee of the customer who is very familiar with the project. However, if the partner company is not or only little familiar with agile methods, it is often not easy to convey to the customer why he should spend a not inconsiderable amount of his employee’s time on the project. It is very important to give the customer an understanding of the procedure and to actively involve him.It is also essential to understand the basics and use agile methods, not only the convenient ones, but also those that may seem annoying in the beginning. Another point is the culture of intolerance to mistakes often found in larger, older farms. Mistakes are important because you learn from them and thus improve. These errors must be communicated in a team and possible solutions discussed. If members are afraid to express their concerns and problems, a Scrum project will most likely fail.Teams that are new to this approach may also be unsure about the flat hierarchies and the apparent lack of responsibilities. Here it can help to integrate an experienced Scrum-Master into the team.Scrum does not define any concrete recommendations for action, but only principles and methods that can be applied. The exact selection and structure is then left to the team, which is certainly also an obstacle in initial contacts with agile software developers.Nevertheless, there are some advantages that Scrum offers compared to classical methods: The rules are quick and easy to learn. To use Scrum in a team, no extensive training is required, the principles are easy to learn and can be introduced quickly. The communication channels are short and flexible, which means that changes can be reacted to quickly and problems can be contained quickly.The high level of transparency due to the high degree of communication and the continuous improvement process ensures that problems are dealt with quickly and thus enables the team to be highly efficient.RésuméFinally, the choice of methodology is not a general one, but depends on many different conditions, both for the team and the project. And in terms of agile software development, there is not only Scrum. Hopefully this article gave you a rough overview of the approach with Scrum. In a follow-up post I will describe alternative concepts so that you can form your own picture and decide what is best for your project. However, in my experience I prefer Scrum over for example Kanban when working with a larger team. For personal and smaller projects, I usually use Kanban. But that’s the topic for the next post. Stay tuned!",
        "url": "/2018/07/agile-get-started-with-scrum"
      }
      ,
    
      "2018-07-docker-installation-and-first-steps": {
        "title": "Docker - Installation and First Steps",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "After outlining the theory behind container management with Docker in last week’s article, I would like to continue the topic in a more hands-on way today.I’ll show you the installation and the first steps in Docker. Let’s get started!InstallationDocker is available for Windows, Linux and Mac OS. For the download you’ll need to sign up for a free account.I would like to point out that the Windows version is not intended for production use, only for development and testing. It runs (currently) on a Mobylinux Hypervisor VM, but a native Win10 application is under development. Nevertheless, you will hardly notice this, the usage feels native and you can work on Windows with a command line of your choice.The first command I want to show you is docker info. This will show you information about your installation. If you are using Windows, you can see here what I just mentioned: The client specifies Windows as OS, but the server indicates Linux.Running Your First ContainerNext we want to create and start our first container. We use the following command for this:docker run hello-world Docker run is the command to start a container, followed by the name of the image, in this case hello-world (Tip: If you get a timeout under Windows, try to set the DNS server to fixed in Docker’s network settings, this helped me).You will often stumble across the term docker engine. The Docker Engine includes the Docker Client and the Docker Daemon. The client makes API calls to the daemon, which then processes the commands. In my example, the Docker Daemon now looks for an image named hello-world. If this is not found locally, the search is continued in the default registry, usually the docker hub. The image is downloaded (if one is found) from there and started. When a container is stopped, the local copy of the image is retained, so that a later call of it does not require a new download.The container has now been started. You can view all active containers with the commanddocker ps With the flag -a you can specify that stopped containers should also be displayed.You can also download an image without starting a container immediately:docker pull hello-world I generally recommend that you always specify the version of the image you want to load. You can enter the version number separated by a colon after the name of the image. Example:docker pull hello-world:1.2 To remove an image, use the commanddocker rmi hello-world The version number can also be specified here; this is done in the same style as for the pull.Creating Your Own ImagesNow I want to create my own image. I want to write a simple PHP hello world application. For this I need a so called dockerfile. These files describe images and serve as a kind of blueprint. For the realization of a PHP application PHP and a compatible web server is required. I will use Apache here, so I need an image with Apache, PHP and my own script. First I need a suitable docker file. Fortunately, I don’t have to write it myself, I can use templates from the Hub.On the Docker Hub I can find it by searching for’PHP’ and using one of the entries that lists the keyword’Apache’. You will find here different entries, each with a highly specialized version on the left, to the right the versions become more and more general. I recommend that you use one of the more specialized versions to prevent unwanted updates.I decide to use the image with PHP 7.2 and Apache Stretch. The Hub page lists how to handle the template:FROM php:7.0-apache COPY src/ /var/www/html/  Since I want to use PHP 7.2, I update the version number accordingly. This script now corresponds to the content of my docker file. Brief summary: I now have a folder containing my docker file with the above content and another folder ‘src’ containing the index.php with a simple Hello-World script:&lt;?php echo 'Hello Docker!'; ?&gt; Docker images are ‘layered’. The PHP image is based on other images and so on. Our own image is based on php:7.2-apache. This allows us to keep our docker file short and concise and to include PHP and Apache with just a single line. So our docker file will download the PHP image from Docker Hub, and copy the files from the src folder to the /var/www/html/ directory within the container.Now the image must be built. To do this, I use the commanddocker build -t hello-docker . Hello-docker is the name of my image, the -t flag is used to assign a name. At the end you have to specify the path to the docker file. The point references the current directory.After the image has been created, it can be started in the form of a new container.docker run -p 80:80 hello-docker The call looks almost like the one we’ve already met. The -p 80:80 addition merely defines that the traffic arriving at port 80 on the host is forwarded to port 80 of the container.After the start you can now reach the web server via localhost. Your first own container is now up and running!",
        "url": "/2018/07/docker-installation-and-first-steps"
      }
      ,
    
      "2018-07-book-review-four-hour-work-week": {
        "title": "Tim Ferriss - The 4 Hour Work Week",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Most of you may already know the book by Tim Ferriss. Nevertheless, I would like to hold my thoughts here, because some approaches and concepts have really made an impression on me.The basic idea of the book is that you can work from any location and thus combine work and travelling. The modern definition of wealth is not defined by the bank account balance, but by the ability to freely manage one’s time.Today’s socially accepted course of life is as follows: Educate yourself in the first 20 years of your life. Work hard for the next 40(+) years and finally retire in the next 20 years. In other words, work hard and save a lot of money that you won’t have any fun with because once you reach the goal you are either old or dead.You probably know the idea of three currencies in life: Time, money and energy. At every stage of your life, however, you seem to be missing one of these. In your youth you have time and energy, but no money. When you grow up you have energy and money, but no time. Being a retiree, you have time and money, but no energy.So what is the first step to avoid this problem? Appreciate all three currencies - and not just the money.As I mentioned earlier, Ferriss measures the degree of freedom by means of a “Freedom Multiplier”. To do this, he asks the following 4 questions for anything he does:  What do you do?  Where do you do it?  When do you do it?  With Whom do you do it?The more of these you control, the freer you are. So if you control all four, you report to no one but yourself.Ferriss describes the way to achieve exactly this with the acronym DEAL: Definition, Elimination, Automation and Liberation.Definition: Describe your goals. Define what you would do if all time and money-related hurdles were removed from your path.Elimination: You can’t do everything at once. A day only has 24 hours. And since time is your most valuable asset, you should use it wisely. Cut the crap! Stop wasting hours on image boards or social media channels and use this time to pursue your dreams. You’ll notice how fast you can come up with results if you just allocate a small, fixed period of time every day.Automation describes the idea of earning money passively. After you have implemented your idea, it should be possible for it to generate money without any further effort on your side.Finally, Liberation is supposed to loosen locationality and allow you to work anytime, anywhere.This is the basic idea of the book, so to speak the TL;DR version of a summary. But let us take up a few concepts in more detail below:Retirement Probably SucksRetirement is praised everywhere as the big goal that is being worked towards for a very long time. This expectation, however, assumes that you hate what you are doing and finally get your peace of mind when you retire. Also, things like inflation will increase the cost of living during your retirement (which may not matter to you, assuming you have made good investments). But if you have the opportunity to retire early, you will most likely have an excellent willingness and motivation to work, you you might get bored after a short period of retirement and get back into business.Ferriss suggests an alternative: Mini-retirements. Instead of betting all your money on never having to work again at the end of your 60s, take mini retirements at regular intervals to recharge your batteries. Use this opportunity to learn something completely new, such as surfing or flying an airplane.If you didn’t have to work anymore and have all the time in the world, you’d probably get bored pretty quickly. I’m pretty sure you want to work. But it’s self-determined and based on your own ideas.Travel CheapA first discouraging thought about travelling is often money. But travelling does not have to be expensive. Living and working abroad is often cheaper than paying rent in your home country. Of course, that always depends on what your starting situation is, but keep that in mind. In the book Ferriss also recommends renting a hotel for the first few nights in a new location and finding local rental apartments during these first few days. Online portals for this are often significantly overpriced.Consistency Is KeyI do not remember how many times I have read this advice or passed it on myself. More is not always better and consistency is often better than intensity. Try to contribute regularly to your goals and you will notice how great the effects are.The same applies to you if you want to start your own business. You don’t have to quit your job and jump right into your new business. This may work, of course, but it scares many people off. Instead, you can simply start to turn your ideas into reality in parallel and - as soon as it turns out that your concept works out - switch to a full-time model.Don’t Shit Where You EatTry to have different places for different things. Don’t work in your bedroom and vice versa. This should help to leave things where they belong and not think about work in bed. I found this really helpful for myself when using my bed to sleep and not to watch movies.Utilize The Pareto PrincipleIn many different areas you will encounter the 80-20 spread. The basic idea is that with 20% of the input result into 80% of the output. The “Better done than perfect” rule is also important here. You have to decide for yourself which points are important for you and I’m not saying that for everything you do you should only aim for the 20%. But think carefully what proportion of the remaining 80% of your time is worth to be realized.In this context, Ferriss also goes into Parkinson’s law, which states that a task takes as much time as you allow it to take.That was new to me, but I realized it is true. And if you started a student research project just before the deadline, I’m sure you’d agree as well.If you focus on 20% with a tighter deadline, you will achieve significantly more than you can imagine.Final Thoughts  Stop hating your reality, subject it to your will  Living in foreign countries is often cheaper than your regular rent  Establish financial reserves for the worst case  Ask for forgivness, not for permission  For the important things in life, it’s never the right time  Relative income is more important than absolute income  Define your personal nightmare and create a plan to limit ist impacts  Define your dreams – short- and longterm  Focus on your strengths rather than trying to eliminate your weaknesses  What are you waiting for?",
        "url": "/2018/07/book-review-four-hour-work-week"
      }
      ,
    
      "2018-07-docker-getting-started": {
        "title": "Getting Started with Docker",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "As a software developer, you’ve probably heard about Docker and perhaps already used it. But if you’re like me, you’ve been observing the topic from a distance with some interest, but you haven’t gotten into it yet.In this article I would like to introduce you to the concept of docker and the “big picture”. This post will not be a detailed tutorial, but will give you an overview of the technology and help you get started.Docker is software for isolating applications through container virtualization. Before we start with Docker as a practical example, I would therefore like to discuss containers in general and describe what distinguishes them from virtual machines.What are containers?Imagine a company wants to put a new application into operation. In the past, this was usually done in such a way that new hardware was purchased for this purpose; each physical server was responsible for one application. When a new application was added, however, it was often unclear how much power would be required for the new application, which is why it was often overdimensioned. This, of course, also results in unnecessary costs.The successor of this concept, which is often used today, are virtual machines. Physical hardware is distributed across multiple virtual machines on which the applications run. This means that an application is no longer managed per physical server, but per VM.However, this concept is already problematic: Although the number of servers is reduced, each VM still requires its own OS installation, which in turn requires license fees (at least in most cases), as well as time for administration of the operating system, etc. This of course was also the case with the previous concept, but we’d like to circumvent that.In addition, every operating system needs a whole bunch of storage space, which could otherwise be used elsewhere. This is best illustrated in the following graphic:The graphic shows a classic hypervisor architecture with three virtual machines. Okay, basically the points OS and VM belong together, but to compare the graphics better with the container counterpart, I have listed them separately here. In return, let’s look at the structure of a container-based architecture:As you can see, the layer of hypervisor and VMs disappeared. The containers in which the applications run share the operating system. This approach is much lighter, since no entire OS needs to be loaded to start a container. When you try Docker, you will notice that a Docker container usually takes less than a second to launch. In addition, much less storage space is generally required, as the various operating systems are no longer required.The fundamental difference between hypervisor and container technology is therefore the common operating system basis of container-based architecture. Next, let’s look at Docker as a concrete example.What is Docker?First of all: Docker is neither the first nor the only container technology. Docker has become the de facto standard thanks to its ease of use and other features and is used productively by a large number of organizations worldwide. One of these important feature of Docker is Docker Hub, which I will cover soon. The many additional applications and plugins are not only provided by Docker Inc., but also by 3rd party developers and companies.The company behind Docker, Docker Inc. was founded in San Francisco in 2010 under the name dotCloud and was renamed in 2013.Docker Inc. is not the same as Docker. The software itself is open source and released under the Apache 2.0 license. At the core of Docker is the Docker engine, which is used to create and run images. You can think of an image like a disabled container or a template for one.Docker Hub is a platform (a so-called image registry) on which images can be exchanged. For example, if you want to create a PHP application and your container needs an Apache web server and a PHP installation, you can search for pre-built images on Docker Hub and integrate them into your project. You will find a multitude of offers for various applications there, which means that you hardly have any effort in creating your own images. You can think of Docker Hub as a “PlayStore for enterprise applications”.DockerHub is not the only image registry. Besides this, there are many other cloudbased registries, but there are also ways to host one in your own network. This is especially useful for business applications with a no-cloud policy (however, you can also mark your Docker Hub images as private so that only you have access to them).For what kind of software can Docker be used?Containers can be used for both stateless and statefull applications. Although many advantages of containers only become visible with stateless applications, there are a large number of images for database management systems, for example. Containers will keep your data when turned off, so you can easily run a PostgreSQL instance with Docker, for example. So-called “volumes” can also be used to hold this data even if a container is destroyed.Container OrchestrationA buzzword you’re sure to stumble upon early on is container orchestration. But what’s it all about? It refers to the (automated) cooperation of many individual services within a complex application. Docker has its own tool for this: Docker Swarm allows you to orchestrate containers across multiple hosts, so you can manage containers across Microsoft Azure or Amazon AWS, for example. Of course, there are also alternatives in this area, for example Kubernetes, initiated by Google.Wrap-UpDocker offers developers a way to run applications in isolation without having to use a VM for each app. Additional tools such as the Docker Hub enable the exchange of images and thus speed up the creation of your own images.I am aware that this short introduction can only give you a minimal insight into how containers work. I hope, however, that I have awakened your interest in getting more involved with this topic and that you now know what to look for. After all, the same applies here: If you want to learn the subject as a developer, you’re best served by getting your hands dirty.You can download Dockerhere, for which you need a free Docker ID (this is also valid for DockerHub). If you want to learn more about the topic, you can find several guides online, I recommend to have a look around at Medium.com, Pluralsight or YouTube.",
        "url": "/2018/07/docker-getting-started"
      }
      ,
    
      "2018-06-introduction-to-vcs": {
        "title": "Introduction to VCS",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "When you start learning to program, you rarely think about how you will be able to work on a project at the same time with other people. By the time your side projects take on larger dimensions or you work in a team, you will be confronted with the topic of version control.Version control is basically the management of source code, so that several developers can work on the same files at the same time. The sense of a system for monitoring changes can be easily understood by an example:Two developers, Bob and John, are working together on a project. They do not use version control and their workflow is as follows:The source code is stored on a network drive to which both have access. Every morning they copy the contents of the drive to their local machines. They discuss who is working on which files on that day. Bob decides to work on the connection to the database, while John decides to revise parts of the business logic. At the end of the day, both copy their changed files to the network drive. Since both have worked on different files, this is possible without any problems.John now remembers that he also made a small change to the user interface. Knowing that Bob was only working on the database, he simply copies the file to the server. However, Bob also made some changes to this file and he also assumes that John was only updating code in the business logic. He also copies his changes and thus overwrites John’s work.When working in this way, precise communication is essential. As the example shows, this procedure is very error-prone, even though only two developers were involved. The coordination effort increases to an immeasurable extent as the number of developers increases.I don’t intend to present a multitude of version control systems, but I would like to give you at least a short overview of what has changed as time passed by. I therefore divide the different systems into three generations: Generation 0 works with file locks, Generation 1 consists of CVCS, Centralized Version Control Systems and Generation 2 are the so-called Distributed Version Control Systems (DVCS).The first software for version control of files was Source Code Control System (SCSS). The software classifies itself into generation 0 and locks files when they are processed. However, these systems have a significant disadvantage: assuming you want to work on a file that is currently being edited by someone else, you have to wait until they have finished making their changes. You could urge the respective developer to work faster, but he might be sick or on vacation. So it can take quite a while before you can access the file to make your changes. You could now create a local copy of the file and perform your changes right to the copy. As soon as the file itself can be accessed again, you perform a manual merge, i.e. you combine the two files and join the respective changes. However, this is again prone to errors and should be avoided.The second generation describes the so-called centralized version control systems. Here you will find a server that manages the source code. To work on a file, a developer must check out this file, i.e. retrieve the latest version of it from the server. I would like to illustrate this again with an example of our already known developers:At the moment John wants to make changes to the login.html file. He loads the latest version from the server and starts working. After he has made his modifications, he checks them in, so the file on the server is being updated. In the meantime, Bob has also fetched this file and made some changes. If he wants to check in his modifications again, the server will inform him that the file has been changed in meanwhile. Bob must now perform a merge, which is usually supported or even automated by the software. Once all conflicts (places affected by both changes) have been resolved, the file can be checked in.There are many different systems in this category, the best known probably being Subversion (SVN) and Microsoft’s Team Foundation Server (TFS). While these systems are still used very often, a new category was formed around the middle of the 00s: The Distributed Version Control Systems.  First and foremost the best known representative, developed by Linux creator Linus Torvalds: Git. Git’s popularity is certainly also related to the launch of GitHub 2008, but DVCS generally offer advantages over its centralized counterparts.The idea of distributed version control systems is that no server is needed to manage the source code. Instead, each copy of the repository contains a full history of all changes made to each file. So, without loading anything from a server, you can reconstruct any point in time of your software. You can also work offline and share your changes with your team members as soon as you can reconnect to them. You also have the advantage that any computer that has a copy of the repository can be used as a backup source. I assume, however, that if you use a CVCS, you also have a corresponding backup strategy, which is why I do not consider this advantage really relevant.I hope I could give you a rough overview of the different categories of version control systems. I already wrote an article about Git, if you like, you can read it directly on my blog.Basically, however, I would like to point out that the use of a version control system also has advantages, even if you work alone. Availability of file histories, branching or publishing to, for example, GitHub are just a few of them. But it’s definitely worth trying if you don’t use VCS yet.",
        "url": "/2018/06/introduction-to-vcs"
      }
      ,
    
      "2018-06-csharp-attributes": {
        "title": "C# - Getting Started with Attributes",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In todays post I want to show you how to use attributes in C#. I have to apologize in advance, though, as I’m going to focus only to a limited extent on why they make sense and what you can use them for, that’s a topic for one of the following articles. Nevertheless, I would like to give you a basic understanding so that you can incorporate this concept into your own applications.So what are attributes? Well, attributes themselves are just classes. They can’t do much themselves, but they can still be very helpful, especially on a topic called Reflection, which I will be discussing in the next days.Attributes are usually utilised to assign metadata to classes, properties and the like. Attributes inherit from the class Attributes. According to the convention, their names are always appended with the extension Attributes. They can be placed on various elements, one speaks of decorating a class, for example. To restrict the use of a custom attribute, the attribute AttributeUsage can be used.That was a whole bunch of attributes, right? Let us test this with an example, so that it will be easier to understand.[AttributeUsage(AttributeTargets.Class | AttributeTargets.Property)]  class DemoAttribute : Attribute {   public string Description { get; set; } } I created my own attribute, DemoAttribute. I have designed the name according to the convention. I want only properties and classes to be decorated with the attribute, which is why I piped these two options together using the AttributeUsage attribute.The attribute has a property called Description. With this I want to describe my classes and properties later. Let us also look at an example.[Demo(Description = \"Test for class A\")] class ClassA {   [Demo(Description = \"Test for Property ClassA.Name\")]  public string Name { get; set; } }[Demo(Description = \"This is class B\")] class ClassB {} class ClassC { } I created three classes to test my attribute: ClassA, ClassB and ClassC. I know, very incredibly creative. I decorated classes A and B with my attribute, class C I deliberately ignored. In addition, class A has a property with the attribute.Now I want to show you the real purpose of attributes, but for this I have to be a little ahead of schedule. If you are interested in the relevant topics, just search for the keyword Reflection (oh, and LINQ, if you are new to this).var classes = from t in Assembly.GetExecutingAssembly().GetTypes()   where t.GetCustomAttributes&lt;DemoAttribute&gt;().Count() &gt; 0   select t; foreach(var c in classes) {   Console.WriteLine($\"Fount class: {c.Name}\"); } In this snippet I first obtain all classes in the current assembly that are decorated with the attribute DemoAttribute. Then I iterate through the result set and simply output the names of the respective classes.You can add the following to search the found classes for properties with the same attribute.var props = from p in c.GetProperties()   where p.IsDefined(typeof(DemoAttribute), false)   select p; foreach(var p in props) {   Console.WriteLine($\"Fount property: {p.Name}\");} Of course, the concept can be extended as far as you like. For example, you can design method calls so that all elements within an assembly or across assemblies are called in this way, thus modularizing your application without creating references between projects. But more about this later. With this short introduction I have only shown the basic idea of attributes. As already mentioned, the use of attributes is a separate topic. Stay tuned!",
        "url": "/2018/06/csharp-attributes"
      }
      ,
    
      "2018-06-less-css": {
        "title": "Simplify your CSS - LESS is more",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "First things first: I am not a web developer and certainly not a designer. The following examples are not intended to represent good practices in terms of design or aesthetics.But now to the topic: As a software developer you can hardly avoid acquiring basic knowledge in web development. Specifically, I mean the handling of HTML and CSS, also in JavaScript as far as I’m concerned. If you are like me, you basically have no problems with it, but CSS files will become quite confusing and difficult to revise over time. Let’s look at some problems I think CSS has, then I’ll show you how to solve them.The Problems of CSSThe thing that probably bothers me the most is the lack of variables in CSS. Whether to define color codes or font sizes: the constant duplication of corresponding entries makes me crazy, especially if something needs to be changed. Oh, and how about calculating values based on variables? For example something like: format each h2 tag with a font size like h1, only 2 units smaller? Nope.Another point is the transparency of nested statements. Long-winded listings of nestings in nestings lead to an almost endless number of CSS statements that no one will have an overview of later. Not to mention old entries that are no longer needed, but are simply overlooked.LESS is moreWell, there are more problems than I have presented that we will solve now. However, I have only gone into what I think are really essential things that bother me about CSS.LESS is an extension to CSS, which means that all CSS code is also valid LESS code. LESS, however, offers various ways of circumventing the problems described above. But before I go into these, I would like to show you how you can use LESS at all.There are two ways to integrate LESS into your website. One possibility is the conversion from LESS to CSS and the integration of the resulting CSS file into your website (as usual). Alternatively, the LESS file can also be included directly, in combination with LessJs, which only evaluates the stylesheets on the client side. I prefer the first option because I don’t have to rely on additional JS libraries.If you also choose this approach, there are several ways to do the processing. There are special websites that work on a copy and paste basis, but I prefer to use something like the Gulp integration for ASP.NET Core in Visual Studio. Click here for more information.Now that the basic structure is in place, we can start with the features themselves.The first thing I mentioned was using variables that are missing in CSS. LESS offers this functionality, let’s look at an example.@blue: #008FFF; @defaultFontSize: 15px; p {     color: @blue;     font-size: @defaultFontSize; } As you can see, variables are declared with an @ character. Variables can be used for various elements, such as colors and sizes. Also, variables can be calculated by using regular arithmetic operators (this also works for colors).My second point was the use of nested statements. LESS offers the possibility to style nested elements as follows: .sidebar {   float: left;   ul {     padding: 10px;     list-style-type: none;     a {       color: @link;       text-decoration: none;     }   } } I think the result of this example is quite easy to understand. The nested CSS statements apply to HTML elements nested in the same style. The statement for the a tag therefore only applies to those elements that lie within an unordered list, which in turn lies in an element of the’sidebar’ class.Those were all the features I really missed. But as promised, there are more: LESS offers possibilities for calculating color values, mixins, imports for distributed CSS files and own functions. I will conclude todays post with a brief comment on the individual elements:Another feature are the so-called mixins. These allow the usage of CSS classes within statements. Let’s look at an example: .borderAll {   border: 1px solid black; } .sidebar {   background-color: red;   .borderAll } LESS offers predefined functions with which (color) values can be manipulated. A complete overview of available functions can be found here, but their use is identical according to the following syntax: color: saturate(@green, 25%); Finally, I would like to show you how to use import statements. You may know the include function of PHP. It’s kind of the same thing. You can use it to include other CSS or LESS files and thus distribute your instructions. If you omit the file extension, a matching LESS file is automatically searched for. @import \"base.css\"; I am aware that this short summary is by no means a complete guide to working with LESS. But I hope that I could arouse a little interest and even make your work with CSS a little easier. As in most such topics, the same applies here: Just give it a try. By applying it you will learn the fastest. A full overview of the features can be found on the official website.",
        "url": "/2018/06/less-css"
      }
      ,
    
      "2018-06-sideproject-clubgrid": {
        "title": "Sideproject - ClubGrid",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "It is finally time to announce my latest side project. ClubGrid was originally designed to make it easier for my coach to manage our baseball games. However, the result can be used for clubs of any kind and I hope that I can also help others with my software.The problem we had was the organization of games and events. Some players posted their acceptance or rejection via Whatsapp, others via Facebook, some via email and others personally. This made it quite complicated for us to keep track of who is present where and when.In addition, there was the assignment of duties. Players alone are not enough, additional umpires, scorers, coaches and people who take care of the sales are needed.This finally gave me the idea to solve the problem via a portal, which can be integrated into the existing club website. Team members can register there for events and trainers can see at a glance who is participating and where they would like to help.The plan was born. I have some knowledge of PHP and therefore decided to implement the platform with this technology. I started with ER modeling. Then I derived my individual pages from this model and created wireframes for the rough design of the website. And then things were ready to start!As I said, I started to implement the website in PHP. That worked quite well, even though it seemed rather messy to me. For the time being, I accepted that and continued to work on my prototype. After some time (I had almost finished the features of the MVP), I nevertheless decided to change technology.There were several reasons for my decision. The first obvious thing was the lack of transparency in my source code. But I also didn’t want to limit myself to my basic PHP knowledge. However, since I had no real interest in delving deeper into PHP and wanted to strengthen my knowledge in other areas instead, I decided to implement the application in C#. At that time I had heard of ASP.NET, but that was all. I never used it. So I read the basics and quickly switched to a Pluralsight course to get my hands dirty with a real example.I don’t want to say much about ASP.NET (Core) here, but compared to my PHP version I’m thrilled. The code is much better structured, clearer and I was able to make much faster progress.Another possibility I took during the development was the use of postgres as the underlying database. Besides the regular functions I haven’t played much with it yet, but so far I have a very positive impression.But enough about that. Let’s look at the result:ClubGrid is my first real web application. The tech stack of the software consists of ASP.NET Core and PostgreSQL, the connection is made using Entity Framework Core. The software offers clubs the possibility to manage their events internally and thus enables trainers to see the status of the promises at a glance. Originally, I only planned to release the software for my local baseball club, but the software can quickly be extended to support other sports or other clubs in general. I setup a website for showcasing the application.In the next days I will implement the last missing functionalities, so that we can put the first instance live. Then I’d like to make some surface improvements and add support for more sports.As soon as all this has happened, I would like to include several options for notifications. I am very curious about what will follow and look forward to any feedback or suggestions for new features!",
        "url": "/2018/06/sideproject-clubgrid"
      }
      ,
    
      "2018-05-step-outside-your-comfort-zone": {
        "title": "Step Outside Your Comfort Zone!",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "We humans tend to make ourselves comfortable. We take the easiest way we can find. But there are so many things we miss this way. In many cases it is the small things that make a big difference. Today I would like to show you how I have taken such a step and what has changed since then.Photo by Jenny Hill on UnsplashAs a child I did athletics for several years. I did the standard disciplines and I really enjoyed it. But I never trained any endurance related disciplines besides the regular 3 laps to get warmed up.Some day, at a regular tournament, my coach had me signed up for the 1000 meter runs. It was hell. That day, seven year old me decided to never participate in something like this again.I kept this promise for 14 years until I successfully finished my first 10K last week. By choice.From 0 To RunningIf you had asked me during my school days what I would have despised most about sports lessons, I would certainly have answered with “endurance runs”.Last September, I decided that I needed change. I wanted to get in general better shape and I wanted to really challenge myself. I thought that the most difficult thing I could try to stick to would be running. Simply because I wanted to prove to myself that I can do it, no matter how much I hate it.At first I tried just to run regularly. But I quickly realized that I lacked planning and motivation. On Reddit I came across the C25K (Couch to 5K) program, which seemed to be tailored to my plan. At this point, I’d like to give a big shoutout to the c25k subreddit, the community is amazing and they really support each other. Definitely check it out.The idea of the program is simple. Install an app that will help you train within 8 weeks so that you can run a 5 km run in 30 minutes without taking a break.The training is based on 3 runs per week, with the training schedule becoming more intensive every week. Training here means changing between walking and running, whereby the running intervals become longer and the walking intervals shorter as you progress.And that really works. While the programme is not easy, I think it is feasible in any case. I never thought I’d actually do this, but it works. After 8 weeks I exceeded my target and was ready for further progress.We had a pretty cold winter in southern germany and running was quite difficult. In January, I got the flu and had to stop training. It took arount one month until I got myself together and decided to continue. There’s a follow-up app C210K available and I decided to try it out. However, I didn’t really manage to stick to the program as I did with c25k.One day later, I signed up for a 10K near my hometown which will take place in early may 2018. This way, I forced myself to train for that. Surrender was no option and my goal was to do the whole thing without walking.Eventuall, may came around and I was a bit behind when looking at my goal. I managed to run 8 KM and figured, I could do 10 at the run.While the first few kilometres where quite heavy, I really got into it and made the full distance without stopping. Also, I did it in less than an hour.Call to ActionTraining alone and going through the program alone is not easy. If you have the possibility to do the whole thing with a partner and you can push each other, this will definitely help you. But even on your own, with a little self-discipline the whole thing is quite feasible.But I don’t want to limit this example to my experience, I would say that it can be applied to many different areas of life. Think about why you loathe something. And then try to see the whole thing from a different angle and fight against the laziness. And I’m sure the odds are good that you’ll actually enjoy it. After all, we are growing on challenges, not on dull activities.",
        "url": "/2018/05/step-outside-your-comfort-zone"
      }
      ,
    
      "2018-05-c-mastering-the-basics-repository-pattern": {
        "title": "C# - Mastering the Basics - The Repository Pattern",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "There’s a very large number of articles about the repository pattern out there.Nevertheless, most of them overlap in the description and cause confusion among developers.For this reason I decided to write my own article to document my opinion.In this article I will first clarify the what and why of the repository pattern.Afterwards I will explain how the pattern can look like in C#.In his book, Patterns of Enterprise Application Architecture, Martin Fowler describes the Repository Pattern as a “Mediate between the domain and data mapping layers, acting like an in-memory collection of domain objects”.The following benefits of utilizing this pattern are usually listed when reading articles on the topic:  Minimize query logic  Decoupling from persistence frameworks  Easier testingThe idea of reducing query logic refers to the reusability of code. Imagine you work directly on a collection. If you need a certain subset of the stored objects, you will query them via LINQ. But chances are, you won’t need this query logic in just one place. However, since the entire collection is available everywhere, you will implement this logic in each place, resulting in duplicated code. The alternative is to move this logic to the repository. All code elements involved then retrieve the subset from this.The decoupling from persistence frameworks follows the same principle. The connection to data storage only takes place in the repository. The business logic only accesses the repository, the implementation details are irrelevant at this point. This means that the repository can be exchanged at any time, for example with another ORM or even to a new storage strategy.The idea behind the simplification of testability is to make repositories easily exchangeable by using an interface and thus to be able to easily implement a mock repository. But this is not a peculiarity of the repository pattern, so I don’t really see this point as an advantage of the pattern.In a NutshellAs mentioned above, the basic idea of the repository pattern is to design an intermediate layer so that the business logic can operate as if on an in-memory collection. In a very simple way, this interface can look like this:  Add(obj)  Remove(obj)  Get(id)  GetAll()  Find(predicate)As you can see, there is no item for saving changes. And that’s exactly where the in-memory collection comes into play. Since the collections only contain object references, the entries can be edited directly.Nevertheless, database entries must somehow be persisted. This is where the Unit-of-Work Pattern comes in. Again, from Martin Fowler: A unit of work maintains a list of objects affected by a business transaction and coordinates the writing out of changes.So this means that we will combine one or more repositories with a single unit of work which will persist changes to the database. An interface for a basic unit of work could have the following methods and properties:  IMyRepository MyRepository { get; }  SaveChanges();Of course, in a real application, there would be some more repositories.If you look at the whole thing now, you might get the idea that Entity Framework already implements these mechanisms. More precisely, a DbSet looks like a repository and a DbContext like a unit of work. Let’s take a closer look:At a surface level, a DbSet looks like a repository. It provides access to a collection and allows you to edit, add and remove entries. Using the DbContext you can persist changes afterwards. However, this approach is problematic in view of the previously defined advantages of the repository pattern: One point was the reduction of duplicated source code by outsourcing functionalities with regard to special subsets. With this approach here the pure collection is published and worked with. The result is exactly what we want to avoid, namely the direct selection and projection of items from the collection.The use of DbContext is also not suitable here. Another positive argument of the repository pattern was the decoupling of persistence frameworks. This contradicts the approach, since the business logic would be tied to Entity Framework.So while DbSet and DbContext look like implementations of the repository and unit of work pattern, they don’t provide the architectural benefits, which is why you still have to provide your own implementation for this.",
        "url": "/2018/05/c-mastering-the-basics-repository-pattern"
      }
      ,
    
      "2018-05-learning-to-learn": {
        "title": "Learning to Learn",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "How often did you tell yourself that you want to learn a specific skill and you either stopped while learning it or learned it but never managed to apply it in your workflow?I bet you encountered both situations more than once. In this article, I’ll cover my method on how I learn new skills efficiently and actually remember the stuff I read.In this post, I’d like to share my thoughts and experiences in learning new skilly. While my examples are mostly centered around programming and software development, I’m sure that you can apply the most of the principles in other topics as well.Learning By DoingYou’ve never heard of that idea, have you? Of course you did. Like probably everyone else. Nevertheless, I find it difficult to derive a practical approach.One thing that helps me personally very well here is learning under the pressure to immediately apply what I have learned. As a result, I only learn what is absolutely necessary. This usually sticks very well through immediate application.Imagine learning to skydive right before jumping out of an airplane. I bet you’ve never been learning as efficient as in that particular situation.While this is a very efficient approach, it is certainly not what we would like to see in everyday life. Firstly due to the stress involved, but also due to the lack of an overall view.A great way to create a similar environment is to set goals for what you’re learning which requires to apply the newly learned skills. For example, let’s say you’d like to get a grasp on relational databases. Of course, you can dig through books or online courses, but I recommend to try and think of an idea where you can both implement the learned expertise.To stick to the database example: this could be a simple app to document your cd collection.By directly applying new skills, you’ll gain a deeper understanding of the topic and a good feeling of what’s important and what may not right away.My Learning RoutineWhile the whole learning by doing approach makes a lot of sense, you’ll probably miss some important or interesting facts. To prevent overly complicated solutions, I created my own learning routine. The main thought of it is not to learn anything, but to learn how to look something up when it’s needed.When you’re reading non-fiction, let’s say a book about a new programming language, you probably won’t try out every part of the printed syntax. However, chances are that you might stumble across a situation while coding when you think “hey, I think I read about something that could really help me here”. And at this point, you’ll be able to look it up again and implement the code as you like. You don’t have to learn any detail of whatever you’re learning. Most of the time you will find a Pareto distribution of the relevance of what you have learned and the effort involved. Assuming you learn one thing 100%, then you will have learned 80% of the knowledge with 20% of the effort. Details are often nice to have, but mostly not absolutely necessary. Use this to set your focus accordingly.I use the following steps for learning a new topic:  Gather information. These can also be thicker books, but be sure to use a few different sources.  Go through the tables of contents of your sources and match them  Use your summarized tables of contents to define an overview of exactly what you want to learn.  If possible, think of an overall goal that you can use to track and monitor your learning progress. If necessary, you can also create a separate goal for each sub-topic.  Be consistent during learning. Try to learn a little something every day, instead of fewer larger blocks. Only half an hour a day is enough for this.That’s all I’m using. How you divide up your time is of course left to you. However, the example of 30 minutes per day should make it clear that even short times can bring great progress, after all, this brings you to 30 hours per month.",
        "url": "/2018/05/learning-to-learn"
      }
      ,
    
      "2018-04-c-mastering-the-basics-events-delegates": {
        "title": "C# - Mastering the Basics - Events and Delegates",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Delegates and Events are powerful tools in C#, but they can definitely be confusing in the beginning. Todays article covers the basics of this topic and helps you to get comfortable implementing this approach in your own applications.DelegatesI think, the main problem is that delegates are often explained unnecessarily complicated. For this reason, I want to give you an easily understandable introduction. Let’s look at a basic delegate declaration:private delegate void myDelegate(string a, string b);The declaration of a delegate looks very similar to a method declaration. In this case, the delegate looks like a method without a return value, but with two parameters, each of type string. The only difference is the keyword ‘delegate’ and the missing method body. Imagine delegates not as methods, but as references to methods.Let’s look at the following two methods:private static void SayHello(string yourName, string myName){  Console.WriteLine($\"Hello {yourName}, I am {myName}\");}private static void AppendStrings(string a, string b){ \tConsole.WriteLine(a + b);}It is not difficult to understand what these two methods do. Note, however, the signature of both methods: it is identical to that of the previously defined delegate. This means that the delegate can be used as a reference for the methods. The only decisive factor here is the type of the respective parameter, not the name.myDelegate del1 = new myDelegate(SayHello);myDelegate del2 = new myDelegate(AppendStrings);del1(\"Internet\", \"Marcel\");del2(\"Some\", \"Text\");To create this reference, a new instance of the delegate is created. The compiler creates a fully-fledged class from the delegate, which is why instantiation can be done as usual using the new keyword. As an argument, the delegate receives the name of the desired method. The referenced method can now be called via the instantiated delegate.Multicast DelegatesA strong feature of delegates, the so-called multicasting, enables the chaining of method calls. Let us illustrate this with an example:myDelegate del1 = new myDelegate(SayHello);myDelegate del2 = new myDelegate(AppendStrings);del1 += del2;del1(\"Hello\", \"World\");This will execute the stored methods for del1 and del2 using the arguments “Hello” and “World” for both methods. That is based on the so-called invocation list. Each delegate has such a list which holds references to all specified methods, which then are called when invoking the delegate.Delegate[] invocationList = del1.GetInvocationList();You can access a delegate’s invocation list using the GetInvocationList method. In this example, you will see that del1 has two entries here. The entries in the InvocationList are always made in the stored sequence.To conclude this chapter, I’d like to show you a way to change arguments as you work through the invocation list. Delegates can also have return values, but this is not helpful during the processing steps. When using chained delegates with return types, the result of the last item from the invocation list will be returned.The key is to use reference types instead of value types. Doing so, a reference, not a copy of the variable, is passed to the method. To achieve this, the parameters must be marked with the ref keyword. I adjusted the content of my SayHello() method to demonstrate the whole thing. After the text is printed to the console, the method removes all vowels from the yourName variable.private delegate void myDelegate(ref string a, ref string b);static void Main(string[] args){  myDelegate del1 = new myDelegate(SayHello);  myDelegate del2 = new myDelegate(AppendStrings);  string hello = \"Hello\";  string world = \"World!\";          del1 += del2;  del1(ref hello, ref world);}private static void SayHello(ref string yourName, ref string myName){  Console.WriteLine($\"Hello {yourName}, I am {myName}\");  yourName = new string(yourName.Where(c =&gt; !\"aeiou\".Contains(c)).ToArray());}private static void AppendStrings(ref string a, ref string b){  Console.WriteLine(a + b);}EventsEvents indicate the occurrence of an action. Imagine an event as a notification to all interested parties. The trick here is that the raiser of the event does not have to know about the parties that are interested in that (subscibers). When an event occurs, data can optionally be sent. In C# this is done using the EventArgs class or a derivation of that class.Events basically just encapsulate delegates. This is probably the point that took me the longest to embrace. I’m going to illustrate the whole thing with an example. With our current knowledge we can build the following application:public partial class Form1 : Form{  public Form1()  {    InitializeComponent();    Worker w = new Worker();    w.WorkCompleted += new WorkCompletedHandler(OnWorkerWorkCompleted);    w.Work();  }  private void OnWorkerWorkCompleted(int hoursWorked)  {    MessageBox.Show($\"Worker has been completed: {hoursWorked} hours worked.\");  }}public delegate void WorkCompletedHandler(int hoursWorked);class Worker{  public WorkCompletedHandler WorkCompleted;  private void OnWorkCompleted(int hoursWorked)  {    Console.WriteLine(\"Work Completed - Inside Worker\");    WorkCompleted?.Invoke(hoursWorked);  }  public void Work()  {    for(int i = 0; i &lt; 3; i++)    {      System.Threading.Thread.Sleep(1000);      Console.WriteLine(\"Working...\");    }    OnWorkCompleted(3);  }}I think you’ll quickly grasp what’s happening here, as well. The application launches and instantiates a worker object. The work method is called, which waits three time for one second and then outputs some information. Finally, the Delegate WorkCompletedHandler is called, to which the worked time is passed. The application now displays a message box and notifies the user that the work method has been completed. The only thing to remember here is the linkage of the OnWorkerCompleted method to the delegate’s invocation list.Let’s take a look at how that looks when using an event:public partial class Form1 : Form{  public Form1()  {    InitializeComponent();    w = new Worker();    w.WorkCompleted += new WorkCompletedHandler(OnWorkerWorkCompleted);    w.Work();  }  private void OnWorkerWorkCompleted(int hoursWorked)  {    MessageBox.Show($\"Worker has been completed: {hoursWorked} hours worked.\");  }}public delegate void WorkCompletedHandler(int hoursWorked);class Worker{  public event WorkCompletedHandler WorkCompleted;  private void OnWorkCompleted(int hoursWorked)  {    Console.WriteLine(\"Work Completed - Inside Worker\");    WorkCompleted?.Invoke(hoursWorked);  }  public void Work()  {    for(int i = 0; i &lt; 3; i++)    {      System.Threading.Thread.Sleep(1000);      Console.WriteLine(\"Working...\");    }    OnWorkCompleted(3);  }}Looks almost the same, right? As I said before, events are just wrappers for delegates. So theoretically you can use both versions I have presented. However, events are used for the same reason as properties are used: It is considered bad practice to expose fields directly. According to the principle of encapsulation, these are thus isolated from the outside. That is exactly the case here as well. Events are used to encapsulate access to delegates.The final thing I want to share with you in this article is the use of custom EventArgs. The.NET framework has a convention whereby a delegate type used for an event always takes two parameters. The first one is a reference to the object that triggers the event. The other one is an object of the class EventArgs or one that inherits from it. We want to create our own EventArgs inheritance that contains the hours worked. The following code does that for us:public partial class Form1 : Form{  public Form1()  {    InitializeComponent();    Worker w = new Worker();    w.WorkCompleted += new WorkCompletedHandler(OnWorkerWorkCompleted);    w.Work();  }  private void OnWorkerWorkCompleted(object sender, WorkerEventArgs e)  {    MessageBox.Show($\"Worker has been completed: {e.HoursWorked} hours worked.\");  }}public delegate void WorkCompletedHandler(object sender, WorkerEventArgs e);class Worker{  public event WorkCompletedHandler WorkCompleted;  private void OnWorkCompleted(int hoursWorked)  {    Console.WriteLine(\"Work Completed - Inside Worker\");    WorkCompleted?.Invoke(this, new WorkerEventArgs(3));  }  public void Work()  {    for(int i = 0; i &lt; 3; i++)    {      System.Threading.Thread.Sleep(1000);      Console.WriteLine(\"Working...\");    }    OnWorkCompleted(3);  }}public class WorkerEventArgs : EventArgs{  public WorkerEventArgs(int hoursWorked)  {    _hoursWorked = hoursWorked;  }  private int _hoursWorked;  public int HoursWorked { get { return _hoursWorked; } }}Wrap-UpDelegates are references to methods. The compiler creates a class when a delete is generated, instances of the delegate are then created as usual with the new keyword. Like methods, delegates can have a return type. Utiliting multicasting, delegates can be chained together, the call order is based on the delegates invocation list. Events are used to encapsulate delegates. Events usually use two parameters, the first being a reference to the trigger and the second an instance of EventArgs or an inheriting class thereof.",
        "url": "/2018/04/c-mastering-the-basics-events-delegates"
      }
      ,
    
      "2018-04-bypass-windows-media-creation-tool": {
        "title": "Bypassing Microsofts Windows Media Creation Tool",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Remember when you could simply download official Windows ISO images to burn on DVDs and install? Microsoft now uses this thing called ‘Media Creation Tool’ to download ISOs, but there’s a simple way to bypass this and download actual images.When searching for Windows10 ISOs, you’ll likely find this url, which provides a download for the Media Creation Tool.  https://www.microsoft.com/de-de/software-download/windows10But: there’s also this url  https://www.microsoft.com/de-de/software-download/windows10ISOHowever, when browsing this site on a windows machine, it automatically redirects you to the first of the pages I linked.If you’re not using Windows, you’ll be able to use the second url to download the ISO file directly.To be able to this on Windows as well, you’ll simply need to fake your browsers user agent header to make Microsoft think you’re using Linux (for example).That’s also pretty easy to achieve, there are many browser plugins available for this very purpose. Just search “user agent switcher” in your addon repository and you’re good to go!",
        "url": "/2018/04/bypass-windows-media-creation-tool/"
      }
      ,
    
      "2018-03-jekyll-search": {
        "title": "Searching Blogposts in Jekyll",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In one of my previous posts, I went over the details why I moved my blog from WordPress to Jekyll. So far, I really appreciate my new system, but I miss one particular feature: searching through my posts.Since Jekyll is a static site generator and does not rely on a database for the posts, you can’t simply add a search functionality like WordPress does. So, I have to work with some frontend / clientside stuff.After doing some research, I stumbled across lunr.js, a JavaScript-based text search library to use on the client side.I decided to give lunr a try and went on to add a search box to my main page. You can now see this in the very bottom of the screen. The is constructed as follows:&lt;form action=\"/search.html\" method=\"get\"&gt;  &lt;label for=\"search_box\"&gt;Search Posts&lt;/label&gt;  &lt;input type=\"text\" id=\"search_box\" name=\"query\"&gt;  &lt;input type=\"submit\" value=\"search\"&gt;&lt;/form&gt;When clicking the search-button, the user will be redirected to the search.html file. This site lists all matches and a search box containing the entered values. The search page consists of my regular header and footer. Also, of course, it contains a script which fetches all matching posts. It then lists all matches inside an unordered list. Of course, all scripts and pages are also located in this Blogs GitHub Repository, feel free to check it out!",
        "url": "/2018/03/jekyll-search"
      }
      ,
    
      "2018-03-sideproject-sist": {
        "title": "Sideproject - Sist!",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "It’s time to announce a new sideproject-launch!Some days ago, I’ve been looking for an app which allowed my to keep track of shopping lists in a simple and fast way. While there are lots of such apps available for Android, all I tested seemed to be overkill for what I really wanted. So I decided to create my own app for this purpose.Besides creating a simple app, my goal was to learn something new while developing the app. I decided to use Androids built in SQLite database to store lists. I’ve been using the database for previous projects, but I did not really care about the implementation. That being said, I wrote the queries all by hand which ended up being pretty messy.In my defense I would like to say that I was still at the beginning of my programming career and had no idea of the existence of things like object relational mappers.So I took a look around and decided to try Google’s Room for Android. If you’re not familiar with this project, feel free to checkout my article on the topic: Introduction to Room for Android.The result of one weekend now meets my expectations: A simple Android app that fulfills the functionality I want. Multi-list management with individual entries and a focus on simplicity and speed. A small detail is for example the automatic expansion of the keyboard when adding new entries.In addition to testing Room, I was able to try other Android features I hadn’t used before. These include controls such as CardView or RecyclerView.I would be very happy if you would test the app and submit feedback to me. As always, the entire source code is also available on GitHub and I’m always available for criticism and suggestions for improvement.  Download from Google Play  Sourcecode on GitHub",
        "url": "/2018/03/sideproject-sist"
      }
      ,
    
      "2018-03-moving-to-jekyll": {
        "title": "Moving to Jekyll",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "I decided that it is time for some changes. When I started this blog, I decided to use WordPress. My goal was to be able to write posts without having to focus on anything other than actual writing. Wordpress was the tool of my choice due to its simplicity.Nevertheless, I wasn’t always really happy with the CMS. Problems occurred again and again, mainly in connection with performance, loading times and general page speed. Not to mention incompatible plugins and various little things. I don’t want to discuss this here at all, I was simply looking for something faster.I don’t really like content management systems very much, I feel more comfortable when I am completely free in the design of my content. I’m also a fan of lightweight systems, a database-driven system only for managing content that I maintain on my own anyway, doesn’t really reflect this idea. However, completely discarding the CMS approach was not a solution, so I looked for compromises.I finally found the result of my search under the term “Static Site Generator”. The idea behind such generators is that you have the code of your page on your computer. You can add content in a simple and easy way, for example by writing markdown files. The generator than builds a full HTML page by combining predefined templates and actual content.There are many of these generators available, but one of the better known ones is called Jekyll. Jekyll is the software which GitHub pages uses as well. And that’s already a great positive aspect for Jekyll: You can directly integrate your website with GitHub pages and use it to add posts and general changes.Jekyll is based on ruby and I have to admit that I haven’t used ruby before. But it’s really easy to get started. I recommend getting started with a template, there are plenty on GitHub. After that, just check out the files and you’ll get an idea of how Jekyll works very quickly. This allows you to customize your template and make it look how you want it to.You can also convert your WordPress posts to Markdown by using the Jekyll Export Plugin. Just make sure that you don’t fuck up your images as I did.These are my first movements using Jekyll and I have a lot to learn. However, I want to get this live as fast as possible, I appreciate any feedback. Jekyll looks really promising, I’ll keep you updated.",
        "url": "/2018/03/moving-to-jekyll/"
      }
      ,
    
      "2018-03-sideproject-perfeggt": {
        "title": "Sideproject: Perfeggt",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Once again, it’s time to announce one of my side projects: Pefeggt – A boiling time calculator for eggs. Actually, I’ve been sitting on this one for quite a while and I decided to complete a working release this weekend. The app is built for Android and it helps you to calculate the perfect time you need to boil eggs to your preferred consistency.Functionality &amp; UsageTo calculate the time, I’m using Charles D. H. Williams formula from his paper “The Science of boiling an Egg”. This calculation requires the weight and temperature of the egg, the height above sea level at the place where it is cooked and the desired internal temperature of the egg to determine its consistency.To provide a better user experience, the user can provide the eggs weight in grams as well as the measurement in the form of sizes S (50 g.), M (58 g.), L (68 g.) and XL (75 g.). Alternatively, you can enter the weight directly. To specify the desired internal temperature, I have specified three possible selections to achieve either a soft, medium or hard result.Finally, it is necessary to state the current position regarding the altitude above sea level. This determines the boiling point of the water.After you have entered all the values and pressed the “Calculate” button, a second page will be loaded showing you the duration. Here you can now start a timer that exits the application. In the status bar you will now see a new entry indicating the time of completion. By clicking this entry, you can abort the countdown prematurely. As soon as the time has elapsed, the application will notify you with an alarm.I am looking forward to any feedback! The app is available in both PlayStore and Open Source on GitHub.",
        "url": "/2018/03/sideproject-perfeggt/"
      }
      ,
    
      "2018-02-introduction-to-i3": {
        "title": "Introduction to i3",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In today’s article I would like to give you an insight into the usage of a tiling window manager, which I will illustrate with the example of i3.A tiling window manager divides the screen into non-overlapping areas. You are probably more used to a stack-based system where windows can overlap. However, the concept of avoiding overlapping offers a major advantage: Due to the pure operation of the computer via keyboard, it is possible to work at a faster pace after a short training period.Of course, this is not everyone’s cup of tea, but I recommend you to give it a try. The Window Manager can be installed in parallel to your existing one and can be selected during the login process. Also, the installation doesn’t require much disk space (~2 MB).Installation &amp; SetupI’m using Arch in combination with the MATE desktop environment. My current window manager is marco, MATEs default which is based on Metacity. On Arch Linux you can install i3 via the package i3 in the official package sources. This should be the same for most other package managers, but if necessary consult the search engine of your choice for your particular case.After installing, you only need to log out and then log in again with the new Window Manager. You can usually define that using the small gear symbol. Of course, you can also set i3 directly as the default WM, but for testing purposes I prefer the temporary setup.Getting StartedIt’s time to get our hands dirty. After you have successfully logged in, you will be greeted by a simple screen with no content except for some status indicators at the bottom. On the first start you get to choose wether you want to create your own configuration or use the standard setup. I will work with the standard first.i3 is based on the use of a so-called mod key. This provides the basis for a large number of keyboard combinations. By default, either the Windows or alt key is used for this purpose.As promised, everything is now controlled by keyboard combinations. Let’s begin with the basic functions.  To create a new window, use Mod + Enter  To close the current window, use CTRL + d  Per default, windows will be added horizontally. To switch to vertical mode, use Mod + v  Use Mod + h to switch back to horizontal modeTo switch between open windows, you can use the following commands:  Mod + j to move left,  Mod + ; to move right  Mod + l to move up  And Mod + k to move downThe last shortcuts I’d like you to know are _Mod + _, where you can replace  by any number you want to switch between multiple screens. By pressing _Shift_ additionally, you can move the current window to the specified screen.Conclusion &amp; Further StepsWhile I think that these few commands will help you to get started with i3, there are far more available. I definitely recommend you to check out i3s official documentation, it’s great. And as always, just try everything out and have fun!",
        "url": "/2018/02/introduction-to-i3/"
      }
      ,
    
      "2018-02-getting-stuff-done": {
        "title": "Getting Stuff Done",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "While being fun, programming is not easy. To be able to dive into a flow state in which you’re completely focussed on the topic, you need to cut off all distractions. With this article I would like to introduce you to my methods of working in a more focused manner and give you some tips that might make your life much easier. My experiences mostly come from the programming area, but the following tips can be extended to various other topics.Consistency is KeyI have mentioned this point more often and I think it is the most important thing you should get used to.Building a habit is the most effective way to achieve real long-term visible progress. We are all just human beings and short-term lows (peaks as well!) will always be present. But if you really force yourself to do something regularly at the beginning, you will feel progress quickly. Additionally, it won’t feel forced in the long run, I promise.Investing Time != Being ProductiveOne thing I have been able to notice very much on myself lately is that the time brought in does not correlate with productivity. On the contrary, if I force myself to work long hours, I am often less productive than if I spend a comparatively short period of time working and filling the gap by doing sports before or after work.I must also say that I enjoy my work. One might think that this approach only applies to cases where this is not the rule.When working for longer periods of time, I will eventually lose my focus. Sport helps me to get fit again and allows me to think about my projects in parallel. Often times I had ideas for new apps or improvements of existing ones while jogging, which I probably wouldn’t have come up with when working stubbornly.So if you can’t get on with a problem, give yourself a little bit of fresh air in between and sit down again later with a clear head. I have noticed for myself that physical exercise, even if only half an hour, significantly increases my ability to concentrate afterwards. And hey, you’re doing something for your health, by the way.Done is better than PerfectThat was a point which I found extremely hard to apply. I have always regarded myself as a perfectionist, which has been very difficult for me when developing apps. I could never stick to an MVP. Whenever I thought of new features I wanted to have them implemented immediately. However, since I’ve really forced myself to first implement the basic functionality, to document ideas in parallel and then to implement them later in a sorted way, I don’t have 20 side projects that are not making any progress. Instead, each project has functioning interim results and I can fully focus one single thing.Don’t try to MultitaskJust don’t. It doesn’t work. Concentrate on one thing, do it and then move on to something else. It’s normal for the brain to wander and to come up with ideas. Write down these ideas and come back to them later, this will help you to get your mind free and to focus again.See other tasks as distractions, just like your mobile phone or TV. Of course you can switch back and forth between several tasks, but you always need a certain amount of time to find your way back into a topic. And that’s exactly the time you can save.For my part, I see the problem more when my own todo list is too full. The feeling of having to do a lot of things increases the temptation to do several things at the same time. To prevent this, it can be very helpful to plan the whole day in the morning. And not only in the style of a simple todo list, but with fixed start and end times. This can help you not to plan the day too fully and to calculate realistic time expenditure.TL;DR &amp; What to do nowThere are various ways to increase your own productivity. In this article, I have dealt with those who are the most important to me personally.First of all, I’m recommending you build a habit. Suppose you want to learn something, be it a new programming language or whatever: set yourself a fixed time period for it every day. Avoid any distractions during this period. Turn off your cell phone. Use addons like LeechBlock if you can’t resist the temptation to surf Reddit. And focus on the essentials, you can finish the final touches later.But also take time out and move between your sessions. If running is too boring or unproductive for you, listen to podcasts while you’re running.This subject is very personal and although I hope that my opinion will help you, I recommend you to browse through medium. You’ll find some great articles on this topic.",
        "url": "/2018/02/getting-stuff-done/"
      }
      ,
    
      "2018-02-introduction-to-room-for-android": {
        "title": "Introduction to Room for Android",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In the context of I/O 2017, Google released the Room Persistence Library, an intermediate layer between application logic and Android’s SQLite database. Using Room, you no longer have to handle stuff like network connection errors or caching yourself. Today’s article will help you get started with the library and teach you all the skills you need to implement Room in your own applications.Background of my sample applicationThe following code snippets are part of one of my side projects. This application manages shopping lists, which in itself can have entries. Actually, this is a very simple application, but it illustrates the functionality of Room very well.Room ComponentsThe structure of Room is based on three elements, which I will explain in detail below. These elements are the entities, data access objects and the database itself. While the purpose of the database should be clear, I would like to comment briefly on that of the other two.EntitiesEntities in general represent real things. Almost anything can be an entity. Think of a car, a house, yourself.I wanted to keep the application very minimalistic, which is why each shopping list only has a title and a timestamp. This allows the user to sort the list chronologically. The class for displaying entries has the same attributes, supplemented by a reference to a shopping list. This is already a bit strange, because this setup corresponds to that of a relational database. When working with object relational mappers, however, you would rather give each shopping list a list of entry elements directly. Room separates itself from this approach: Room doesn’t allow object references. Google covers this extensively in a dedicated article. Instead, you have to explicitly tell Room what parts you need.For this reason I will build my pojos according to a relational database schema. This results in the following schema:In Android, this schema can be translated to regular POJO classes. Using Java annotations, you can tell your class what elements should be treated in which way. The class which represents a shopping list looks like this:@Entity(tableName = \"shopping_list\")public class ShoppingList {    @PrimaryKey(autoGenerate = true)    public int id;    public String description;    @ColumnInfo(name = \"timestamp_seconds\")    public int timestampSeconds;    @Ignore    public List&lt;ShoppingListItem&gt; items;}As you can see, there are already multiple annotations. The first one is the @Entity annotation. It tells room that this class needs to be persisted to a database and what the name of the matching table will be. The next annotation is @PrimaryKey. You need to assign a primary key to each entity. Doing so, you specify a unique identifier to each of the tables entries. I added autoGenerate = true, so Room will be handling this matter for me.In general, I don’t recommend to use simple integers as primary keys, but that’s another topic. Also, for the sake of simplicity, I set the scope of all properties to public. When using private, Room requires appropriate accessor methods to these properties.Per default, room will use class and property names to specify the respective elements in the database. By using the @ColumnInfo annotation, you can customize these. The last annotation in this example is @Ignore, which tells room to ignore the property when loading or saving data.You can see another annotation when checking out the class representing an item inside a shopping list:@Entity(        tableName = \"shopping_list_item\",        foreignKeys = @ForeignKey(                entity = ShoppingList.class,                parentColumns = \"id\",                childColumns = \"list_id\",                onDelete=CASCADE))public class ShoppingListItem {    @PrimaryKey(autoGenerate = true)    @ColumnInfo(name = \"id\")    public int id;    @ColumnInfo(name = \"list_id\")    public int listId;    @ColumnInfo(name = \"description\")    public String description;    @ColumnInfo(name = \"timestamp_seconds\")    public int timestampSeconds;}As mentioned earlier, I’ve added a reference to the shopping list to each item. Since the id we specified for these is an automatically generate integer, we can simply access it here and store it as integer as well. By adding a @ForeignKey annotation, you’ll firstly need to specify the referenced class, followed by the referenced row. Complete the statement by specifying the column of the current class with which the join is to be done. In my case, this is the id column of the ShoppingList class and the list_id column of the ShoppingListItem class. Note that the names must match those of the table and you may have overwritten them with @ColumnInfo annotation.You can also customize the OnDelete action. If CASCADE is specified as an OnDelete action, all items in a list are deleted if the list itself is deleted.Data Access ObjectsThe next part we will cover are the DAOs. Data Access Objects allow you to interact between the database and the entity. And here’s the best part: they are very easy to implement. I have created two DAOs, one for the lists and one for the entries. In order to keep the whole thing a little bit short here, I’m just going to go into the DAO of my list.@Daopublic interface ShoppingListDao {    @Query(\"SELECT * FROM shopping_list\")    List&lt;ShoppingList&gt; getAll();    @Query(\"DELETE FROM shopping_list WHERE id = :id\")    void deleteListById(int id);    @Insert()    void insertList(ShoppingList shoppingList);    @Update()    void updateList(ShoppingList shoppingList);    @Delete    void deleteList(ShoppingList shoppingList);}A DAO is basically an interface that describes the interaction possibilities with the database. How exactly these look depends of course on your specific application. By specifying a Java annotation you can control the type of operation. In addition to the regular operations for creating, updating, or deleting objects, Room offers you the option of implementing your own queries using the query statement.Of course, you can also use parameters in your custom queries. To do this, simply enter the name of the parameter with a preceding colon in the query.In my final section, the database itself, I will show you how to combine the components and how to persist your objects.DatabaseTo interact with the SQLite database, you need to create a separate class that inherits from RoomDatabase and passes the connection details via @Database annotation. Google recommends using a singleton pattern, which I have implemented in my application.@Database(entities = {ShoppingList.class, ShoppingListItem.class}, version = 1)public abstract class AppDatabase extends RoomDatabase {    private static AppDatabase INSTANCE;    public abstract ShoppingListDao shoppingListDao();    public abstract ShoppingListItemDao shoppingListItemDao();    public static AppDatabase getAppDatabase(Context context) {        if (INSTANCE == null) {            INSTANCE =                    Room.databaseBuilder(context.getApplicationContext(), AppDatabase.class, \"shoppinglist-db\")                            .allowMainThreadQueries()                            .build();        }        return INSTANCE;    }    public static void destroyInstance() {        INSTANCE = null;    }}As you may have noticed, I explicitly allowed Room to perform database operations in the UI thread. Please note you should not release something like this in a production-ready application. Otherwise, longer running operations may block the user interface and have negative effects on the UX.The following example shows you how to retrieve data from the database.List&lt;ShoppingList&gt; shoppingLists = AppDatabase.getAppDatabase(getApplicationContext()).shoppingListDao().getAll();You can now perform all other operations in the same way. All information as well as advanced topics can be found directly on Google in the corresponding documentation.",
        "url": "/2018/02/introduction-to-room-for-android/"
      }
      ,
    
      "2018-02-using-androids-recyclerview-with-kotlin": {
        "title": "Using Androids Recyclerview with Kotlin",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Traditionally, you were using a listview to display several homogeneous elements in you Android app. However, this view is now deprecated. Android now offers an alternative, which aims to increase performance by only loading those elements, that are currently rendered on-screen: the RecyclerView.This article shows you how to get started with the RecyclerView. To make things a bit more interesting, we will be using Kotlin instead of Java.You can set up an Android project for Kotlin by simply clicking the checkbox for Kotlin support in the new project wizard.Preceding ConfigurationBefore you can use the Recyclerview in your app, a little preparatory work is necessary. The first thing you’ll need to do is to add this dependency to your modules build.gradle file:implementation 'com.android.support:recyclerview-v7:26.1.0'Basic GUI SetupThe next thing you’ll want to do is to set up a simple xaml page to display the view. I’ll be using a coordinator layout, which allows me to add a FloatingActionButton at a later stage.The snippets I use in this article are from my ShoppingList-App, which is basically a minimalistic app to save shopping lists. The user can add and remove items from shopping lists, multiple shopping lists can be used at the same time.&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;android.support.design.widget.CoordinatorLayout  xmlns:android=\"http://schemas.android.com/apk/res/android\"    xmlns:app=\"http://schemas.android.com/apk/res-auto\"    xmlns:tools=\"http://schemas.android.com/tools\"    android:layout_width=\"match_parent\"    android:layout_height=\"match_parent\"    tools:context=\"com.jurtz.marcel.shoppinglist.MainActivity\"&gt;    &lt;android.support.v7.widget.RecyclerView        android:id=\"@+id/rvShoppingLists\"        android:layout_width=\"match_parent\"        android:layout_height=\"match_parent\"        android:layout_margin=\"8dp\" /&gt;&lt;/android.support.design.widget.CoordinatorLayout &gt;RecyclerView Components: Adapter &amp; ViewHolderWhile it offers the advantage of improved performance, the RecyclerView is a bit more complicated to create and requires additional components. In our MainActivity class, the first thing to do now is to specify the RecyclerViews LayoutManager. This is required to define the appearance of the multiple items. I’d like to display them in a vertical list.rvShoppingLists.layoutManager = LinearLayoutManager(this)The next thing you’ll want to do is to set the views adapter. You can think of the adapter as a bridge between view and model which defines the appearance of your the POJOs.To implement the adapter, add a new class which inherits from _RecyclerView.Adapter_. As you can see, this class is generic and requires a ViewHolder, I&#8217;ve also created a custom class for this purpose. The following snippet shows the methods that need to be overridden.class ShoppingListAdapter(var shoppingLists: List&lt;ShoppingList?&gt;) : RecyclerView.Adapter&lt;ShoppingListViewHolder&gt;() {    override fun getItemCount(): Int {        return 5    }    override fun onBindViewHolder(holder: ShoppingListViewHolder?, position: Int) {    }    override fun onCreateViewHolder(parent: ViewGroup?, viewType: Int): ShoppingListViewHolder {            }}class ShoppingListViewHolder(val view: View) : RecyclerView.ViewHolder(view) {   }Note that I added 5 as return value for getItemCount(), you can leave this for now, we will see what this does in the next steps.Custom Layout for RecyclerView ItemsNow, we will add a new layout file (xml) to specify how each row in the RecyclerView should look like. For this purpose, I’d like to use a CardView with a nested LinearLayout that contains two TextViews. In my app, I’m using the first TextView to display a shopping lists description and the amount of items in the second one.&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;android.support.v7.widget.CardView xmlns:android=\"http://schemas.android.com/apk/res/android\"    xmlns:app=\"http://schemas.android.com/apk/res-auto\"    xmlns:card_view=\"http://schemas.android.com/apk/res-auto\"    android:id=\"@+id/cvRowEntry\"    android:layout_width=\"match_parent\"    android:layout_height=\"wrap_content\"    card_view:cardCornerRadius=\"4dp\"    android:layout_margin=\"8dp\"&gt;    &lt;LinearLayout        android:layout_width=\"match_parent\"        android:layout_height=\"wrap_content\"        android:orientation=\"vertical\"&gt;        &lt;TextView            android:id=\"@+id/lblShoppingListRowItemHeader\"            android:layout_width=\"wrap_content\"            android:layout_height=\"wrap_content\"            android:layout_margin=\"8dp\"            android:text=\"@string/rv_shopping_lists_placeholder_title\"            android:textSize=\"24sp\" /&gt;        &lt;TextView            android:id=\"@+id/lblShoppingListRowItemSubheader\"            android:layout_width=\"wrap_content\"            android:layout_height=\"wrap_content\"            android:layout_margin=\"8dp\"            android:text=\"@string/rv_shopping_lists_placeholder_subtitle\" /&gt;    &lt;/LinearLayout&gt;&lt;/android.support.v7.widget.CardView&gt;Now we want to link the view to the RecyclerView in the adapter. To do this, we will update the onCreateViewHolder method we overrode earlier.override fun onCreateViewHolder(parent: ViewGroup?, viewType: Int): ShoppingListViewHolder {    val layoutInflater = LayoutInflater.from(parent?.context)    val cellForRow = layoutInflater.inflate(R.layout.shopping_list_row, parent, false)    return ShoppingListViewHolder(cellForRow)}This tells the RecyclerView that each row should look like the layout we just created. If you have left the 5 in the getItemCount()-method, you will see that the view is displayed 5 times when running the app.Adding real DataOf course, that’s not all we want. Currently, we can display multiple instances of the basic view, but we want to be able to show actual data. This is where the ViewHolder comes in. Usually, you will have access to a collection of objects that will be displayed in the RecyclerView.In my snippet above, you can see that I already added a List&lt;ShoppingList?&gt; parameter to the adapters constructor. The ShoppingList class basically just contains a description  and a List of ShoppingListItem-objects, that again only have a description field.The first thing to do now is to update the getItemCount()-method to actually return the amount of available objects:override fun getItemCount(): Int {    return shoppingLists.size ?: 0}In the next step, we will link the object to the view, which is done by the following:holder?.bindShoppingList(shoppingList = shoppingLists.get(position))And, last but not least, declaring the views properties to the objects variable values:class ShoppingListViewHolder(val view: View) : RecyclerView.ViewHolder(view) {    fun bindShoppingList(shoppingList: ShoppingList?) {        view.lblShoppingListRowItemHeader.setText(shoppingList?.description)        var suffix = \"\"        var count = shoppingList?.items?.size ?: 0        if(count == 1) {            suffix = view.context.resources.getString(R.string.rv_shopping_list_items_suffix_single)        } else {            suffix = view.context.resources.getString(R.string.rv_shopping_list_items_suffix_multiple)        }        view.lblShoppingListRowItemSubheader.setText(count.toString() + \" \" + suffix)    }}That’s it! I added the following code to my MainActivity to test the adapter:rvShoppingLists.layoutManager = LinearLayoutManager(this)var list1 = ShoppingList()list1.description = \"Groceries\"var list2 = ShoppingList()list2.description = \"Clothes\"var list3 = ShoppingList()list3.description = \"Stuff for the apartment\"var list = listOf(list1, list2, list3)rvShoppingLists.adapter = ShoppingListAdapter(list) ",
        "url": "/2018/02/using-androids-recyclerview-with-kotlin/"
      }
      ,
    
      "2018-01-how-to-use-github-over-ssh-on-public-wifi": {
        "title": "Using GitHub over SSH on public WIFI",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "When using GitHub via SSH, port 22 will be used per default. However, often times you’ll see this port being blocked on public WIFI networks. On a Linux machine, there is a simple way to change the default port.To test if our plan works out, you can use the following command:&gt;ssh -T -p 443 git@ssh.github.comThis will test the ssh connection by using port 443. If this returns a positive result, you can change the port in your ssh config file.You can find the SSH configuration in ~/.ssh/config. To change the port, open the file and add a new entry for github, which will look like this:&gt;Host github.com  Hostname ssh.github.com  Port 443You can use whatever port you’d like. I’m using port 443, which is the default HTTPS port. That is also the one GitHub recommends to use in their documentation. Save your changes and you will be able to work as you’re used to.",
        "url": "/2018/01/how-to-use-github-over-ssh-on-public-wifi/"
      }
      ,
    
      "2018-01-c-mastering-the-basics-operator-overloading": {
        "title": "C# – Mastering the Basics – Operator Overloading",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Most of the built-in operators that are available in C# can be redefined. In todays article, I’ll be showing you how you can redefine operators to match your custom classes. Additionally, I’ll cover which operators actually can be overwritten.Redefining Operators To create custom functionality for operators in combination with your own classes, you’ll simply need to create methods matching a specific pattern. These methods require the usage of the keyword operator, followed by the actual operator you’ll want to overwrite.I’ve created a simple class to demonstrate the concept of operator overloading. This class represents a rectangle, which only has the two properties Length and Width.public class Rectangle{    public double Length { get; set; }    public double Width { get; set; }}I’d like to start by overloading the + operator. When this is applied to two rectangles, I want to receive a new rectangle where both width and length from both input objects are added. You achieve this functionality by adding the following method to the class Rectangle.public static Rectangle operator + (Rectangle a, Rectangle b){    return new Rectangle { Length = a.Length + b.Length, Width = a.Width + b.Width };}Quite easy, isn’t it? But of course, you’re not restricted to these simple operators, which is why I’ll cover all of the available operators in the next section.Another example I’d like to demonstrate is the comparison of two objects. In the following listing, you can see the comparison of two Rectangle objects with the operators == and !=.public static bool operator == (Rectangle a, Rectangle b){    return (a.Length == b.Length &amp;&amp; a.Width == b.Width);}public static bool operator != (Rectangle a, Rectangle b){    return (a.Length != b.Length || a.Width != b.Width);}(Non-)Overloadable OperatorsAltough a lot of operators can be overloaded, there are some exceptions. To give you a better understanding and overview of allowed operators, I’ve listed them in the table below.            Operator                  Description                  Overloadable                    +, -, *, /                  Basic arithmetic operations                  ✓                    ++, &#8212;                  Increment / Decrement                  ✓                    ~                  Bitwise complement                  ✓                    ==, !=, &lt;, &gt;, &lt;=, &gt;=                  Comparison                  ✓                    &amp;&amp;, ||                  Conditional logical operators                  ✗                    +=, -=, *=, /=, %=                  Assignment Operators                  ✗      ",
        "url": "/2018/01/c-mastering-the-basics-operator-overloading/"
      }
      ,
    
      "2018-01-install-magicavoxel-on-linux": {
        "title": "Installing MagicaVoxel on Linux",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "As a programmer with definite lack of visual skills, MagicaVoxel is a gift from God to create usable 3D models. Unfortunately, there is no installation option for Linux on the official website. With the help of Wine it is possible to use MagicaVoxel under Linux. And it really works great!Installation PrerequisitesAs I said you need to run Wine. As stated on their landing page, Wine is a compatibility layer that allows Windows applications to run under POSIX-compliant operating systems such as Linux, macOS and BSD. Instead of simulating internal Windows logic, such as a virtual machine or emulator, Wine translates Windows API calls into real time POSIX calls, eliminating the performance and memory degradation associated with other methods. Wine allows you to integrate Windows applications neatly into your desktop environment.You should be able to install wine using your distros package manager. On Linux Mint, that’s sudo apt install wine. Hint: If you’re on arch, you can skip this step. There’s an AUR package available (It’s also based on wine).Installing MagicaVoxelAfter installing wine, you can run .exe files from your terminal by entering wine ~/path/to/exe. All you have to do is download the windows version and store it somewhere save. In my setup, I use a folder in my home directory which contains all the files from the windows release. So, for me it’s wine ~/MagicaVoxel/MagicaVoxel.exe. You can also use this command to create desktop shortcuts.Of course, you’re not limited to MagicaVoxel, wine is capable of so much more. But never having it touched before, it really makes a great impression.",
        "url": "/2018/01/install-magicavoxel-on-linux/"
      }
      ,
    
      "2018-01-c-mastering-the-basics-lambda-expressions": {
        "title": "C# – Mastering the Basics – Lambda Expressions",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Are you one of the people who are easily intimidated by complicated-looking things? I felt a little bit like that when I saw lambda expressions for the first time. But let me tell you this: they really only look scary on the very first look. This article covers the basics of using lambda expressions and should be seen as quick introduction rather than extensive documentation.What are Lambda Expressions?Lambda expressions somehow belong to the anonymous methods. However, they are not called expression instead of method for nothing. They are therefore only similar, not identical. Under a certain circumstance, i. e. the assignment of a delegate, they can be used identically.By the way, anonymous methods are methods that cannot be called simply because of a missing name.Lambda expressions are often used when working with LINQ, but they are also applied in asynchronous programming.How can they be used?A lambda expression consists of three elements: the parameters, the Lambda operator and the statements. Any number of input parameters can be used. The number of instructions is also theoretically up to you, but in practice a limitation of three statements is widely accepted. Otherwise the readability of your source code will suffer. Moreover, Lambda statements are also meant for short inserts anyway.Enough talk, here’s an example:Func&lt;string, string, string&gt; concatShort = (x, y) =&gt; x + \" \" + y;Console.WriteLine(concatShort(\"Hello\", \"World\"));This basic example shows you how to create a method using lambda expressions. The input consists of two variables (x and y, name them whatever you want) and the method will concatenate two strings and return them. The third string entry in the Func&lt;&gt; signature is reserved for the return type.And that’s the most basic usage. There are some important rules, which I will wrap up in the following:  If you have only one input parameter, you can omit the brackets  The typing of the parameters is optional  If only one statement is used, the brackets AND the return keyword can be omittedAs you might be used to from LINQ, lambda expressions are only evaluated on execution. This means that variable values are interesting at the time of execution, not earlier. At this point it is equally important to say that it is possible to access variables which are available outside the lambda expression but within the method defining it. Let me demonstrate this:int variable = 0;Action print = () =&gt; Console.WriteLine(outerValue);variable = 42;print(); // Output will be 42Further Usage and ExamplesWhat exactly is the point of lambda expressions? Simply a shorter version of anonymous methods are no justification of a new construct in C#. And that’s the point. LINQ has given lambda expressions their right to exist in C#. Anonymous methods alone were no longer sufficient.If you simply assign a variable of the type System.Linq.Expression to a lambda expression instead of a delegate, you get the ability to analyze and generate it at runtime.The result of this is called “Expression Tree”, which has the important restriction to consist of only one expression. But that goes beyond the scope of this article.Let’s get back to the point: lambda expressions are used in many other areas. Let’s showcase some of them:The following example shows a method that accepts two integer arrays as parameter and returns their difference. So, the result is an integer array containing all items from a, that are not included in b. As you can see, there is only one input parameter and one statement, which allows me to omit the brackets.public static int[] ArrayDiff(int[] a, int[] b){  return a.Where(x=&gt;!b.Contains(x)).ToArray();}My second example checks wether a string is a pangram and stores this information as a boolean variable. A pangram is a sentence that contains each letter from the alphabet.bool isPangram = str.ToLower().Where(c =&gt; Char.IsLetter(c)).GroupBy(c =&gt; c).Count() == 26;",
        "url": "/2018/01/c-mastering-the-basics-lambda-expressions/"
      }
      ,
    
      "2018-01-debugging-xamarin-apps-on-physical-device-over-wifi": {
        "title": "Xamarin Debugging over WIFI",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Xamarin utilizes the Android Debug Bridge (ADB) for debugging on physical devices, which are usually connected over usb. While this feature definitely is useful, it would sometimes be more practical if you could do this over WIFI instead.Luckily, that is possible! You can simple switch between using USB and TCP/IP for debugging. To get started, you need to connect your device via USB to the computer you’re debugging from. I’m using Windows, so the commands I’ll execute the following commands from the commandline (which runs as an administrator), but since they are adb commands, they should be the same on Linux or macOS.The first command to switch from USB to TCP/IP is adb tcpip &lt;/code&gt;. Replace  with anything you like, I&#8217;ll use the same as Xamarin suggests in their [documentation](https://developer.xamarin.com/guides/android/getting_started/installation/set_up_device_for_development/), which is 5555. After this is done, you&#8217;ll want to connect adb to your device. To do this, you need its IP address, which can be discovered by going to _Settings_ &#8211; _WIFI_ &#8211; _More_ (the dots-symbol in the upper right corner) &#8211; _Advanced_.After you obtained the IP, connect to the device using adb connect :&lt;/code&gt;. After this step, you can disconnect the device from USB. When using adb devices, this should now list a device at the matching IP address. Visual Studio will now also display the devices IP address in the debugging window.To switch back from WIFI to USB, simply use adb usb.Since this is all based on ADB, debugging over WIFI is not restricted to use with Xamarin &amp; Visual Studio. You can also use this for regular Android apps that are developed with Android Studio! ",
        "url": "/2018/01/debugging-xamarin-apps-on-physical-device-over-wifi/"
      }
      ,
    
      "2018-01-advanced-git-git-stash": {
        "title": "Advanced Git - Git Stash",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In my introductory post on git, I told you that git uses three areas to track changes. Well, maybe I lied to you in this case. There are actually four areas available and I will cover this fourth area in todays post.The fourth area is called Stash. Basically, it works like a clipboard to which you can save current changes.Concepts of the Stash …Imagine the following scenario: You are working on a change. In the middle of your work you remember that you also wanted to do something else. This other change is important and should be handled immediately. However, it cannot be implemented with the uncomitted changes you are currently working on. In short, you need the status of the last commit, but you don’t want to discard your current changes and you also can’t commit them yet.This is where the stash comes in handy. The stash basically allows you to copy the changes that are located in your working area and index and stores them. It also checks out the latest commit so your working area and your index a re in a clean state. You can have multiple of such clipboard contents on your machine and you can restore each of them individually.… and how to apply themAll of the stash commands are initiated by git stash. To stash the current changes, use git stash save. For this, you can also simply use git stash without any suffixes. If you now use git status to view your changes, you’ll see that there are none available and your working area and index are in a clean state.You can then use git stash list to view all the contents of the stash. You’ll notice that each entry has an id, which can be used to restore an individual entry. Per default, the most recent entry will be used.To restore an entry from the stash, use _git stash apply _. This will restore the changes to your working area and index, but the entry will also remain in the stash. To clear all entries from the stash, use _git stash clear_.",
        "url": "/2018/01/advanced-git-git-stash/"
      }
      ,
    
      "2018-01-advanced-git-git-reset": {
        "title": "Advanced Git &amp;#8211; Git Reset",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In one of my earliest posts, I wrote an introduction to version control, more specifically: git. The topic I will cover today extends this article by a topic which is actually not that complicated. However, people seem to find it hard to deal with it and use it as a highway to StackOverflow.I talk about git reset. This command can be used to reset changes in your working area or to remove staged files from the index. I think that one of the problems here is the context-dependent functionality of the command. Another problem is the commands potentially disruptive character, since it can lead to data loss.Moving the current BranchIn general, you can split the commands functionality into two separate parts. First, the command will move the current branch. Let’s look at an example. In my current project, I’ve made some changes that I’d like to reset. In my example, my current commit 25a5d0e contains unwanted information and I’d like to return back to the state at commit ea02e01.Of course, this is a very simple example, git reset is not restricted to a single branch. I’d also like to mention, that this operation will lead to commits that don’t belong to any branch. In this case, git will automatically detect and delete them using its garbage collection mechanism.Copy FilesAs I mentioned earlier, the reset command moves the current branch (which is actually a pointer to a specific commit). The second part of its functionality is to optionally copy contents from the repository to the index (also known as staging area) and the working area.To specify where contents should be copied to, you can use the parameters –hard, –mixed or –soft. First of these copies the contents from the repository to both the index, and the working area. Appending –mixed will lead to the contents being copied only to the index, not to the working area. When using git reset without any parameters, this is what will be applied. The last option is to use –soft, which will prevent any content from being copied. In this case, only the branch-movement-part of the command will be executed.ConclusionWorking with git reset is easier than you think. Also, it’s definitely helpful to always think of the two components. Doing so, there is another a really cool feature that you may already have seen: You can use git reset to unstage files. Alternatively to git rm –cached, you can use git reset HEAD –mixed, which will overwrite the staged files.",
        "url": "/2018/01/advanced-git-git-reset/"
      }
      ,
    
      "2018-01-pgp-for-thunderbird": {
        "title": "PGP for Thunderbird",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Today, I’ll talk about how you can set up PGP for Thunderbird. PGP (Pretty Good Privacy) allows you to encrypt and digitally sign your emails. I wanted to publish this post for quite some time now and thanks to some help from the 34C3, I finally managed to do it.Pretty Good Privacy (PGP)Before we can start installing all the requirements and setting up PGP, I’d like to give you a short introduction to PGP. Basically, PGP is a tool to encrypt and digitally sign emails by applying public key cryptography. This means that you link your email account to a key pair, which can be used to encrypt and decrypt mails. Each of these key pairs consists of a public and a private key. Using those keys, you can encrypt and digitally sign your emails. Any person that knows your public key will now be able to use it to encrypt emails. On the other hand, you can use your private key to prove that you are the author of the email. Your private key will be used to decrypt mails encrypted with your public key and vice versa.To wrap this up: you have your email account set up to send and receive encrypted emails. Use your public key to allow other people to send encrypted emails, and use your private key to encrypt these or digitally sign emails. Any person that knows your public key can decrypt mails you signed with your private key. On the other hand, only you can read emails that were encrypted with your public key.One thing I have to mention altough is that PGP will not encrypt your whole message. The encryption only affects the mails content and attachments, but senders and recipients addresses, as well as the subject of the mail are still send in plaintext.Prerequisites and InstallationTo be able to send and receive encrypted emails, you need several components. First of all, you need an email client. I recommend using Thunderbird since it’s open source and works great with the PGP-addon I will cover in the next step.The second thing you will need is GPG (Gnu Privacy Guard). GPG is where the actual encryption happens. It is the basis for GPG.Last but not least, you need something to tie GPG and email client together. For this task, I use the Enigmail Thunderbird Plugin.I recommend starting off by installing Thunderbird and GPG. Depending on the platform you are using, you can either install GPG by downloading it from gnupg.org or by using your linux distros package manager.After you have Thunderbird and GPG installed, you’ll want connect Thunderbird to your email account. Note that a PGP key pair is linked to one email address, so if you want to use multiple, you’ll have to one key pair for each address.On this occasion, I’d also like to mention that you can of course still synchronize encrypted emails with your smartphones email client, but to encrypt them, you’ll need the matching private key. While you can use the same keys on both your phone and your pc, I recommend to really take your time thinking about doing this. When you lose your phone, attackers could gain access to your saved emails. Also, the security of a mobile phone is a completely different matter than the security of a PC. For this reason, I chose not to do this and to use encryption only on my computer.So much for that. The last thing you’ll need to install is the Enigmail addon for Thunderbird. You can do this by using the plugin manager built into Thunderbird. On linux distros, you can alternatively utilize your package manager (this works at least for Arch and Ubuntu).Setting up EnigmailThe next step is to set up a key pair and link it to an email account. You can access the Enigmail configuration by clicking on the hamburger menu in Thunderbird. Select the Enigmail entry by hovering over the arrow symbol, which displays a context menu. Select manage keys to proceed.The now displayed list contains all your locally saved keys. At this point, this list should be empty. To create a new key pair, select the Create entry from the menu bar and then click the New Keypair button. In the following dialog, start of by selecting the email address that the key pair should be assigned to. I recommend to set a password at this point, you can also specify how long you want the key pair to be valid.The key generating process will take a short amount of time. After the keys have been generated, you can specify wether you want to create a revocation certificate. These allow you to manually revoke the validity of your key pair. I recommend doing this, since a person that has gained access to your keys will not be able to use them anymore. You should store the resulting file in a save location and assign it a save password, since a person that has access to it could disable your PGP keys.Mail &amp; Key ExchangeWhen creating an email, you’ll notice the new enigmail-menu:As it is stated in bold red letters, the mail is currently not being encrypted. To change this, you can click the lock icon. To digitally sign your mail, click the pen icon right next to it. Of course, you can do both simultaneously. You can also send your public key as an attachment, but note that this will only be useful if you don’t sign your mail as the recipient will already need the key to encrypt the mail otherwise.You need the recipients public key in order to encrypt emails. There are several ways to exchange keys. One way are so called key servers. That basically is a service offered by enigmail, where public keys can be uploaded. Thunderbird then can utilize these servers to search for keys by email address.While this approach works quite well, there is one problem: You can’t be sure that the keys aren’t changed from a third party.The second option is to share keys via your personal website or any other channel. The best option regarding possible tampering would be to meet in person and exchange keys, but that’s not always a viable option. One way I recommend using is to provide public keys on as many ways as possible, simply to allow as many people as possible to find it.An additional tooling to prevent tampering, I recommend using fingerprints. This means that you can publish a hash of your key on a trusted way (business card etc.) which people can use to verify your public key.If you choose to not or not only use the key servers, you can export and import keys. To manually exchange keys, go to the key menu we used earlier. To export a key, right click the entry and select Export to file. If you want to import keys, simply use the File entry from the menu and import the file. The key will automatically be added to Thunderbirds key list and can from now on be used for the matching email address.To test your keys, I recommend simply sending an encrypted email to yourself and to verify it in your webmail client. The encrypted email will look like this:  —–BEGIN PGP MESSAGE—–Version: GnuPG v2  hQIMAzeTl89mQ+b4AQ//ae5T5gcqMLo/nBIQHNw+O/HSeyOI5Lg0nexgPpB44c8ZfdUSpRnfK02P6KPrFXSm5h+BZzCX020aVstwzhdvHpK3wiEvrzDUcURrWBJ9RRACAbM+r3+V7T017XOj8JIhsT+/NTKzZAqhZzRCC6DFL/cPYkS+n4+w1Hp817W5KIlJHdrMFUx64DSWDZ1ylNzrqMi102+tTBqqTqJIm36j8qRXzvQfjYPlxrGPq3DxEW9Segsw0iKvkTfw+/qdvVFHPYUn/suUJBe89ZD8nFNX9FVv0vCFj2t/IbA9jCKocHOX0JnxgYrrz31M7NuFJHlXzzYahn2Ebe9ruwtG5K159/ITZUpYLK7/yeuBXNgu1OED8hvBoq9hwqGt/f8C/lovumNDs8ALvyIzRyhVJ2Flxi2WqFo/7IJwCPfD6HsUpR2dtyZTQ0fFXyFkIOEb4+QjEW8jgtDS0s8M2Ew+30BvYQ3hiDsNuQ5H23VN6pX3fHY8F1k7B5fn0EHYPe2R1WbEqEG8qzN+elnM/yJ4OQVirytpFhYBgoDSTMFEQKneBHjjjHXVVk913sSZnlhQFteEznIwP4OjNoAizRNzfOCXMCyblcyA9XtstZ00VhbcsdUN+kNT53Ut5HdA38OqOzuGB410P1XXjGh0wrZ19s4Bdb38Ji+Gm7WdNyUbTY3mOCLSwLUBXyQHI9gaWSA4uKuBJ95BbKrKvl3EdLjWfvfZT192tuK1NLb9CVkEjCIDH4gqabkb13N3dFyEaKVkacjCQLGNYJ8OxxNP3l6WAodqYZ2+bS6AaHtLAkgJ7tfAKp7+k8y4XZRSXu15DaE9DQST1ofIaAmJCzcJtDrloQpmBnQJVAPVI4ah+VTrzB4Bfrqw/5bUcJD09jBsGayOucGNmfTgq0dnuODoEWpPK7faOppjbFC7lHEWgfE/sE9lFwWXVFQV7Y5DWoJWSSKf19Lk7L7f14GniO/ONBh5iMlPZ2Nmcwkw2zIs7NWyk8SZgDxrOCQ7jY28HEBVBWFF6oL+Tq8bqENBmf0W67Xnjc7zgjSKtOZl3jCePrQvp1PUvTpQDV6Q91RF8Gq8TGZmhZkqv8CNdQcPWPxjefqGr+uuDcLh8kYcBjISqTYjRvZWw8ckLid1jZe/8nmyCCXNB/ntXsYL4eo2SM0yb2lV8amV0cz9ru4khdWf=Q17/—–END PGP MESSAGE—–In Thunderbird however, it will automatically be decrypted. Note that you might need to enter the passwort you’ve set for the key pair before the mail can be decrypted.How to continueWhile this introduction hopefully gave you an idea on how to set things up and get started, I recommend not to stop at this point. There are two websites that I were introduced to and I’d like to share them with you. Both this, and this website offer a great overview of different topics regarding digital self-defense. Also, stay tuned for further updates on this website!",
        "url": "/2018/01/pgp-for-thunderbird/"
      }
      ,
    
      "2017-12-c-mastering-basics-advanced-statements": {
        "title": "C# – Mastering the Basics – Advanced Statements",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In todays episode, I’ll show you how to use three advanced statements in C#. I’ll go over the so-called null-conditional operator, the null-coalescing operator and the ternary operator.Null-Conditional OperatorYou can use the null-conditional operator to prevent _NullReferenceException_s. The basic principle of the operator is to return a value if it is not null, and return null if it is. The following code shows you how to use the operator, which is initiated by a question mark, followed by a dot.List&lt;String&gt; stringList = null;int? val = stringList?.Count;You can see the operator preceding the call of the Count-property. Running the code without the operator would lead to a NullReferenceException, but this way, null is assigned to the variable val instead.Null-Coalescing OperatorThe next operator is the null-coalescing operator. It is initiated by two question marks and it’s used to assign different values based on wether the first choice is null or not. To get a better understanding of this, let’s look at an example:int? val = null;int result = val ?? 0;The value of the variable val is assigned to result. However, if val is equal to null, result will receive the value 0.Ternary OperatorThe last operator in todays article is the ternary operator. It basically provides a short hand version for if-else-statements that can be written in a single line.Let’s look at the following example:int val1 = 1;int val2 = 2;int smaller;if (val1 &gt; val2){    smaller = val2;}else{    smaller = val1;}The if-statement takes up a lot of space while its logic is very simple. This can be replaced by the following code using the ternary operator:int val1 = 1;int val2 = 2;int smaller = val1 &gt; val2 ? val2 : val1;By using the ternary operator, you can simplify the assignment of variable by typing an expression that returns either true or false after the assignment operator. Complete the statement by a question mark. After that, the two values separated by a colon represent the values that will be assigned to the variable. The first one will be used if the statement is true, otherwise the second one is assigned.",
        "url": "/2017/12/c-mastering-basics-advanced-statements/"
      }
      ,
    
      "2017-12-octoprint-raspberry-pi": {
        "title": "Octoprint on a Raspberry Pi",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Being tired of running back and forth to my 3D-printer to change stl files and starting / stopping prints, I decided to give Octoprint a shot. Octoprint basically provides a webinterface for 3D-printers, which allows you to send tasks over your local network to the printer and to monitor the prints. The software also provides a plugin functionality, so you can create your custom addons if required.Note that you can use Octoprint for slicing, but in my case I will be starting of with only sending pre sliced stl files to print.Hardware &amp; InstallationIn this article, I cover the usage in combination with a Raspberry Pi. If you have a spare Raspberry Pi 3, I recommend using it, since it has built in WIFI. However, you can of course also use older versions with wired connection or by adding a WIFI adapter.If you don’t have anything installed on your pi, you can use OctoPi, which is a preconfigured image which includes Octoprint. However, since I already have raspbian installed, I’ll install Octoprint manually.As you can see in the installation guide, you’ll first need to install several packages for python. Of course, update your system first.sudo apt-get install python-pip python-dev python-setuptools python-virtualenv git libyaml-dev build-essentialAs soon as this is done, clone the repository from GitHub and run the installation script.git clone https://github.com/foosel/OctoPrint.gitcd OctoPrintvirtualenv venv./venv/bin/pip install pip --upgrade./venv/bin/python setup.py installmkdir ~/.octoprintAfter installing, you might have to update user configuration:sudo usermod -a -G tty pisudo usermod -a -G dialout piNow, you should be able to start the service:~/OctoPrint/venv/bin/octoprint serveYou should be able to connect to the web interface by using the pi’s IP on port 5000. After your first connect, you’ll face an installation page. These steps are useful if you want to setup custom slicing for octoprint. Since I slice my models in cura and send stl files to the printer, I’ll skip these steps.CustomizationI currently don’t have a webcam for my pi, so I won’t install webcam support. However, you can check out the instructions here if you’d like to do this.I’d like to set up my installation to automatically start when the pi boots up. These steps are also covered in the installation guide, but I’ll wrap them up. Start by copying the init script and adjusting its privileges to be executable:sudo cp ~/OctoPrint/scripts/octoprint.init /etc/init.d/octoprintsudo chmod +x /etc/init.d/octoprintsudo cp ~/OctoPrint/scripts/octoprint.default /etc/default/octoprintRemove the comment-symbol (#) from the DAEMON-line in your/etc/default/octoprintfile and add the script to your autostart withsudo update-rc.d octoprint defaults.Besides having automatic startup enabled, you can now start, stop and monitor the octoprint service withsudo service octoprint [start / stop / restart / status].Connecting to a 3D-PrinterWell, that last step is quite simple. In my case, my Anet A8 came with a USB type B cable which can be direcly plugged into the Raspberry Pi. And that’s it. After connecting to the printer, you can’t just only upload files and print them, you’re also able to see the files available on the printers sd card and restart older jobs.Closing ThoughtsWhile that first introduction gave me some insights on what octoprint is capable of, but I’ve definitely barely scratched the surface. One cool thing for example is the built in API, which allows you to connect for example Android apps to monitor temperatures or to upload files.All in all, I’ve had a great start with Octoprint and really recommend trying it out. Stay tuned for future updates!",
        "url": "/2017/12/octoprint-raspberry-pi/"
      }
      ,
    
      "2017-12-c-mastering-basics-extension-methods": {
        "title": "C# – Mastering the Basics &amp;#8211; Extension Methods",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In this series, I go over the very basics of the C# programming language. In todays guide, I will focus on writing custom extension methods for existing, prebuilt classes.You can use extension methods to add custom functionality to classes that are built by others. In my very case, I’d like to extend the functionality of the String class to set its first letter to upper case. I already implemented this functionality in my sideproject CryptoFolio, be sure to check out my article on the topic!As you can see in Microsofts documentation, extension methods are defined as static methods, but are called by using instance method syntax. This means that we will create a static method which can later be called by any object of the type String. _While the implementation of such a method is very similar to a regular method, there is one thing you’ll have to remember when writing extension methods: the _this keyword before the parameter. Let’s see an example of how this works:public static class StringExtensions {    public static String ToFirstLetterUpperCase(this String s)    {        if (s == null)            return null;        if (s.Length &gt; 1)            return char.ToUpper(s[0]) + s.Substring(1);        return s.ToUpper();    }}In the example, I’ve added a new class called StringExtensions. This is the place where I will store all of my custom exension methods for strings. As you can see, the method looks very normal, the only thing different is the previously mentioned this keyword right before the parameters data type.After creating the extension method, it can be used by simply calling ToFirstLetterUpperCase() on any string:String s = \"hello world!\";Console.WriteLine(s.ToFirstLetterUpperCase());// Output: Hello world!",
        "url": "/2017/12/c-mastering-basics-extension-methods/"
      }
      ,
    
      "2017-12-c-mastering-the-basics-collections": {
        "title": "C# – Mastering the Basics – Collections",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Altough the topic “Collections” matches programming in general, I’ve decided to add it to my series on mastering the basics of C#. For this reason, you will find some content here that is generally applicable, but I will also discuss different language-specific elements.Collections support several different use cases, e. g. searching through a set for objects with certain properties, or iterating through multiple elements by predefined sorting specifications.In the first part of this article, I will cover the two basic types of collections in C#, lists and dictionaries. Then, I will go over the groups of collections you might know from Java: lists, sets and maps. I’d like to describe and compare their characteristics and then implement their functionality in C#.Collections in CThe simplest form of collections in C# are arrays. An array allows you to store a group of objects of one specific type. The following example shows a string array, which contains three elements.String[] movies = new String[3];movies[0] = \"The Matrix\";movies[1] = \"The Dark Knight\";movies[2] = \"#9\";foreach(String movie in movies) {    Console.WriteLine(movie);}In this simple example, you can see the problem with arrays: the size of it needs to be known before adding the elements. The “real” collections in C# can be utilized to handle this problem.The basis of C# collections are List and Dictionary&lt;K,T&gt;, which will be covered in the following section.ListLists offer a way to organize objects in a similar way arrays do. Basically, you create a List of a specific type, which allows you to dynamically add and remove items from this list. Opposed to arrays, lists don’t need to specify the amount of objects they can contain, which allows you to dynamically change their size.The following snippet instaniates two new instances of the class “Person”, adds both to a list and outputs the value of Name-properties (the class consists only of this one property).List&lt;Person&gt; persons = new List&lt;Person&gt;();Person alice = new Person { Name = \"Alice\" };Person bob = new Person { Name = \"Bob\" };persons.Add(alice);persons.Add(bob);foreach(Person person in persons) {    Console.WriteLine(person.Name);}Besides adding items, the List class offers multiple useful properties and methods, such as Count to receive the amount of objects, Clear() to remove all items or Contains() to check if the list contains a specific object. Check out the [MSDN page](https://msdn.microsoft.com/en-us/library/6sh2ey19(v=vs.110).aspx) for full documentation.One last thing I’d like to mention is the option to access a specific item by its index, as you’re probably used to from using arrays.Dictionary&lt;K,T&gt;The second main type of collections C# offers is the Dictionary&lt;K,T&gt;. As the name suggests, it allows you to keep track of multiple objects by a unique key. Both object and key can be of whatever type you’d want it to be.The following snippet shows you how to create a dictionary with a string as key and a person as object. I’ve also added an int property named Age to the class Person.Dictionary&lt;String,Person&gt; persons = new Dictionary&lt;String,Person&gt;();Person alice = new Person { Name = \"Alice\", Age = 30 };Person bob = new Person { Name = \"Bob\", Age = 32 };persons.Add(\"alice\", alice);persons.Add(\"bob\", bob);Console.WriteLine($\"{persons[\"bob\"].Name} is {persons[\"bob\"].Age} years old\");// Output: Bob is 32 years oldAs you can see, access to a dictionary works like accessing an array by replacing the index with the key. However, you can still iterate over the contained items. At this point, you can choose wether you want to iterate over the dictionary items (key &amp; value) or just key or value.// Iterate over dictionary entriesforeach(var entry in persons) {    Console.WriteLine($\"Key: {entry.Key}, Name: {entry.Value.Name}, Age: {entry.Value.Age}\");}// Iterate over dictionary valuesforeach(Person person in persons.Values) {    Console.WriteLine(person.Name);}// Iterate over dictionary keysforeach(String key in persons.Keys) {    Console.WriteLine(key);}SetIn mathematics, a set is a collection of objects, which has two main criteria: there is no given order and each element of a set is unique.Of course, C# offers an implementation to cover such collections as well: [HashSet](https://msdn.microsoft.com/en-us/library/bb359438.aspx) is your way to go. HashSets offer high performance set operations on collections that can&#8217;t hold duplicate elements nor use a specific order.The following snippet instantiates a new HashSet of type Person and adds alice and bob to it. While you can add an object multiple times, it will be added to the set only once, which is why the output of the snippet will only display bob only once.HashSet&lt;Person&gt; persons = new HashSet&lt;Person&gt;();persons.Add(bob);persons.Add(alice);persons.Add(bob);foreach(Person person in persons) {    Console.WriteLine(person.Name);}ListCompared to sets, lists are very simple to describe. Lists contain a dynamic amount of objects, whereby an object can be contained multiple times. Also, the order of items in a list is important. The previously described List class already offers predefined methods to sort lists.Besides the List class, there are other variants of lists available, that serve different purposes. ArrayList stores data like an array does, and List basically is a wrapper for ArrayList. It allows you to access the list by index and is optimized for random access.Another option is LinkedList, which maintains pointers to the actual objects along with references to the next and previous item. This results in more work when adding or removing items from the list since each objects reference must be updated. Also, you can&#8217;t access a LinkedList via index. However, if you have heavy workload in the form of tail- or head-inserts, this might be your choice.MapThe term map is used in Java for collections, which are known as Dictionary under C#. I’ve already covered this type of collection in the first chapter of the article, but the conclusions will be wrapped up here.Dictionaries (or Maps) are used to associate objects to a unique key, by which they can be accessed later. One possible use case for dictionaries could be the association of user session ids with the users properties.To conclude this, you may choose to use a dictionary when you need to look up a value by a key. If you have an object like { key, value } and you need to access both, key and value without knowing them, you might prefer list.",
        "url": "/2017/12/c-mastering-the-basics-collections/"
      }
      ,
    
      "2017-12-getting-started-net-core-arch-linux": {
        "title": "Getting Started with .NET Core on Arch Linux",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Hello Internet! Today, we will try to develop and run .NET Core Apps on a Macbook running Arch Linux! Because what could go wrong!(Honestly, this went way better than I thought.)InstallationBefore we can start writing .NET Core applications on Linux, we need to install some packages. The Arch Wiki states that to run .NET Core applications, the dotnet-runtime package needs to be installed. Additionally, we will need dotnet-sdk-2.0 from the AUR to be able to develop custom applications.Besides these packages, I recommend installing Visual Studio Code as text editor. I currently use this as my main text editor and it offers a plugin for C# development. You can download it from the AUR as well and then run it from the terminal by entering the command ‘code’.Last but not least, if you’re getting started with VS Code as well, you can simplify your progress by using Microsofts cheatsheet (this is targeting windows users, but I’m sure you’ll be fine with it).To install the plugin, simply use CTRL + Shift + X and search for ‘C#’. You’ll find a package from Microsoft called C# for Visual Studio Code (powered by OmniSharp), which you’ll want to install.Hello World!After installing all the mentioned packages and plugins, you’re ready to start developing! You can use the built in terminal from VS Code and create a new project folder. Create a new folder wherever you want and use dotnet new followed by the type of application you’d like to create.I’ll start with a simple console application by entering dotnet new console. You can see all available options by entering the command without a project type.This command generates all the neccessary files to get started. The entry point of your project will be program.cs, which is already populated with the source code for a basic ‘Hello World’ – application.using System;namespace Dotnet{    class Program    {        static void Main(string[] args)        {            Console.WriteLine(\"Hello World!\");        }    }}You can now run your program by entering dotnet run inside your project folder. In this case, this will write ‘Hello World!’ to the terminal.One last thing I would like to cover in this post is the possibility to debug C# applications in VS Code.The installed plugins comes with integrated intellisense and debugging, which makes it very easy to develop apps. As you may be used to from Visual Studio, you can set breakpoints by clicking on the border to the left of the row number.To debug your application, you can use F5 or the the ‘Debug’ entries from the menu. If that does not work, you might have the program.cs file open directly, without the project folder. In this case, open the folder in VS Code, since it contains debug configuration.",
        "url": "/2017/12/getting-started-net-core-arch-linux/"
      }
      ,
    
      "2017-12-c-mastering-the-basics-comments": {
        "title": "Comments &amp;#038; how to use them",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Comments are used in a lot of programming languages. While this concept is useful for a lot of purposes, beginners often start bad habits when commenting their code. In this article I will explain when comments are useful and on the other hand illustrate problems where commenting can be less meaningful or even disturbing.Bad Comments …At first sight (especially at the beginning of your programming career), you might think of comments as the perfect way to describe elements of your code that you don’t fully understand. This approach is not entirely wrong, but it does have a few problems that I will now discuss.Comments as excuse for unreadable codeA problem of overly intensive commenting is the justification of illegible code. According to the motto “the code is not readable, but the commentary explains everything I need” the whole code quickly becomes unreadable and it takes a lot more time to understand its functionality. A simple example of this is the following code, which in the form of static methods offers the possibility to convert temperatures from Fahrenheit to celsius and vice versa.class Converter{    /* Celsius to Fahrenheit     * input: temperature in celsius     */    public static double cToF(double x)    {        return x * 9 / 5 + 32;    }    /* Celsius to Fahrenheit     * input: temperature in celsius     */    public static double fToC(double x)    {        return (x - 32) * 5 / 9;    }}A much better approach for this very simple example could be implemented like the following, which will work without any comments and will still be understood much better than the previous variant.class TempConverter{    public static double FahrenheitToDecimal(double fahrenheit)    {        double celsius = (fahrenheit - 32) * 5 / 9;        return celsius;    }    public static double CelsiusToFahrenheit(double celsius)    {        double fahrenheit = celsius * 9 / 5 + 32;        return fahrenheit;    }}Readability of the Actual CodeAnother important point you should consider is that comments can even decrease the readability of your code.  Of course, your source code will be hard to read if you have to read through ten lines of comments before each line of code. This of course a bit exaggerated, but the point becomes clear.This problem has to be considered especially in combination with the first one. By using comments to describe even the smallest of activities, there is a risk that source code will be poorly structured. Also, you’ll most likely spent less time thinking about naming things, which can reduce readability drastically.Code Changes and Obsolete CommentsThe last problem I would like to address is the change of code. The more comments written, the higher the probability of changing code and not adapting a descriptive comment. I’m sure that you are aware of this and probably stumbled across that topic more than one time.However, this is usually not a very big problem, since the source code itself explains how a method works, for example. This is more difficult if you depend on the content of the comments. Accordingly, this problem also combines with the two previous points.While source code typically changes quite quickly, comments often remain unchanged. If the comment now describes a functionality but is obsolete, this can easily lead to confusion.… and how to avoid themEnough of the problems that come with comments. Comments are by no means to be considered as ballast and are definitely useful. With this article, however, I want to create a certain basis to deal with this functionality in a more deliberate way.While comments are helpful to keep track of your thoughts, this tool should be used with thoughtfulness. Excessive use can easily lead to the opposite of the expected result. However, it is also important to note that the code alone is definitely not documentation enough. Of course, this does not mean that the entire project documentation should be in the form of comments, but the possibility of commenting on code should certainly not be ignored.All in all, I recommend that you think about the meaning of it before adding a comment. Are there other ways to communicate the content of the comment? Do I only use it to describe the functionality of a method? In this case, you should prefer to start with checking whether the naming of the components is clear enough. On the other hand, an argument for the use of comments could be the documentation of unexpected result values or the like, i. e. anything that is not quickly apparent from the source code itself.",
        "url": "/2017/12/c-mastering-the-basics-comments/"
      }
      ,
    
      "2017-12-validating-litedb-data-on-android-application-data": {
        "title": "Validating LiteDB Data from an Android App",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In my new sideproject CryptoFolio, which I announced in this article, I described that I’d like to use LiteDB to locally store data that I received from the coinmarketcap-API. LiteDB is basically a NoSQL database, in particular a document store. It functions on a serverless file basis and can be accessed via a simple API.While it is quite easy to implement the databases functionality itself, testing the resulting data structure is somewhat more difficult. But to be sure that my data is saved correctly, I needed a way to explore the database located on the android device. Therefore, I use the following approach:I start by downloading LiteDB Explorer, a free tool to visually inspect LiteDB database files. However, to view such a file, I need access to it first.You can do this by using the Android Debug Bridge (ADB). After enabling the developer options on your device, you can use the command adb backup -noapk com.your.packagenameto copy your applications data from the smartphone to the pc. Note that you can useadb restore backup.dbto go the opposite way, which can be useful for restoring application backups.After entering the command, you’ll have to confirm the operation on the device.  The backup will be copied to your home directory per default. As a result of this operation, you will receive an .ab-file. I recommend using ADB Backup Extractor, which you can download from SourceForge for free. This tool converts the .ab-file to a regular .tar-file, which can easily be extracted using a tool like 7-Zip.Use this command to convert your ab file:java -jar abe.jar [-debug] [-useenv=yourenv] unpack &lt;backup.ab&gt; &lt;backup.tar&gt; [password]Among the unzipped files you will now find the database file. Use the previously mentioned explorer to visualize it.",
        "url": "/2017/12/validating-litedb-data-on-android-application-data/"
      }
      ,
    
      "2017-12-sideproject-cryptofolio": {
        "title": "Sideproject: CryptoFolio",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Today I would like to introduce my current side project. I’m currently developing CryptoFolio, an app that allows you to keep track of your investments in cryptocurrencies.Functionality &amp; MVPThe first release of the application will allow you to view the current rates of the top 100 cryptocurrencies with the highest market capitalization. You can then add investments, where input, output and the date of the transaction is recorded.To address as many users as possible, I would like to support as many regular currencies as possible.On the main page you will find an overview of all your assets, which are displayed in the form of a list for each existing currency with total in- and output. On the detail view of each currency, I would like to display a similar list, which shows the transaction history.Technologies and basic ThoughtsTo implement the application I will work with Xamarin Forms. Basically, I prefer building native apps, but since I’m currently trying out Xamarin at work. Also, I’d like to gain new experiences, so I’ll try to realize the project using this technology.However, I need to answer some technological questions before starting development. Android offers SharedPreferences to store user settings. In this app, that functionality could be used to store the currency the user wants to use per default.Fortunately, there is a plugin from James Montemagno that implements this functionality for Xamarin Forms. The plugin is available under MIT-License and can be installed easily via NuGet.While this question clarifies a small part of the implementation, there are certainly more important problems: The data on the exchange rates of the cryptocurrencies must be obtained from somewhere. Also, I’d like to store the data locally in order to prevent unneccessary repeated loading.The probably best known website for collecting current exchange rates, coinmarketcap.com, provides an API, which seems to suite my idea just fine. To consume this API, I’d like to use ServiceStack, a framework I’ve already discussed in several articles.To store data locally, I want to use LiteDB. LiteDB is an Open Source NoSQL database, which allows to save JSON documents. This way, I can theoretically store the whole response objects which I receive from the API. LiteDB is also available under MIT license from GitHub and can be installed via NuGet.The last question I want to cover before development concerns usability and GUI design. I would like to use icons for the different currencies, but I am absolutely useless in the design of logos or icons. Fortunately, there are several icon packs available on GitHub. I have decided to use the Christopher Downers icon pack, which he provides under CC0 license. His icons are available in both color and black and white, making them suitable for a wide range of applications.Plans for future UpdatesBesides the first functions I plan to include more features in future releases. I am thinking here of the presentation of more detailed data, such as the price trend in the form of a diagram. Also interesting would be a kind of ticker, so that the rate data is updated on the go.",
        "url": "/2017/12/sideproject-cryptofolio/"
      }
      ,
    
      "2017-12-servicestack-logging-with-slack-integration": {
        "title": "ServiceStack Logging with Slack Integration",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Besides my series on how to get started with ServiceStack, I have already published a few articles that are related to the topic, but do not belong directly to the introductory series. In the last such article, I used the example of coinmarketcap.com to show how to access third-party APIs using the C# client.Today, I’ll show you how to use ServiceStacks Logging API and link it to a slack channel. The prerequisites for this article are an existing Slack account and a simple ServiceStack service (see my article on this topic).Creating the ServiceTo be able to integrate your service to Slack, you need to login to your Slack account and create a new Incoming Webhook. A default channel now needs to be specified. However, this will be overwritten by us later, so at this point the selection does not play an important role. After creating the webhook, Slack will provide an url that will be added to our logger in the next step.Slack logging requires the nuget package ServiceStack.Logging.Slack. Add this to your project in Visual Studio. As soon as the package is installed, the base of the project is done. Next, the service will be adapted. The following source code must be added to the Configure()-method of your AppHost class:LogManager.LogFactory = new SlackLogFactory(\"webhook-url\", debugEnabled: true){    DefaultChannel = \"logs\",    ErrorChannel = \"errorlogs\",    BotUsername = \"Sample ServiceStack Logger\"};Replace the first parameter with the URL of the previously created webhook and adjust the logger to cover your personal preferences. I use the channel “logs”as default for all messages, and “errorlogs” for all error messages. Similarly, a separate channel can be created for each logging type (debug, info, warning, error, fatal).Generating LogsAnd that’s it! The logger can now be accessed from any part of the program. While each type of logging has its own method, in slack there is no automatic differentiation between them apart from the different channel distribution.public static ILog Log = LogManager.GetLogger(typeof(MyService));Log.Info(\"Hello World!\");",
        "url": "/2017/12/servicestack-logging-with-slack-integration/"
      }
      ,
    
      "2017-12-query-coinmarketcap-api-using-servicestack": {
        "title": "Query Coinmarketcap API using ServiceStack",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In the first article of my series on using ServiceStack I mentioned the feature of the framework that the individual components can be used independently of each other.This short article is intended as an example of how the C# client can be used separately from a custom service to communicate with third-party APIs. If you would like to know more about the client specifically, you can read my article on this feature.Idea …I would like to use coinmarketcap.com‘s API to access statistics on different crypto currencies. The API documentation is available on the projects website. Within the scope of this article, there are two things I want to achieve: Querying all available currency data, which contains the 100 strongest crypto currencies in terms of turnover, as well as the targeted query of a single currency.We receive all the necessary information from the docs. These are the paths of the service as well as the structure of the objects we’d like to receive.I have decided to use Bitcoin as an example, which leads to the following two paths for use in the project:  api.coinmarketcap.com/v1/ticker/bitcoin/  api.coinmarketcap.com/v1/ticker/… And ExecutionSince we have no influence on the objects we receive from api, we have to adapt a class accordingly. In order to be able to design the properties according to my own ideas, I use the attributes [DataContract] and [DataMember], so that the properties do not have to be named identically to those of the API.[DataContract]public class CoinDTO{    [DataMember(Name = \"id\")]    public String Id { get; set; }    [DataMember(Name = \"name\")]    public String Name { get; set; }    [DataMember(Name = \"symbol\")]    public String Symbol { get; set; }    [DataMember(Name = \"rank\")]    public String Rank { get; set; }    [DataMember(Name = \"price_usd\")]    public String PriceUsd { get; set; }    [DataMember(Name = \"price_btc\")]    public String PriceBtc { get; set; }    [DataMember(Name = \"24h_volume_usd\")]    public String VolumeUsd24h { get; set; }    [DataMember(Name = \"market_cap_usd\")]    public String MarketCapUsd { get; set; }    [DataMember(Name = \"available_supply\")]    public String AvailableSupply { get; set; }    [DataMember(Name = \"total_supply\")]    public String TotalSupply { get; set; }    [DataMember(Name = \"percent_change_1h\")]    public String PercentChange1h { get; set; }    [DataMember(Name = \"percent_change_24h\")]    public String PercentChange24h { get; set; }    [DataMember(Name = \"percent_change_7d\")]    public String PercentChange7d { get; set; }    [DataMember(Name = \"last_updated\")]    public String LastUpdated { get; set; }}And that was actually the most complicated part. To obtain the data through the API, I directly specify the corresponding paths from the documentation, since we do not use request DTOs.public class APIClient{    private const String SERVICE_URL = \"https://api.coinmarketcap.com/v1/ticker/\";    public List&lt;CoinDTO&gt; GetAllCurrencies()    {        List&lt;CoinDTO&gt; response;        using (var client = new JsonServiceClient(SERVICE_URL))        {            response = client.Get&lt;List&lt;CoinDTO&gt;&gt;(\"/\");        }        return response;    }    public CoinDTO GetBitcoin()    {        List&lt;CoinDTO&gt; response;        using (var client = new JsonServiceClient(SERVICE_URL))        {            response = client.Get&lt;List&lt;CoinDTO&gt;&gt;(\"/bitcoin\");        }        return response[0];    }}Since the API always returns an array, I simply return the first element from the Bitcoin queries response. As promised, the implementation of an external service with the ServiceStack Client is quick and easy as usual. The concluding image shows the result of the query.",
        "url": "/2017/12/query-coinmarketcap-api-using-servicestack/"
      }
      ,
    
      "2017-12-c-preprocessor-directives": {
        "title": "C# Preprocessor Directives",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "You can use preprocessor directives in csharp to provide straightforward instructions to the compiler. For example, these directives allow you to execute certain code elements only under predefined conditions. Another possible field of use is simply the structuring of your source code into blocks, which can be folded in and out of Visual Studio.In this article I will discuss some of these directives. Preprocessor directives are always started with a #-symbol.#define &amp; #undefThe first two directives I would like to mention are #define and #undef. They are used to define symbols and remove them. Imagine such a symbol as a simple variable, the next elements will help to illustrate it as well. Note, that #define-elements need to be at the very top of a file, even above the using-statements!#if, #else, #elif  &amp; #elseThe next symbols are #if, #else, #elif and #endif. As you have probably already guessed, they are used to execute certain source code only under predefined conditions. And this is exactly where the symbols I defined in the previous section play a role. In the following source code I have defined a symbol, which is then checked for existence. According to this definition, the output “Running in demomode!” will be performed. You can also use the predefined symbol “DEBUG”, to check wether your application runs in debug or release mode.#define DEMOMODEusing System;namespace CompilerDirectivesDemo{    class Program    {        static void Main(string[] args)        {            #if DEMOMODE            Console.WriteLine(\"Running in demomode!\");            #else                        Console.WriteLine(\"Not running in demomode!\");                        #endif            Console.ReadLine();        }    }}VisualStudio automatically adjusts the display when saving, so that you can see directly in the editor which part of the if-statement will be executed.As just mentioned, it is possible to use predefined symbols. You can edit these settings if you go to project settings and check the build tab.#region &amp; #endregionThe last directives I would like to mention are #region and #endregion. These are used to split source code into related blocks.The code within such a block can be expanded and collapsed by the plus and minus symbols in Visual Studio, which are displayed next to the row number bar. An optional name following the #region-remark allows you to assign a name to each block.",
        "url": "/2017/12/c-preprocessor-directives/"
      }
      ,
    
      "2017-12-servicestack-authentication-and-authorization": {
        "title": "ServiceStack &amp;#8211; Authentication and Authorization",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "This is the fourth part on my series on how to get started using ServiceStack. Be sure to check out the earlier articles, if you haven’t read them already:  Part 1 – What is ServiceStack and why should I use it?  Part 2 – Building a Simple Service  Part 3 – Using the C#-ClientToday, I’ll be adding basic authentication and authorization to the project we’ve created over the last parts. As always, you can get the source code from GitHub.Authentication vs. AuthorizationTo be able to use authentication and authorization, we’ll first need to know the difference between both of these.Authentication basically means to provide a guarantee that you are who you pretend to be. Usually, such a functionality is implemented via username / password combinations.Authorization on the other hand is used to define, what a user is allowed to do. For example, you might be authorized to moderate comments on a forum.Authentication in ServiceStackTo authenticate a user, ServiceStack offers several options, check out the full documentation. Among others, the following methods are available.  Credentials (username &amp; password combination)  Basic Auth (HTTP Basic Auth)  Custom Credentials (Custom login implementation, uses username &amp; password combination)As I mentioned above, this list is by no means complete, I just picked some methods that I’d like to explain in detail in this article. Another option available is authentication via OAuth. This means that you can allow your users to authenticate themselves using their twitter, github, facebook or other accounts.HTTP Basic AuthI’d like to go over the detials of implementing authentication functionality by using the HTTP Basic Auth implementation of ServiceStack. The goal of the modifications of our sourcecode is to allow the transfer service only after successful authentication by the user.Do you remember the _Configure-_method of our _ExpenseTrackerAppHost-_class, which has remained completely empty so far?We’ll start with this one. The mentioned method servers the instantiation of plugins for ServiceStack. These include various modules that are built into ServiceStack, but which are only available after manual activation. An example of this is the API documentation with Swagger. We will use two such plugins: The AuthFeature-Plugin to enable authentication, and the InMemoryAuthRepository to be able to easily test our code without having to maintain actual users.The server configuration needs to be adjusted as shown in the snippet below. The first entry you see are the two mentioned elements. Next I created a user, which we can use to test the service.public override void Configure(Funq.Container container){    Plugins.Add(new AuthFeature(() =&gt;        new AuthUserSession(), new IAuthProvider[] {        new BasicAuthProvider() }));    var userRepository = new InMemoryAuthRepository();    container.Register&lt;IUserAuthRepository&gt;(userRepository);    string hash;    string salt;    new SaltedHash().GetHashAndSaltString(\"password\", out hash, out salt);        userRepository.CreateUserAuth(new UserAuth    {        Id = 1,        DisplayName = \"Marcel Jurtz\",        Email = \"jurtz@example.com\",        UserName = \"MJurtz\",        FirstName = \"Marcel\",        LastName = \"Jurtz\",        PasswordHash = hash,        Salt = salt    }, \"password\");}After the server has been configured, you’ll need to specify which routes require authentication. This is done simply by adding the [Authenticate]-attribute above the specific request-dtos class, like this:[Authenticate][Route(\"/Expense\")][Route(\"/Expense/{Amount}\")]public class Expense : IReturn&lt;ExpenseResponse&gt;{    public double Amount { get; set; }}The service now won’t return any valid data as long as the user is not logged in. This can be tested by using postman, which will return HTTP statuscode 401 (unauthorized) for any request. If, however, the “Authorization” option (oh, the irony) is activated in the header data, the login works.Custom Credentials AuthorizationAnother approach I’d like to cover is the implementation of a custom authentication mechanism. By extending CredentialsAuthProvider and overriding the methods TryAuthenticate and OnAuthenticated, you’re able to implement your very own login functionality, for example to match existing business logic. The following example simply checks for hardcoded credentials to demonstrate the basic functionality.public class CustomCredentialsProvider : CredentialsAuthProvider{    public override bool TryAuthenticate(IServiceBase authService, string userName, string password)    {        return userName == \"MJurtz\" &amp;&amp; password == \"password\";    }    public override IHttpResult OnAuthenticated(IServiceBase authService, IAuthSession session, IAuthTokens tokens, Dictionary&lt;string, string&gt; authInfo)    {        return base.OnAuthenticated(authService, session, tokens, authInfo);    }}TryAuthenticate() is used to test for valid login credentials, OnAuthenticated() will be executed after successful login. To test this, we use postman again. If you use your own mechanisms for authentication, it is necessary to send a request to /Authenticate first. Here, username and password have to be provided in the body-field. Once this request has been successfully completed, ServiceStack’s automatic session functionality provides access to our service as usual.Login with the C#-ClientOf course, you’ll want to be able to access the service with the ServiceStack C#-Client, which I introduced in part 3 of this series.ServiceStack offers an easy way to access username and password via the C# client. In the case of the BasicAuthProvider this works as follows:JsonServiceClient client = new JsonServiceClient(\"http://localhost:61401\") { UserName = \"MJurtz\", Password = \"password\" };In the case of a custom implementation, access via client is minimally more complicated:var authResponse = jsonServiceClient.Post(new Authenticate{    provider = \"credentials\",    UserName = \"MJurtz\",    Password = \"password\",    RememberMe = true});Authorization in ServiceStackAs explained at the beginning of the article, we differentiate between authentication and authorization. After the first part has been completed, we will now cover the second part.With regard to authorization in ServiceStack, there are two big points we want to consider: roles and permissions. With the help of permissions we can assign certain rights to individual users. Users can also be grouped into roles, which in turn have certain rights.Once again, ServiceStack offers a convenient way to manage rights. However, both options work very similarly, so I will not go into the individual elements in detail.In addition to the Authenticate request from earlier, services can be provided with additional attributes that control the access rights. For filtering to a certain role, this attribute is [RequiredRole (“User”)], the counterpart for the permission is [RequiredPermission (“DoSomething”)].We will continue the example with the BasicAuthProvider created at the beginning and assign rights to the user created there. This is similar in both cases.In addition to the Authenticate request from earlier, services can be provided with additional attributes that control the access rights. For filtering to a certain role, this attribute is[RequiredRole (“User”)], the counterpart for the permission is[RequiredPermission (“DoSomething”).We will continue the example with the BasicAuthProvider created at the beginning and assign rights to the user created there. Again, this is similar in both cases. To provide roles and permissions to a user, simply add the specific element either to the Roles- or Permissions-List.Roles = new List&lt;string&gt; { \"User\" }Permissions = new List&lt;string&gt; { \"DoSomething\"}As an alternative to my hardcoded roles and permissions, you can of course transfer them to constants or, for more practical purposes, to a database.#",
        "url": "/2017/12/servicestack-authentication-and-authorization/"
      }
      ,
    
      "2017-11-servicestack-using-the-c-client": {
        "title": "ServiceStack - Using the C#-Client",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "After we covered the basics of ServiceStack in part one and how to set up a service in part two of this series. Today we’ll go through how the C#-Client can be utilized to make communication between applications even easier. The sourcecode for todays article is available GitHub. If you missed one of the previous parts, feel free to check out Part 1 – What is ServiceStack and why should I use it? or Part 2 – Building a Simple Service.Implementation of the ClientFirst, we will need to add a new project to our solution. This will function as the client-side application. For the sake of simplicity, I decided to create a console application. After the new project has been created, we have to install the ServiceStack nuget-package. Another required step is to add a reference to our base project. This allows gives us access to the request and response DTOs.After the project has been set up, the C#-Client can easily be utilized. The following snippet is all that it takes to send a request to the service and save its response. Don’t forget to update the clients URL to match the address of your service.JsonServiceClient jsonServiceClient = new JsonServiceClient(\"http://localhost:61401\");var response = jsonServiceClient.Post&lt;ExpenseResponse&gt;(new Expense { Amount = 500 });In order to make the example a little more valuable, we will improve the service from the last part a little bit.Service Improvements: Using SessionsAs you can see in the following snippet, I have installed a session mechanism that manages the current requests. I specified a general total of 1000, whereby each request reduces this amount by the requested withdrawals. Also, each request increments the request counter. I limit the amount of withdrawals to the total amount available. If more money is withdrawn, the service will not execute the request and the user will be informed. To keep track of the session data, I created another class called TrackingData, which is shown below the Post-method of our service.public object Post(Expense request){    var Session = base.SessionBag;    var trackingData = (TrackingData)Session[\"Expenses\"];    if (trackingData == null)        trackingData = new TrackingData { TotalBalance = 1000, WithdrawalsAmount = 0 };    if(trackingData.TotalBalance &gt;= request.Amount)    {        trackingData.Withdrawals += request.Amount;        trackingData.TotalBalance -= request.Amount;        trackingData.WithdrawalsAmount++;        Session[\"Expenses\"] = trackingData;        return new ExpenseResponse        {            Amount = request.Amount,            Total = trackingData.TotalBalance,            WithdrawalsAmount = trackingData.WithdrawalsAmount,            Status = \"OK\"        };    }    else    {        return new ExpenseResponse        {            Amount = request.Amount,            Total = trackingData.TotalBalance,            WithdrawalsAmount = trackingData.WithdrawalsAmount,            Status = \"Balance too low\"        };    }}Let’s add some further modification to be able to increase our withdrawals. These modification reads a users input as long as he enters valid integers. When entering anything else, the loop will exit and the program stops.public class TrackingData{    public double Withdrawals { get; set; }    public double TotalBalance { get; set; }    public int WithdrawalsAmount { get; set;}With these adjustments it is possible to generate successive requests. After several requests, postman delivers a result similar to the following.{    \"Amount\": 200,    \"Total\": 600,    \"Status\": \"OK\",    \"WithdrawalsAmount\": 3}Further ShortcutsAnother small change I would like to make concerns the DTOs themselves. By specifying a return value using the IReturn interface, you do not need to specify the response type on the client side.[Route(\"/Expense\")][Route(\"/Expense/{Amount}\")]public class Expense : IReturn&lt;ExpenseResponse&gt;{    public double Amount { get; set;}    public class ExpenseResponse{    public double Amount { get; set; }    public double Total { get; set; }    public String Status { get; set; }    public int WithdrawalsAmount { get; set; }}This change allows the usage of the client by following notation:var response = jsonServiceClient.Post(new Expense { Amount = 500 });Final Updates for the ClientThe last change I want to make is to loop the user input, so that we can test the session mechanism in our console application. The following snippet waits for user input, as long as this input is a valid integer. If not, it breaks and the program terminates.JsonServiceClient jsonServiceClient = new JsonServiceClient(\"http://localhost:61401\");int userInput;while(Int32.TryParse(Console.ReadLine(), out userInput)) {    var response = jsonServiceClient.Post(new Expense { Amount = userInput });    Console.WriteLine(String.Format(\"Status: {0} - Withdrawals: {1} (Total: {2}, {3} Withdrawals)\", response.Status, response.Amount, response.Total, response.WithdrawalsAmount));}The program does not contain any logic yet, so you can mess with it in different places. However, this basic example shows how easy it is to set up the C#-Client for ServiceStack and how to use it. In the next part, we will cover the basics of authentication and authorization, which allows us to increase our services security.",
        "url": "/2017/11/servicestack-using-the-c-client/"
      }
      ,
    
      "2017-11-introduction-to-blockchains": {
        "title": "Introduction to Blockchains",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "What if there was a technology that could entirely change the basic elements of our society and our understanding of economy? This technology already exists and it is called crypto currency. Many people think of bitcoin when this buzzword comes up, but if you take a closer look, you will find out that the monetary point of view of the technology behind is only the tip of the iceberg.Bitcoin and crypto currencies are currently a highly controversial issue. Prices are rising and rising and the hype seems to be unstoppable, but influential personalities of the global economy are warning against putting too much trust into this technology. Whether they’re right about that or whether these antiquated idiots just want to hide their fear of computers with these statements is a mystery, which I won’t try to unveil here.What I would like to achieve with this article is the communication of the basic functioning of Blockchain technology and the associated possibilities and risks, so that you can see this technology not only as an investment, but also understand how it works.State of the artMoney exists for trading. In the last few centuries, trade has become complex – everybody trades with everyone, worldwide. In order to keep track of the transactions carried out, many different techniques of accounting. We use trusted third parties for this purpose, banks, for example.Bitcoin uses a network of computers for accounting. The transactions that have been made are not closed to the public, so the whole transaction history is publicly visible.As already mentioned, this article does not specifically refer to Bitcoin. However, since Bitcoin is a great example to explain the technology behind it, I will explain the functionality of a blockchain with this example in the following.Transactions in the form of bank transfers are normally carried out via banks. This third instance regulates that the recipient actually receives the money and the sender owns what he wants to send. Banks act as arbitrators for potential disputes, which increases the transaction costs for the participants.Another approach to handle transactions is peer-to-peer networks, which relinquish this third instance. Users communicate directly with each other, which results into a distributed network of equal nodes.The problem of such networks arises from possible fraud attempts by one of the participants, as there is no control authority as it exists in centralized systems.To conclude, you can say that the execution of a transaction in a peer-to-peer network is based on trust, which makes it easy to exploit.What Bitcoin does differentlyBitcoin is now trying to replace the requirement of trust with cryptographic proof. This combines the benefits of peer-to-peer networks (no/low transaction costs) with those of engaging a third party (non-fraud transactions).Each user possesses a certain number of coins (which can be divided into smaller parts). The interesting thing about this system, however, is that the Bitcoins themselves do not exist, only records of completed transactions. In order to be able to carry out a transaction, a user needs to own a wallet which can be considered a digital banking account. When a wallet is created, a private as well as a public key is generated. An address represents a shortened notation of the public key (several addresses can be derived from one public key). In order to receive Bitcoins, other users must send them to such an address. To receive Bitcoins on the other hand, you need to be in possession of the matching private key. There are various wallet providers that also offer different types of wallets, the website bitcoin.org offers a comprehensive overview regarding this topic.Once the user has set up a wallet, transfers can be sent and received. A transfer in the network works as follows: User A sends bitcoins to user B. A signs the transaction with his private key, allowing all network participants to verify the origin of the transaction using As public key. The transaction is executed publicly, so all nodes of the network are informed about them and can add them to their unconfirmed transactions.At this point, I have to distinct between active and passive network nodes. Active participants collaborate in the administration of the blockchain, bundle confirmed transactions and try to publish them based on the calculation of cryptographic evidence. Passive participants simply use the network to send and receive bitcoins. To confirm a transaction, the senders account balance must be known, which is possible for any account by knowing the senders address. For example, the website blockchain.info lists all transactions in real time, which can be filtered and searched. Also, this website can be used to check any wallets balance.To commit a transaction, the sender must reference other transactions, in which he received at minimum the same amount of bitcoins he wants to send. The active network participants, the so-called miners, then validate the referenced transactions for whether they have not already been issued and either accept or reject them. This mechanism makes it possible to establish an exact history of where the money comes from and where it goes.The example in the picture shows that a transaction can have several inputs. Inputs represent references to transactions the owner has received Bitcoins from, which he now wants to spend. However, transactions can also have multiple outputs. For example, if the output does not exactly match the input, the owner can transfer the difference to himself.Based on this principle, transactions can already be transparently traced back. However, a temporal component is missing. Miners are used for this purpose, which combine transactions from the network into blocks. All transactions within a block are considered to be processed at the same time.However, once a block has been created, miners must solve a task before sharing it to the network, which prevents individual miners to flood the network. This task is based on the computation of cryptographic evidence, which must be difficult to solve but easy to verify. Published blocks are checked by the receiving nodes for validity of the task solution, and if correct, they are added to the nodes local blockchain. The node then starts creating the next block in the same way. I won’t go into the details on the algorithm which is responsible for the cryptographic evidence, but it is automatically updated in a way that a block takes about ten minutes to be discovered.Miners are allowed to add a transaction out of nowhere to themselves to their block, which motivates the miners and ensures that more bitcoins come into circulation. The amount of bitcoins in these transaction is halved every four years and currently amounts to 12.5 Bitcoin.Problems and DrawbacksNow that the basics of blockchain technology should be clear, it’s time to discuss the problems behind it. The basis of the network is the presence of many equal participants. The problem is, therefore, when a network subscriber has a large part of the total computing power of the network, which can cause fake transactions to circulate.The so-called double-spending attacks are the spending of money that one does not possess at all. These attacks fall into this sector. Imagine you want to buy a car for Bitcoin. You agree on a price and transfer Bitcoins in this amount to the car dealer. The transaction will initially land in the unconfirmed transactions and you will receive the car. Now you create a second transaction in which you transfer the Bitcoins you have just paid for the car to yourself. If you are in possession of a major part of the network’s overall computing power, you are quite likely to find the next block. Now make sure that your second transaction is first recorded in a block and accepted by the network. If the other transaction is then considered by a miner for bundling, it will be rejected because you have already issued the referenced inputs.This problem has to be taken into account if the networks are rather small. However, there are also so-called mining pools in which miners join forces and try to find blocks together. In the event of success, the reward will be distributed to all participants. This may sound good, but depending on the size of the pool, it can also be used by its operators for double-spending attacks.A further problem, especially with Bitcoin, is the basis on computing power to confirm a block. Due to the high number of nodes, immense computing power is used for the generation of blocks, which does not achieve a direct result and is therefore often regarded as a waste of energy.Bitcoin technology is also poorly scalable because blocks have a limitation on the size of the transactions they can contain. since a block is found every ten minutes, the amount of unconfirmed transactions accumulates if many network participants want to carry out transactions. By designing transactions with greater input than output, transaction fees are generated, which are treated preferentially by the Miners, as they are allowed to assign the difference to themselves. However, this contradicts the principle of lower transaction costs as explained above.ConclusionBitcoin is by far not the only blockchain technology, but certainly the best known. The solution to the problem of high energy demand has been taken up by various other technologies and is trying to attract attention with appropriate publications. The same goes for the other problems described above.A large number of crypto currencies are now in circulation, coinmarketcap provides an overview of market capitalization. In addition, there are various projects for different niche areas, with the idea of a currency rarely being its main objective. Each of these technologies has its own advantages and disadvantages, and each of them could easily fill the length of this article. If I have been able to arouse your interest with this article, I therefore advise you to take a look at the overview list and look for interesting entries yourself.",
        "url": "/2017/11/introduction-to-blockchains/"
      }
      ,
    
      "2017-11-servicestack-building-simple-service": {
        "title": "ServiceStack - Building a Simple Service",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "This is the second post in my series on building web services with ServiceStack. In the first part, I covered the benefits of using ServiceStack, this article continues with the setup of a basic service and its several components.In this and the following parts I will create a simple example project to illustrate the use of servicestack. This project will be an expenses tracker. In this part, we will develop the functionality to add expenses and establish an overall balance. In the following part we will combine them with the C# client.The source code for this and the following parts can be found in this GitHub repository, where I will create a separate folder for each article. Since this is the second part of the tutorial, you’ll find the source code for todays article in the folder Part_2_Basic_Service.ServiceStack Service ArchitectureBefore we can create our first service, we need a basic understanding of how these work in ServiceStack. Basically, each service consists of three elements: a request, a response and an actual service. The request describes the object which is sent to the service, which proceeds the request and returns a reponse. We’ll add a simple service to our project in the next step.Setting up the ServerLet’s get right into development, where we’ll start with the implementation of the server. Start by creating an empty ASP.NET web application in Visual Studio. There are some things you’ll want to do now: First of all, install ServiceStack via nuget package manager. After that, adjust your web.config file so that it matches mine:&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;!--  Informationen zur Konfiguration Ihrer ASP.NET-Anwendung finden Sie unter  https://go.microsoft.com/fwlink/?LinkId=169433  --&gt;&lt;configuration&gt;  &lt;system.web&gt;    &lt;httpHandlers&gt;      &lt;add path=\"*\" type=\"ServiceStack.HttpHandlerFactory, ServiceStack\" verb=\"*\"/&gt;    &lt;/httpHandlers&gt;    &lt;compilation debug=\"true\"/&gt;  &lt;/system.web&gt;  &lt;!-- Required for IIS7 --&gt;  &lt;system.webServer&gt;    &lt;modules runAllManagedModulesForAllRequests=\"true\"/&gt;    &lt;validation validateIntegratedModeConfiguration=\"false\"/&gt;    &lt;handlers&gt;      &lt;add path=\"*\" name=\"ServiceStack.Factory\" type=\"ServiceStack.HttpHandlerFactory, ServiceStack\" verb=\"*\" preCondition=\"integratedMode\" resourceType=\"Unspecified\" allowPathInfo=\"true\"/&gt;    &lt;/handlers&gt;  &lt;/system.webServer&gt;&lt;/configuration&gt;The next step is to add a global.asax file. Do so by right-clicking your project – add new item – global.asax. In this file, the service going to be instantiated. However, you’ll  first need a service which can be instantiated. Let’s do so by adding our service class: ExpensesService.cs. This service is created as described in the previous section:public class ExpensesService : Service{    public object Post(Expense request)    {        return new ExpenseResponse        {            Amount = request.Amount,            Total = 500,            Status = \"OK\"        };    }}public class Expense{    public double Amount { get; set; }}public class ExpenseResponse{    public double Amount { get; set; }    public double Total { get; set; }    public String Status { get; set; }}This service basically takes an amount as input for its request, and returns a new response object with a Total of 500 and the status “OK”. Of course, there is no logic in here currently, this will be added later. For now, we’ll just want do get the service running.Another thing which we need to set up is the previously created global.asax file. Simply add the following code inside the AppHostBase-class (the overriden class should already be there, you don’t need to set this up manually).public class ExpenseTrackerAppHost : AppHostBase{    public ExpenseTrackerAppHost() : base(\"Expense Tracker\", typeof(ExpensesService).Assembly) { }    public override void Configure(Funq.Container container)    {        // Configure Application    }}protected void Application_Start(object sender, EventArgs e){    new ExpenseTrackerAppHost().Init();}The Meta PageBy now, the service should be able to run. When starting the project, you should be able to see a window like the following:This overview provides information on all available services in our application. By clicking on the JSON-entry of the Expense-Operation, information about the service is displayed.As you can see, this gives plenty of information on the service, including its route (/json/reply/Expense), its HTTP-verb (POST) and its parameters. Also, it shows us how the response-object will look like.Testing with PostmanTo try this out, I use a tool called Postman, which you can download as extension for chrome, but I recommend the standalone version, since the plugin is outdated. Postman allows us to test our routes and objects with the several HTTP-verbs and optional parameters.As you can see in the image, I set the HTTP-verb to POST and added the previously noted route. I also added an “Amount”-parameter, which ServiceStack then maps to the POCOs pendant. The response we get displays pretty much what we’ve expected.Adjusting the RoutesOne thing that bothers me here, is the fixed route which looks pretty ugly. We can adjust this by adding a [Route]-Attribute to our service.[Route(\"/Expense\")]public class Expense{    public double Amount { get; set; }}You can also specify multiple routes for one object, by adding curly braces you can add variables. If you want a variable to be optional, simply add an asterisk after the variable name. In the following example, both routes could be combined that way.[Route(\"/Expense\")][Route(\"/Expense/{Amount}\")]public class Expense{    public double Amount { get; set; }}Finally, note that ServiceStack doesn’t recognize the format any longer with these custom routes. To clarify, what format you’ll want to receive, simply add its ending to the route, like this: /Expense.json.So that’s it for todays post, the next one adds the C#-Client to easily communicate between C#-applications!",
        "url": "/2017/11/servicestack-building-simple-service/"
      }
      ,
    
      "2017-11-csharp-architecture-basics": {
        "title": "C# &amp;#8211; Mastering the Basics &amp;#8211; Application Architecture",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In this series, I discuss the optimization of the basics of programming in C#. This article deals with the basic structure of an application and its different components.C# Application ArchitectureThe top level always represents the so-called solution. A solution can contain several different projects, whereby a project can be used by different solutions, which allows to reuse source code. Each of a solutions projects compiles into either an executable or a dll.The following image shows the structure of an example solution and its components.The application is divided into three levels: user interface layer, business logic layer and data access layer. The latter is usually realized by an object relational mapper like the entity framework or ORMLite, which I presented in my last post. The UI layer contains the user views. These can be several projects, for example in the shape of a legacy WinForms application and a newer WPF implementation. The user interactions detected there are passed on to the business logic layer, which contains the actual logic of the software and the related POCOs.To clarify this approach, projects of the Business logic layer are usually defined as class library projects, projects of the ui layers for example as WinForm.The same logic is often required in more than a single application. An email functionality or the sending of push notifications would be conceivable. Such elements can be outsourced and referenced by multiple applications. These elements are located in the commons block.Types of C# ClassesAccording to this division, the connected classes must also be divided into several groups. A class is generally a template for an object that can be imagined as a casting mold.For this purpose I differentiate between the types UI class, Domain entity class and library class. The UI class is the class that is automatically generated when a form is created. It is used to pass user interaction to the business logic. In addition, such a class can be implemented in the form of a ViewModel if it is developed according to the design pattern MVVM.The domain entity class is used to describe entities in the business logic. Such a model therefore describes, for example, a customer or vendor, usually in the shape of a simple POCO. This also includes any repository classes that manage the matching entity classes in memory.Finally, library classes represent classes that can be dynamically loaded and provide additional functionalities. These could be third-party libraries or components from the previously mentioned commons area.",
        "url": "/2017/11/csharp-architecture-basics/"
      }
      ,
    
      "2017-11-what-is-servicestack": {
        "title": "What is ServiceStack and why should I use it?",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "This article is the beginning of a series of articles in which I want to discuss the basics of building web services and designing REST APIs using ServiceStack. This first article discusses the question of what ServiceStack is all about, the benefits of it, and why you should use (or at least try out) this framework. The following articles will then discuss the design of a simple service by using a simple example to illustrate the various possibilities it offers. Each chapter ends with a summary to provide a quick way to look up previous sections.If you can’t wait to get started, you might checkout this or this article, which I published earlier.What is ServiceStack?ServiceStack is basically an open source framework for creating web services based on Microsoft’s. NET framework. The first thing I would like to mention is the excellent documentation. You’ll find all the information you might need on the project’s website. This also applies to the feature overview, which I’m summarizing with this article.ServiceStack offers an alternative to the design of web services with WCF, MVC &amp; Web API. It  may be less configurable than these, but offers improved performance on the other hand.Another decisive argument the frameworks principle to streamline applications. The API itself is almost invisible later on, the focus lays on the POCOs. Accordingly, the creation of Web services with ServiceStack is quite simple and does not require any immense training effort. This simplicity is evident, for example, in the free choice of available formats. You can switch between displaying objects in XML and JSON (or others) without using your own logic.Finally, ServiceStack runs under. NET and Mono, so it can be deployed on a Linux server. IIS is not mandatory. The underlying database is also selectable, supported according to the current documentation are MSSQL, MySQL, PostgreSQL and SQLite.Why should I use it?As the name suggests, ServiceStack is not a specific project, but consists of different building blocks. This stack consists of serializers, service endpoints, an IoC container, ORM and caching. This means that web services do not have to integrate further libraries and can be implemented completely with servicestack. The modules are also independent of each other and can therefore be exchanged or used individually.For example, the fast serialization mechanism can be used as a standalone tool. On the other hand, corresponding other elements can be integrated into ServiceStack, for example, the Entity Framework can be used instead of the integrated object relational mapper, ORMLite.This independence of the components allows a very detailed adaptation to your own specific needs. The following three components should explain this principle a bit more clearly.ServiceStack.TextThis element provides the serialization functionality, which is described very well on the projects GitHub page. The library allows fast serialization and does not contain any other dependencies. Among other things, it consists of serializers for JSON, JSV and CSV and the associated auto mappers.ServiceStack.ORMLiteORMLite also has a well-documented page at GitHub, which describes the project as a set of light-weight C# extension methods to be able to map a POCO class 1:1 to an RDBMS table, cleanly by conventions. Simplicity and lightness are the focus here too.ServiceStack.RedisThe last element I would like to mention here is ServiceStack.Redis, a C# client for the NoSQL database (Key-Value-Store) redis. Even if the actual ServiceStack features are not used, this project allows a comfortable access mechanism to the database.SummaryIt is difficult to put a precise definition of ServiceStack into words, so I give my best to clarify this in the following articles by demonstrating concrete examples of the way this project works. In any case, it is clear that the framework offers a fast, convenient and easy way to develop web services for communication between applications in C#. The availability of Xamarin extends this to mobile devices, which adds even more possibilites.",
        "url": "/2017/11/what-is-servicestack/"
      }
      ,
    
      "2017-11-support-multiple-screen-sizes-on-android": {
        "title": "Support Multiple Screen Sizes on Android",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Android runs on a variety of different devices. In order to improve the way your app looks on different phones, depending on their screen size and resolution, Android offers the possibility to use different layouts for different screen sizes. This is the topic I’ll discuss in this article.Summarizing the Demo ApplicationFirst of all, I would like to briefly discuss the app, the optimization of which will be discussed below. The app serves as a tool for the card game “Magic the Gathering”. While this app was my first real application for Android, this side project has evolved over time and accompanied me on the way to Android development. I maintain the sourcecode on GitHub and you can download the app via PlayStore.The feature at issue is simply managing the health of two players. Poisonpoints can also be managed, which use a similar functionality. Finally, the player can choose the color of his or her playing area using the appropriate controls.The Problem …So far, so good, this functionality has proven itself since the first release version of the app. But with the changes I’m working on, I’m about to implement an optional 4-player view. Of course, there is not unlimited space on a smartphone screen, which is why I had problems with the display of all of the controls in the style of the 2-player version. When using smaller devices (in terms of pixel density), the image buttons that allow the player to select his background color moves over the lifepoints and the Poisonpoints are displayed too close to the edge of the screen, so that the whole app doesn’t really look good.However, while this view is problematic for smartphone screens, tablets work quite well. For this reason, I would like to maintain the view for tablets, but adapt it for smaller devices. To make this description more specific: My 10-inch tablet should use the default view, while my Redmi Note 4 (5.5-inch) and my Nexus 5 (5-inch) should use the customized view. All three devices have a Full-HD display with a resolution of 1920 x 1080 px, which allows easy comparisons between them. The Redmi Note 4 should additionally be used as the maximum size for the customized layout, since the view is no longer really shifted here, but still looks quite suboptimal. The following picture shows the planned layout for the 4-player support.… and its SolutionThis post on the Android developer documentation gives a pretty good overview on the different screen sizes and the pitfalls to be considered. Basically, two factors play an important role: The physical screen size of the device (inches) and its pixel density. The various influencing variables then aggregated to groups. While this separation for screen sizes is divided into the values small, normal, large and xlarge, the following values exist to categorize the pixel density:  ldpi ( ~120dpi)  mdpi ( ~160dpi)  hdpi ( ~240dpi)  xhdpi ( ~320dpi)  xxhdpi ( ~480dpi)  xxxhdpi ( ~640dpi)And it’s exactly these different categories that are interesting now: Low resolution means little space for placing controls, so I’m going to design a special representation for such devices. You can create layouts separately for different screen resolutions, so the above categories can be controlled individually.I want to realize my idea as follows: devices with high screen resolutions should display the four-player view similar to the two-player view. All devices that are smaller will use a fallback layout which adds a little functionality. Here, the display of life- and poisonpoints should be hidden by pressing the setting button, but the colour selection should be shown instead. If the Poisonpoints are to be displayed, the Lifepoint display is shifted a little to the center of the screen. The following pictures are the best way to understand this.Within your Res/Layout folder, you can now create folders for the different resolutions. The necessary naming convention is based on the prefix “layout-” and the subsequent size.Since I only use the additional view for high-resolution devices, I create a folder “layout-large“. I use the previous layout file as a basis, copy it to the newly created folder and start editing the original file. I have to point out that to create the folder and thus the layout file, it is necessary to switch to the project view in Android studio. In the standard view, the folder remains invisible.I now adjust the layout so that the life and poison points are displayed below each other, the color selection is centered above the point display. This is not a problem, since the visibility of these controls will always be toggled. To be able to follow the adjustments exactly, you can check out both entries on my GitHub profile:  Regular Layout  Layout-LargeThe adjustments to toggle between the different states are dynamic and are controlled by Java code. I’ve added the following code to be able to get the current devices resolution:screenLayout = getResources().getConfiguration().screenLayout &amp; Configuration.SCREENLAYOUT_SIZE_MASK;This returns an integer value. By using the following constants, I make it easier for myself to differentiate between them:private final int SCREEN_SMALL = 1;private final int SCREEN_NORMAL = 2;private final int SCREEN_LARGE = 3;private final int SCREEN_XLARGE = 4;And that’s it, actually. I use an activity for the game itself, which controls both the 2-player and 4-player view. To toggle the state of the different controls I use corresponding methods, which I have equipped with a Boolean parameter This tells me whether or not the corresponding controls should be repositioned. I set this initial as follows:repositionControlsOnToggle = screenLayout != SCREEN_XLARGE &amp;&amp; view.GetPlayerAmount() == 4;If you have any further questions, you can find the complete source code on GitHub.",
        "url": "/2017/11/support-multiple-screen-sizes-on-android/"
      }
      ,
    
      "2017-11-custom-visualization-for-numeric-values-in-xamarin-devexpress-dxgrid": {
        "title": "Custom Visualization for Numeric Values in Xamarin / DevExpress dxGrid",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "The dxGrid grid control for Xamarin, which DevExpress provides free of charge, is a powerful feature for mobile application development. However, many of the functions are a little bit hidden. In this article I will discuss how to customize the display of column values.In my concrete example my grid contains a numeric column, which can contain numbers with or without decimal places. I want these decimal places to be displayed only if they exist. The magic term that DevExpress provides fortunately is DisplayFormat. You can use this parameter to make various adjustments that describe the corresponding value and its representation.The documentation of DevExpress describes the use of standard or custom numeric format strings, which can be used when using the dxGrid. Both of these types of formatting are documented in the MSDN:  Standard Numeric Format Strings  Custom Numeric Format StringsTo solve my problem I use the custom formats. The available elements for controlling the display are easy to understand, and in my case I only need the following two elements:  0 to display the number before the decimal point  # for optional display of decimal placesThe combination of these elements solves my problem with the following statement:String.Format(\"{0:0.###}\", myNumber)The prefix 0: ensures that the formatting is only applied to the first argument of the statement and can be omitted in this case, but is useful for concatenated strings.While this method can be used for all Xamarin controls, the dxGrid also offers the possibility to make adjustments directly in the XAML file:&lt;dxGrid:GridControl     x:Name=\"grid\"     &lt;!-- ... --&gt;    IsReadOnly=\"true\"&gt;    &lt;dxGrid:GridControl.Columns&gt;        &lt;!-- ... --&gt;        &lt;dxGrid:NumberColumn             FieldName=\"NumberSample\"             Caption = \"Number\"             DisplayFormat=\"0:0.###\" /&gt;    &lt;/dxGrid:GridControl.Columns&gt;&lt;/dxGrid:GridControl&gt;",
        "url": "/2017/11/custom-visualization-for-numeric-values-in-xamarin-devexpress-dxgrid/"
      }
      ,
    
      "2017-11-reusable-styles-android": {
        "title": "Reusable Styles for Android",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "View definitions under android are often used for many different controls. However, there is an easy way to recycle defined styles and use them for other controls, often saving a lot of code. So, styles basically allow you to move your repeatedly used styles out of the layout file into a styles.xml file (which is located in the values-folder). This article covers the basics of using styles on Android.Think of the following layout, which represents two simple buttons inside a LinearLayout:&lt;LinearLayout        android:orientation=\"horizontal\"        android:layout_width=\"match_parent\"        android:layout_height=\"wrap_content\"        android:layout_weight=\"0\"&gt;        &lt;Button            android:layout_width=\"match_parent\"            android:layout_height=\"wrap_content\"            android:layout_weight=\"1\"            android:text=\"@string/cmdPrevPage\"            android:id=\"@+id/cmdPrevPage\" /&gt;        &lt;Button            android:layout_width=\"match_parent\"            android:layout_height=\"wrap_content\"            android:layout_weight=\"1\"            android:text=\"@string/cmdNextPage\"            android:id=\"@+id/cmdNextPage\" /&gt;&lt;/LinearLayout&gt;The buttons look nearly identical, which leads us to creating a new entry in styles.xml looking like this:&lt;style name=\"button\"&gt;        &lt;item name=\"android:layout_width\"&gt;match_parent&lt;/item&gt;        &lt;item name=\"android:layout_height\"&gt;wrap_content&lt;/item&gt;        &lt;item name=\"android:weight\"&gt;1&lt;/item&gt;&lt;/style&gt;The style contains all the elements, that both buttons have in common. Of course, this does not include its ID and text properties. To apply this to the buttons, simply change the first snippet to the following:&lt;LinearLayout        android:orientation=\"horizontal\"        android:layout_width=\"match_parent\"        android:layout_height=\"wrap_content\"        android:layout_weight=\"0\"&gt;        &lt;Button            style=\"@style/button\"            android:text=\"@string/cmdPrevPage\"            android:id=\"@+id/cmdPrevPage\" /&gt;        &lt;Button            style=\"@style/button\"            android:text=\"@string/cmdNextPage\"            android:id=\"@+id/cmdNextPage\" /&gt;&lt;/LinearLayout&gt;This small example already shows the advantage of using styles: your layout becomes clearer and if you want to change some layouts, you only have to do this in one place.However, this approach is not the end of the story. Often only small details of controls are different, for example the positioning of a button on the left or right. In order to be able to handle such minimal changes in case of multiple use, we can use inheritance. Let us go back to the previous example to demonstrate this principle.One of the buttons is used to mark “Next”, the other one for “Back”. Let’s say the code is developed for an app that represents a blog. With these two buttons you can switch back and forth between the available pages. It is realistic, however, that such a navigation is implemented for the articles themselves, but also for categories or tags, which is why a simple possibility for multiple use is required. With the following two styles this can be realized very easily:&lt;style name=\"button_prev\" parent=\"@android:style/button\"&gt;    &lt;item name=\"android:text\"&gt;@string/cmdPrevPage&lt;/item&gt;&lt;/style&gt;&lt;style name=\"button_next\" parent=\"@android:style/button\"&gt;    &lt;item name=\"android:text\"&gt;@string/cmdNextPage&lt;/item&gt;&lt;/style&gt;Further information on this topic is available in the Android developer documentation.",
        "url": "/2017/11/reusable-styles-android/"
      }
      ,
    
      "2017-11-voxel-explosions-unity": {
        "title": "Voxel Explosions in Unity",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "This article describes the process of creating voxel explosions in Unity by using particles. For our models, we use MagicaVoxel, but every other tool can be used as well. The final result will look similar to this:Setting up the test environmentFor test purposes, I’ve set up a basic FPS environment using the built-in CharacterController package. I then added a gun model to the FirstPersonCharacter _game object, which is located as child element in the hierarchy of the _FPSController. The following snippet shows the code I added as a custom script component to the gun:using UnityEngine;public class GunScript : MonoBehaviour {    public Camera FPSCamera;    public float maxDistance = 100f;    public AudioClip shot;    float fireRate = 0.5f;    private float nextFire = 0.0f;    private Transform t;    void Start () {        t = transform;    }    void Update ()    {        if(Input.GetButtonDown(\"Fire1\") &amp;&amp; IsOkToShoot())        {            Shoot();        }    }    void Shoot()    {        AudioSource.PlayClipAtPoint(shot, t.position);        RaycastHit rcHit;        if(Physics.Raycast(FPSCamera.transform.position, FPSCamera.transform.forward, out rcHit, maxDistance))        {            if(rcHit.transform.tag == \"Enemy\")            {                ExplosionScript ex = rcHit.transform.gameObject.GetComponent&lt;ExplosionScript&gt;();                                if(ex != null)                {                    ex.Explode(rcHit.point);                }            }        }    }    bool IsOkToShoot()    {        bool fireable = false;        if (Time.time &gt; nextFire) {            nextFire = Time.time + fireRate;            fireable = true;        }        return fireable;    }}So basically, this script takes up three public variables, one for the camera of the controller, which is needed to shoot from the player’s perspective, a maxDistance to set how far can be shot, and an AudioClip to play a sound file when a shot has been fired. Additionally, there are a few private variables:  fireRate, to set how fast shots can be fired after each other  nextFire, which is used to determine when a shot can be fired  t, which represents the transform component of the current gameObjectEvery frame I check if the left mouse button is pressed. If so, a shot should be fired if the method IsOkToShoot() returns true. This happens when the current time minus the last time shot is larger than the previously set fireRate.When an actual shot happens, the sound is being played where t.position determines the location from where the shot is going to be heard. After that, I call up a ray cast to scan the targeted environment for possible targets. The outgoing argument hit provides information about the target that has been hit (if nothing has been hit, the code inside the outermost if-statement will not be executed).I created a custom tag called Enemy, which is going to be added to all the objects I want to hit. These are going to get a custom script called ExplosionScript, which contains a method named Explode. The next step is to build this script and actually blow something up.Exploding VoxelsI’m using a basic model for testing purposes, that can bee seen in the screenshot below.It currently consists of an empty GameObject as parent, which has been expaned by adding a MeshCollider. The child element contains the actual content.At first, a ParticleSystem is going to be added to the object. I use the following configuration here:Note that the last setting (shader) can’t be set yet. That will be created later. Also, ExplosionMat is just a regular material. After configuring the ParticleSystem, the animation should look like some cubes exploding and falling on the ground. Now the colors of the cubes need to be adjusted. The problem is, that a custom shader and a bit of additional coding is needed here. Now you just create a new prefab and move the ParticleSystem onto it. Then delete it from the object that has been used for testing.I’ll start with the shader. You use the context menu and add a new shader – standard surface shader. You can open the newly created file with Visual Studio (or whatever editor you want) and edit it to match our plan:Shader \"Custom/ExplosionShader\" {    Properties {        _Color (\"Color\", Color) = (1,1,1,1)        _MainTex (\"Albedo (RGB)\", 2D) = \"white\" {}        _Glossiness (\"Smoothness\", Range(0,1)) = 0.5        _Metallic (\"Metallic\", Range(0,1)) = 0.0    }    SubShader {        Tags { \"RenderType\"=\"Opaque\" }        LOD 200                CGPROGRAM        // Physically based Standard lighting model, and enable shadows on all light types        #pragma surface surf Standard fullforwardshadows        // Use shader model 3.0 target, to get nicer looking lighting        #pragma target 3.0        sampler2D _MainTex;        struct Input {            float2 uv_MainTex;                        // NEW LINE            float4 vertexColor : COLOR;        };        half _Glossiness;        half _Metallic;        fixed4 _Color;        void surf (Input IN, inout SurfaceOutputStandard o) {            // Albedo comes from a texture tinted by color            fixed4 c = tex2D (_MainTex, IN.uv_MainTex) * _Color;                        // NEW LINE:            c *= IN.vertexColor;            o.Albedo = c.rgb;            // Metallic and smoothness come from slider variables            o.Metallic = _Metallic;            o.Smoothness = _Glossiness;            o.Alpha = c.a;        }        ENDCG    }    FallBack \"Diffuse\"}There are two lines that need to be adjusted, I’ve marked them with the comment //NEW LINE. After that, the currently used material for the particles should be set to the color white. The color that is going to be set later will be mixed with the default color, and if that isn’t white the colors won’t match our wanted ones. Also, the shader of the material needs to be set to the newly created one.An additional script is needed to edit the palette.using UnityEngine;public class ExplosionScript : MonoBehaviour {    public GameObject explosionPrefab;    private GameObject explosion;    bool exploding = false;    public string colorDescriptor;    private Color32[] colors;    public void Explode(Vector3 pos)    {        explosion = Instantiate(explosionPrefab, pos, Quaternion.Euler(0f,0f,0f));        exploding = true;           }    private void LateUpdate()    {        if(exploding)        {            ParticleSystem explosionParticleSystem = explosion.GetComponent&lt;ParticleSystem&gt;();            ParticleSystem.Particle[] particles = new ParticleSystem.Particle[explosionParticleSystem.main.maxParticles];            colors = ColorManager.getColor(colorDescriptor);            int numParticlesAlive = explosionParticleSystem.GetParticles(particles);            for (int i = 0; i &lt; numParticlesAlive; i++)            {                particles[i].startColor = colors[Random.Range(0, colors.Length)];            }            explosionParticleSystem.SetParticles(particles, numParticlesAlive);            exploding = false;            Destroy(gameObject);        }           }}Again, here are some public and private variables:  explosionPrefab represents the prefab containing the ParticleSystem  explosion is an instance of the prefab  exploding is a flag for controlling the explosion  colors is an array containing the colors that are going to be assigned to the exploding particlesThe first method starts the explosion. It instantiates the explosion at a given position, which is going to be where the ray cast hit the object. In LateUpdate(), the particles are going to be painted. This method is only run, when the exploding-flag is set to true, and it is also run only once, which is why the flag is set to false again at the end.The gameObject itself is destroyed in the very end, since it is needed to assign its properties to the ParticleSystem created at runtime.All the particles of the explosion are collected inside the particles _array. The for-loop is iterating through all of the particles and assigns a new color. The color is determined via random selection of a color of the above-mentioned array. I found this solution to be a bit ugly, so I created another script called _ColorManager, which contains arrays for each of my models. It basically just contains the following code:private static Color32[] foxColors ={    new Color32(238, 0, 0, 255),    new Color32(0, 0, 34, 255),    new Color32(238,238,238,255),    new Color32(187,187,187,255)};private static Color32[] chickenColors ={    new Color32(238,238,238,255),    new Color32(238,0,0,255),    new Color32(255,102,0,255),    new Color32(0,0,17,255)};private static Color32[] emptyColors ={    new Color32(255,255,255,255)};public static Color32[] getColor(string colorDescription){    switch(colorDescription)    {        case \"fox\":            return foxColors;        case \"chicken\":            return chickenColors;        default:            return emptyColors;    }} Note that you can view the colors that have been used using MagicaVoxel by clicking on the tool marked by a smaller-than sign and then clicking on HSV.If this is done, the explosions should work!",
        "url": "/2017/11/voxel-explosions-unity/"
      }
      ,
    
      "2017-11-touch-controls-unity-game-development": {
        "title": "Touch Controls for Unity Game Development",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Some time ago, I created this game (online playable version) in Unity, and I wanted to be able to play it on my Android phone. Since the input options on the smartphone are slightly different from those on the pc, a certain amount of adjustments were necessary. I won’t go over the specific details on the game mechanics, you can check out these on GitHub, they are described in the README file. However, the basic concept of the game is  the movement of a cube to one of the directions up, down, left or right. The information about which direction to use is displayed on the screen.On a PC, you would use your arrow keys to move the cube. Using Android, you don’t have any keys available. Instead, there is a touchscreen. So you need a way to receive information about user interaction on the touchscreen. Therefore, I’ve created the script GestureRecognizer, which can be seen in the listing below.The script fetches user input at the first contact, which is saved in the isTouching boolean. The script checks every frame, if the user is touching the screen. If so, it also checks if the user has moved the position on the screen. I use Input.touches for this, since it is an array which contains information about the movement on the screen. All that is left to do now is to check, in which direction the user moved his finger.However, the immediate evaluation is difficult, as the player will often carry out a minimal movement in a different direction than the intended one (just try it out). For this reason, I have defined a minimum distance that must be exceeded before the script actually communicates the movement. The current movements distance is saved in SwipeDelta, the minimal distance is saved in SWIPE_TOLERANCE, which is assigned 200 units.using System.Collections;using System.Collections.Generic;using UnityEngine;public class GestureRecognizer : MonoBehaviour {    private bool tap, swipeLeft, swipeRight, swipeUp, swipeDown;    private bool isTouching = false;    private Vector2 swipeStart, swipeDelta;    private const int SWIPE_TOLERANCE = 200;    private void resetSwipePosition()    {        swipeStart = Vector2.zero;        swipeDelta = Vector2.zero;        isTouching = false;    }    public Vector2 SwipeDelta { get { return swipeDelta; } }    public bool SwipeLeft { get { return swipeLeft; } }    public bool SwipeRight { get { return swipeRight; } }    public bool SwipeUp { get { return swipeUp; } }    public bool SwipeDown { get { return swipeDown; } }    public bool Tap { get { return tap; } }    private void Update()    {        tap = false;        swipeLeft = false;        swipeRight = false;        swipeUp = false;        swipeDown = false;        // Mobile Inputs        if(Input.touches.Length &gt; 0)        {            if(Input.touches[0].phase == TouchPhase.Began)            {                tap = true;                isTouching = true;                swipeStart = Input.touches[0].position;            }            else if(Input.touches[0].phase == TouchPhase.Ended || Input.touches[0].phase == TouchPhase.Ended)            {                isTouching = false;                resetSwipePosition();            }        }        // Distance Calculation        swipeDelta = Vector2.zero;        if(isTouching &amp;&amp; Input.touches.Length &gt; 0)        {            swipeDelta = Input.touches[0].position - swipeStart;                 }        // Swipe Recognition        if(swipeDelta.magnitude &gt; SWIPE_TOLERANCE)        {            float x = swipeDelta.x;            float y = swipeDelta.y;            if(Mathf.Abs(x) &gt; Mathf.Abs(y))            {                // Left or Right                if(x &lt; 0)                {                    swipeLeft = true;                }                else                {                    swipeRight = true;                }            }            else            {                // Up or Down                if (y &lt; 0)                {                    swipeDown = true;                }                else                {                    swipeUp = true;                }            }            resetSwipePosition();        }    }}To be able to move the cube with this script, it needs to be added to the Update() method of the cubes controller script. To support both touchscreen and keyboards, I simply add an or operator to the if statement:if (Input.GetKeyDown(KeyCode.UpArrow) || swipeControls.SwipeUp){    // ...}SwipeControls is simply an instance of the above created GestureRecognizer class.And that’s basically it! To release a game for android, you have to select the Android entry under File – Build Settings and then click Build. If you have an emulator running or your phone (with USB-debugging enabled) connected to your PC, you can directly run the game on the device. Note, that for building apps for Android, you’ll need to have the Android SDK installed, which can be downloaded directly in Unity.",
        "url": "/2017/11/touch-controls-unity-game-development/"
      }
      ,
    
      "2017-11-building-a-chess-game-in-unity": {
        "title": "Building a Chess Game in Unity",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In this post, I’ll be covering the basics of building a simple chess game in Unity and C#.The MVP of this project will be a fully playable 3D chess game for two players. Each character will only be able to make moves that comply with the rules. After slaying a king, the game is reset. To improve the game, menu scenes, statistics and a simple AI will be added later. The final project and its source code is available on my GitHub-profile.Since this article became quite large, I split it into different parts. Use one of the following links to jump directly to the relevant section.  Loading the Assets for programmers lacking 3d-modeling skills  Setting up the Scene to create a basic setting  Drawing the Chessboard to make testing easier  Initializing the Characters and move them to their default location  Movement Control to differentiate between selecting and moving characters  Board Highlighting to mark all fields to which can be moved  Obey the Rules to implement each characters movesetsLoading the AssetsI think it is quite common that programmers are bad designers. At least that’s the case for me, which is why I try to get the graphic elements for my chess game from the Asset Store. I found Arcane Cyber’s Classic Chess Set to look pretty nice and decided to give it a shot. This asset pack contains three different types of figures (metallic, marble &amp; plastic), although the board is only available in the marble look.Setting up the SceneI start with creating a simple scene, which contains a camera and a light source, as well as an empty GameObject for the chessboard. The chessboards prefab is attached to this gameobject as a child element. Another child element is a simple plane, which I use for testing. For the time being, I deactivate the chess board itself to get a better overview.As soon as the scene itself is finished, I start with the actual scripting. The parent element of the chess field receives a script called BoardManager, which manages the whole game.Drawing the ChessboardThe BoardManager has several tasks, which I’ll be covering in the following. First of all, the manager loads all the characters at their starting positions. Then, possible movements are calculated and the observance of the alternating moves is checked.I’ll start by drawing a chessboard manually. This helps to test the correct movements and positioning inside the squares of the chess board. The method is called in the scripts Start()-method.private void DrawChessBoard(){    Vector3 widthLine = Vector3.right * 8;    Vector3 heightLine = Vector3.forward * 8;    for (int i = 0; i &lt;= 8; i++)    {        Vector3 start = Vector3.forward * i;        Debug.DrawLine(start, start + widthLine);        for (int j = 0; j &lt;= 8; j++)        {            start = Vector3.right * j;            Debug.DrawLine(start, start + heightLine);        }    }}This function generates an 8×8 grid, which symbolizes the chess board and is now used to simplify the positioning of the chess pieces. Before I will position the game pieces next, I want to add a function to hold the current mouse position on the chess board. This function will be implemented by displaying a cross on the labelled field.The currently selected position will be identified by two integer values, which represent X and Y position, ranging from 0 to 7. These two variables are defined at class level and have a default value of -1, which indicates that no field on the chessboard is selected. This value should also be assumed if the mouse position is outside of the chess field. To update the selection, I move the call of DrawChessboard() from the Start()– to the Update()-method.I use a Raycast to check if the mouse is inside the board. I also assign the chessboard GameObject its own layer called “ChessPlane”, which is checked for availability by the Raycast.private void UpdateSelection(){    if (!Camera.main) return;    RaycastHit hit;    float raycastDistance = 25.0f;    if (Physics.Raycast(Camera.main.ScreenPointToRay(Input.mousePosition), out hit, raycastDistance, LayerMask.GetMask(\"ChessPlane\")))    {        selectionX = (int)hit.point.x;        selectionY = (int)hit.point.z;    }    else    {        selectionX = -1;        selectionY = -1;    }}This method is also called in the Update()-method. As you can see in the snippet above, only the X and Y variables are set in the method, but no corresponding changes are made to the graphical user interface. I implement this functionality in the DrawChessBoard()-method to maintain a clear code structure through the related functional area. So, after drawing the board itself, I use the following code to display the current mouse position. By this instruction, two further lines are drawn, which are represented in the form of a cross on the chess board.if (selectionX &gt;= 0 &amp;&amp; selectionY &gt;= 0){    Debug.DrawLine(Vector3.forward * selectionY + Vector3.right * selectionX,        Vector3.forward * (selectionY + 1) + Vector3.right * (selectionX + 1));    Debug.DrawLine(Vector3.forward * selectionY + Vector3.right * (selectionX + 1),        Vector3.forward * (selectionY + 1) + Vector3.right * selectionX);}Initializing the CharactersNext, the chess pieces are initialized and positioned at their respective locations. For this purpose I need information about the different game pieces, so a prefab for each piece has to be created. The package from the Asset Store I used already has prebuilt assets, but you’ll want to adjust the scaling and rotation.I would like to create a class for each type of character so that I can deduce the different possible movements later on. But this is not needed at the moment, so I create a superclass which describes each character and is later used as a parent class of the different characters.I’ve already done some preliminary work here, which is why this class needs an explanation. Each figure has a position, described by two-dimensional coordinates (X and Y). In addition, each figure is either white or black and should have information about the positions to which it may move. The differentiation between white and black figures is realized by a boolean. Alternatively, an enumeration could be used here as well, which I think would be better with regard to readability, but the boolean offers the advantage of comparing this property with a corresponding property of the BoardManager to check the current active color and switching it with the != operator. I have provided the class with the keyword abstract, which prevents the use of the class itself, so only the subclasses can be used.public abstract class ChessFigure : MonoBehaviour{    public int CurrentX { get; set; }    public int CurrentY { get; set; }    public bool isWhite;    public void SetPosition(int x, int y)    {        CurrentX = x;        CurrentY = y;    }    public virtual bool[,] PossibleMove()    {        return new bool[8,8];    }}So much for it. Next, a class is created for each type of character, inherited from the superclass. Since these classes will only overwrite the possible movements, they do not contain any logic of their own at the moment. Remember to adjust the different prefabs after adding the script using the public property “isWhite” and set the check mark in the editor to the white figures.To assign the different prefabs to BoardManager, I’ll now add a public list of the GameObject type and add the different prefabs to it in the editor. The order of the instances is not important, but I recommend that you build a basic logic to make the instantiation as easy to read as possible later on. In my case, I use the following order:  King (White)  Queen (White)  Rook (White)  Bishop (White)  Knight (White)  Pawn (White)  King (Black)  Queen (Black)  Rook (Black)  Bishop (Black)  Knight (Black)  Pawn (Black)To instantiate the different figures correctly, different functionalities are needed. The figure must start on the correct field, but also take the right position (centered) within the field. To calculate the center of a field, I created a method GetTileCenter (). This requires the information about the size of a field, which I have stored in a constant called TILE_SIZE (which is equal to 1). I also calculate the center using an offset (TILE_OFFSET) of 0.5. The parameters correspond to the coordinates of the respective figure on the chess board, which are represented by X and Y (0-7).private Vector3 GetTileCenter(int x, int y){    Vector3 origin = Vector3.zero;    origin.x += (TILE_SIZE * x) + TILE_OFFSET;    origin.z += (TILE_SIZE * y) + TILE_OFFSET;    return origin;}This method is now called by another one, which is used to instantiate the figures. Here too, I have already implemented another functionality, which I must briefly explain. ChessFigurePositions is a two-dimensional array of the type GameObject, which holds information about the positions of figures on the board. When an entry of this is equal to null, that means that no figure is located on that position. ActiveFigures is list of the type GameObject, used to keep track of all characters that are currently alive.private void SpawnChessFigure(int index, int x, int y){    GameObject go = Instantiate(chessFigures[index], GetTileCenter(x, y), chessFigures[index].transform.rotation) as GameObject;    go.transform.SetParent(transform);    ChessFigurePositions[x, y] = go.GetComponent&lt;ChessFigure&gt;();    ChessFigurePositions[x, y].SetPosition(x, y);    activeFigures.Add(go);}With this method, it is now possible to instantiate game pieces, but there is no information on which position belongs to which figure. I create another method called SpawnAllChessFigures(), which handles this task. This is then called in the Start() method of the script and will later also be used to implement the functionality to reset the game. The only difficulty here lies in the correct positioning of the game pieces, which is determined by the parameters of the spawn function.private void SpawnAllChessFigures(){    // White    SpawnChessFigure(0, 4, 0); // King    SpawnChessFigure(1, 3, 0); // Queen    SpawnChessFigure(2, 0, 0); // Rook    SpawnChessFigure(2, 7, 0); // Rook    SpawnChessFigure(3, 2, 0); // Bishop    SpawnChessFigure(3, 5, 0); // Bishop    SpawnChessFigure(4, 1, 0); // Knight    SpawnChessFigure(4, 6, 0); // Knight    SpawnChessFigure(5, 0, 1);    SpawnChessFigure(5, 1, 1);    SpawnChessFigure(5, 2, 1);    SpawnChessFigure(5, 3, 1);    SpawnChessFigure(5, 4, 1);    SpawnChessFigure(5, 5, 1);    SpawnChessFigure(5, 6, 1);    SpawnChessFigure(5, 7, 1);    // Black    SpawnChessFigure(6, 4, 7); // King    SpawnChessFigure(7, 3, 7); // Queen    SpawnChessFigure(8, 0, 7); // Rook    SpawnChessFigure(8, 7, 7); // Rook    SpawnChessFigure(9, 2, 7); // Bishop    SpawnChessFigure(9, 5, 7); // Bishop    SpawnChessFigure(10, 1, 7); // Knight    SpawnChessFigure(10, 6, 7); // Knight    SpawnChessFigure(11, 0, 6);    SpawnChessFigure(11, 1, 6);    SpawnChessFigure(11, 2, 6);    SpawnChessFigure(11, 3, 6);    SpawnChessFigure(11, 4, 6);    SpawnChessFigure(11, 5, 6);    SpawnChessFigure(11, 6, 6);    SpawnChessFigure(11, 7, 6);}Movement ControlAfter all characters have been added to the board, they need to be able to change their position. I splt this functionality into two parts. First of all, it must be possible to select a character by clicking on it. Afterwards, the selected character must be able to move to another location (considering its allowed moves) as far as it is the figures colors turn.To implement this functionality, I have created two new methods in the BoardManager: SelectChessFigure() and MoveChessFigure(). To keep track of the currently active color, I have created a class wide boolean-variable named isWhiteTurn, which can be compared to the isWhite property of the individual characters. The call of these two functions is in the Update()-method and listens for a mouse click.if(Input.GetMouseButtonDown(0)){    if(selectionX &gt;= 0 &amp;&amp; selectionY &gt;= 0)    {        if(selectedFigure == null) SelectChessFigure(selectionX, selectionY);        else MoveChessFigure(selectionX, selectionY);    }}I have created another boolean-variable inside the method, which is used to monitor whether the selected figure can move at all. If this is not the case, the figure should not be selectable, so that a different figure can be selected directly afterwards. Otherwise, the selection of a field to which the piece should moved follows. In case of no other possible movement a double click on a new figure would be required, which is circumvented by this implementation. So, the task of the nested for-loop is simply to check if the chosen figure is able to move.If the figure is able to move, all available target fields should be highlighted. I have outsourced this functionality to another class, which I will discuss next. The array containing information on the available movements is also filled here. This calculation takes place in the different classes of the individual game pieces, which will also be discussed soon.private void SelectChessFigure(int x, int y){    if (ChessFigurePositions[x, y] == null) return;    if (ChessFigurePositions[x, y].isWhite != isWhiteTurn) return;    bool hasAtLeastOneMove = false;    allowedMoves = ChessFigurePositions[x, y].PossibleMove();    for(int i = 0; i &lt; 8; i++)    {        for(int j = 0; j &lt; 8; j++)        {            if(allowedMoves[i,j])            {                hasAtLeastOneMove = true;                i = 7;                break;            }        }    }    if (!hasAtLeastOneMove) return;    selectedFigure = ChessFigurePositions[x, y];    BoardHighlighting.Instance.HighlightAllowedMoves(allowedMoves);}The MoveChessFigure()-Method is implemented quite simple. If there is already a different colored figure on the target field, it will be destroyed. If this figure happens to be a king, the EndGame-()-method is called, which resets the game. Afterwards, the board layout and position properties of the selected piece are updated.private void MoveChessFigure(int x, int y){    if(allowedMoves[x,y])    {        ChessFigure c = ChessFigurePositions[x, y];        if(c != null &amp;&amp; c.isWhite != isWhiteTurn)        {            activeFigures.Remove(c.gameObject);            Destroy(c.gameObject);            if(c.GetType() == typeof(King))            {                EndGame();                return;            }        }        ChessFigurePositions[selectedFigure.CurrentX, selectedFigure.CurrentY] = null;        selectedFigure.transform.position = GetTileCenter(x, y);        selectedFigure.SetPosition(x, y);        ChessFigurePositions[x, y] = selectedFigure;        isWhiteTurn = !isWhiteTurn;    }    BoardHighlighting.Instance.HideHighlights();    selectedFigure = null;}Another detail that is visible in the implementation of the EndGame()-method is the access to the BoardHighlighting-class. This was implemented as a singleton, whereby only one instance of the class can exist, which is accessible from every area of the game.private void EndGame(){    if (isWhiteTurn)        Debug.Log(\"White team won!\");    else        Debug.Log(\"Black team won!\");    foreach (GameObject go in activeFigures)        Destroy(go);    isWhiteTurn = true;    BoardHighlighting.Instance.HideHighlights();    SpawnAllChessFigures();}Board HighlightingThe BoardHighlighting-class is used to emphasise possible target positions. I use a simple prefab in the form of a square plane, which is instantiated on the potential target fields. The possible fields are set by a parameter in form of a two-dimensional boolean array. The highlight objects are additionally managed in a list, which makes it easy to perform a reset between moves.public class BoardHighlighting : MonoBehaviour {    public static BoardHighlighting Instance { get; set; }    public GameObject highlightPrefab;    private List&lt;GameObject&gt; highlights;    private void Start()    {        Instance = this;        highlights = new List&lt;GameObject&gt;();    }    private GameObject GetHighlightObject()    {        GameObject go = highlights.Find(g =&gt; !g.activeSelf);        if(go == null)        {            go = Instantiate(highlightPrefab);            highlights.Add(go);        }        return go;    }    public void HighlightAllowedMoves(bool[,] moves)    {        for (int i = 0; i &lt; 8; i++)        {            for (int j = 0; j &lt; 8; j++)            {                if (moves[i, j])                {                    GameObject go = GetHighlightObject();                    go.SetActive(true);                    go.transform.position = new Vector3(i + 0.5f, 0, j + 0.5f);                }            }        }    }    public void HideHighlights()    {        foreach (GameObject go in highlights) go.SetActive(false);    }}And that’s it! Almost. The only thing missing is the assignment of the possible moves to the different pieces, which will be covered next.Obeying the RulesThe simplest character is also the most difficult to implement, so I’ll start with this one. Generally, the pawn can only move forward one field per turn. However, there are special regulations: if the pawn is located on its start field, then he’s allowed to move two fields forward. He can also not move forward if there is another character on that field. Finally, the pawn may only attack diagonally.Because the direction in which the figures move is different, I implement this logic for both colors separately:public class Pawn : ChessFigure{    public override bool[,] PossibleMove()    {        bool[,] r = new bool[8, 8];        ChessFigure c, c2;        if (isWhite)        {            // Diagonal Left            if(CurrentX != 0 &amp;&amp; CurrentY != 7)            {                c = BoardManager.Instance.ChessFigurePositions[CurrentX -1, CurrentY +1];                if(c != null &amp;&amp; !c.isWhite) r[CurrentX - 1, CurrentY + 1] = true;            }            // Diagonal Right            if (CurrentX != 7 &amp;&amp; CurrentY != 7)            {                c = BoardManager.Instance.ChessFigurePositions[CurrentX + 1, CurrentY + 1];                if (c != null &amp;&amp; !c.isWhite) r[CurrentX + 1, CurrentY + 1] = true;            }            // Forward            if(CurrentY != 7)            {                c = BoardManager.Instance.ChessFigurePositions[CurrentX, CurrentY + 1];                if(c == null) r[CurrentX, CurrentY + 1] = true;            }            // Two Steps Forward            if(CurrentY == 1)            {                c = BoardManager.Instance.ChessFigurePositions[CurrentX, CurrentY + 1];                c2 = BoardManager.Instance.ChessFigurePositions[CurrentX, CurrentY + 2];                if(c == null &amp;&amp; c2 == null) r[CurrentX, CurrentY + 2] = true;            }        }        else        {            // Diagonal Left            if (CurrentX != 0 &amp;&amp; CurrentY != 0)            {                c = BoardManager.Instance.ChessFigurePositions[CurrentX - 1, CurrentY - 1];                if (c != null &amp;&amp; c.isWhite) r[CurrentX - 1, CurrentY - 1] = true;            }            // Diagonal Right            if (CurrentX != 7 &amp;&amp; CurrentY != 0)            {                c = BoardManager.Instance.ChessFigurePositions[CurrentX + 1, CurrentY - 1];                if (c != null &amp;&amp; c.isWhite) r[CurrentX + 1, CurrentY - 1] = true;            }            // Forward            if (CurrentY != 0)            {                c = BoardManager.Instance.ChessFigurePositions[CurrentX, CurrentY - 1];                if (c == null) r[CurrentX, CurrentY - 1] = true;            }            // Two Steps Forward            if (CurrentY == 6)            {                c = BoardManager.Instance.ChessFigurePositions[CurrentX, CurrentY - 1];                c2 = BoardManager.Instance.ChessFigurePositions[CurrentX, CurrentY - 2];                if (c == null &amp;&amp; c2 == null) r[CurrentX, CurrentY - 2] = true;            }        }        return r;    }}The next character I’m going to implement will be the bishop. The bishop can run any number of fields diagonally, as long as no other figures stand in the way.public class Bishop : ChessFigure{    public override bool[,] PossibleMove()    {        bool[,] r = new bool[8, 8];        ChessFigure c;        int i, j;        // Top Left        i = CurrentX;        j = CurrentY;        while(true)        {            i--;            j++;            if (i &lt; 0 || j &gt;= 8) break;            c = BoardManager.Instance.ChessFigurePositions[i, j];            if (c == null) r[i, j] = true;            else            {                if (c.isWhite != isWhite) r[i, j] = true;                break;            }        }        // Top Right        i = CurrentX;        j = CurrentY;        while (true)        {            i++;            j++;            if (i &gt;= 8 || j &gt;= 8) break;            c = BoardManager.Instance.ChessFigurePositions[i, j];            if (c == null) r[i, j] = true;            else            {                if (c.isWhite != isWhite) r[i, j] = true;                break;            }        }        // Bottom Left        i = CurrentX;        j = CurrentY;        while (true)        {            i--;            j--;            if (i &lt; 0 || j &lt; 0) break;            c = BoardManager.Instance.ChessFigurePositions[i, j];            if (c == null) r[i, j] = true;            else            {                if (c.isWhite != isWhite) r[i, j] = true;                break;            }        }        // Bottom Right        i = CurrentX;        j = CurrentY;        while (true)        {            i++;            j--;            if (i &gt;= 8 || j &lt; 0) break;            c = BoardManager.Instance.ChessFigurePositions[i, j];            if (c == null) r[i, j] = true;            else            {                if (c.isWhite != isWhite) r[i, j] = true;                break;            }        }        return r;    }}The rook is implemented in a similar way to the bishop, but the movement here is straight (vertical and horizontal) instead of diagonal.public class Rook : ChessFigure{    public override bool[,] PossibleMove()    {        bool[,] r = new bool[8, 8];        ChessFigure c;        int i;        // Left        i = CurrentX;        while(true)        {            i--;            if (i &lt; 0) break;            c = BoardManager.Instance.ChessFigurePositions[i, CurrentY];            if (c == null) r[i, CurrentY] = true;            else            {                if(c.isWhite != isWhite) r[i, CurrentY] = true;                break;            }        }        // Right        i = CurrentX;        while (true)        {            i++;            if (i &gt;= 8) break;            c = BoardManager.Instance.ChessFigurePositions[i, CurrentY];            if (c == null) r[i, CurrentY] = true;            else            {                if (c.isWhite != isWhite) r[i, CurrentY] = true;                break;            }        }        // Forward        i = CurrentY;        while (true)        {            i++;            if (i &gt;= 8) break;            c = BoardManager.Instance.ChessFigurePositions[CurrentX, i];            if(c == null) r[CurrentX, i] = true;            else            {                if(c.isWhite != isWhite) r[CurrentX, i] = true;                break;            }        }        // Back        i = CurrentY;        while (true)        {            i--;            if (i &lt; 0) break;            c = BoardManager.Instance.ChessFigurePositions[CurrentX, i];            if (c == null) r[CurrentX, i] = true;            else            {                if (c.isWhite != isWhite) r[CurrentX, i] = true;                break;            }        }        return r;    }}Another complicated looking figure is the knight. The knight moves two fields straight ahead in one direction, followed by a 90 degree turn and a further movement by one field in this direction. Alternatively, the movement of a single field can be done first, followed by the two-field-movement. Figures that are on the fields within the movement sequence are irrelevant. However, the knight has a positive side: the movements do not have to be implemented separately for both colors.public class Knight : ChessFigure{    public override bool[,] PossibleMove()    {        bool[,] r = new bool[8, 8];        // Up / Left        KnightMove(CurrentX - 1, CurrentY + 2, ref r);        KnightMove(CurrentX - 2, CurrentY + 1, ref r);        // Up / Right        KnightMove(CurrentX + 1, CurrentY + 2, ref r);        KnightMove(CurrentX + 2, CurrentY + 1, ref r);        // Down / Left        KnightMove(CurrentX - 1, CurrentY - 2, ref r);        KnightMove(CurrentX - 2, CurrentY - 1, ref r);        // Down / Right        KnightMove(CurrentX + 1, CurrentY - 2, ref r);        KnightMove(CurrentX + 2, CurrentY - 1, ref r);        return r;    }    public void KnightMove(int x, int y, ref bool[,] r)    {        ChessFigure c;        if(x &gt;= 0 &amp;&amp; x &lt; 8 &amp;&amp; y &gt;= 0 &amp;&amp; y &lt; 8)        {            c = BoardManager.Instance.ChessFigurePositions[x, y];            if (c == null) r[x, y] = true;            else if (c.isWhite != isWhite) r[x, y] = true;        }    }}The possible movements of the king correspond to two fields in any direction, which I have implemented as follows:public class King : ChessFigure{    public override bool[,] PossibleMove()    {        bool[,] r = new bool[8, 8];        ChessFigure c;        int i, j;        // Top        i = CurrentX - 1;        j = CurrentY + 1;        if(CurrentY &lt; 7)        {            for(int k = 0; k &lt; 3; k++)            {                if(i &gt;= 0 &amp;&amp; i &lt; 8)                {                    c = BoardManager.Instance.ChessFigurePositions[i, j];                    if (c == null) r[i, j] = true;                    else if (c.isWhite != isWhite) r[i, j] = true;                }                i++;            }         }        // Bottom        i = CurrentX - 1;        j = CurrentY - 1;        if (CurrentY &gt; 0)        {            for (int k = 0; k &lt; 3; k++)            {                if (i &gt;= 0 &amp;&amp; i &lt; 8)                {                    c = BoardManager.Instance.ChessFigurePositions[i, j];                    if (c == null) r[i, j] = true;                    else if (c.isWhite != isWhite) r[i, j] = true;                }                i++;            }        }        // Left        if(CurrentX &gt; 0)        {            c = BoardManager.Instance.ChessFigurePositions[CurrentX - 1, CurrentY];            if (c == null) r[CurrentX - 1, CurrentY] = true;            else if (c.isWhite != isWhite) r[CurrentX - 1, CurrentY] = true;        }        // Right        if (CurrentX &lt; 7)        {            c = BoardManager.Instance.ChessFigurePositions[CurrentX + 1, CurrentY];            if (c == null) r[CurrentX + 1, CurrentY] = true;            else if (c.isWhite != isWhite) r[CurrentX + 1, CurrentY] = true;        }        return r;    }}And last but not least, the queen’s movements are still missing. These seem to be quite complex again, but here you can simply combine the already created movements of rook and bishop, which is why I don’t separately add a snippet of the source code for the queens implementation.Now that’s it! The functionality of the MVP defined at the beginning is fully implemented. I will now try to implement a simple AI, which will help you to play the game without disturbing social interaction. Stay tuned!",
        "url": "/2017/11/building-a-chess-game-in-unity/"
      }
      ,
    
      "2017-11-decoupling-views-in-xamarin": {
        "title": "Decoupling Views in Xamarin",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "As a software developer, you’ve probably stumbled across old source code you’ve written from time to time and you’ve just been thinking ‘how the hell can someone come up with such bullshit?’. I don’t see myself as an exception regarding this topic and just recently had such a case, which I would like to document in this article. More specifically, I want to discuss the decoupling of views under xamarin. The source I use in this article is available on my GitHub profile.Xamarin NavigationDecoupling allows you to use multiple views without dependencies between them. Without decoupling, all relevant elements would have to be edited for individual changes. Xamarin relies on a simple page-based navigation structure that is managed in the form of a stack (see figure). A new page is added with Push(), the topmost page can be removed with Pop().These pages are usually interdependent, for example, information is required on a page that is entered on the next page. After entering the required information, the user is taken back to the calling page and the information is transferred to this one. This is exactly the point I want to clarify with this article. The strict interaction of the sides is problematic in the case of subsequent changes.Building the demo applicationTake a look at the following screenshots to see how the demo application works. The app consists of two pages, whereby the second view is opened by a button on the first one. The second view contains an input field whose value will then be accessed in the first view. There is an additional button to abort the process. If the “Confirm” button is pressed even though no text has been entered, the user will be informed.The default configuration of Visual Studio already creates a default page for every new Xamarin project. I created an additional one next to it. For interaction I have created an interface which manages the possible handlers. The folder structure of my main project consists of the following files:  App.xaml (+ code-behind)  MainPage.xaml (+ code-behind)  InputPage.xaml (+code-behind)  IRequireDialogInteractionSince this project is used as showcase to demonstrate the decoupling of views, I don’t follow the MVVM-approach here. However, this is done only to minimize possible distractions, MVVM can of course still be used.The first thing you’ll want to do is to set up a navigation page. This is done in App.xaml.cs by adding: MainPage = new NavigationPage(new MainPage());After doing so, you can navigate between your views via:Navigation.PushAsync(page);The next thing is setting up the simple GUI:MainPage.xaml&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;&lt;ContentPage xmlns=\"http://xamarin.com/schemas/2014/forms\"             xmlns:x=\"http://schemas.microsoft.com/winfx/2009/xaml\"             xmlns:local=\"clr-namespace:XamarinDecouplingDemo\"             x:Class=\"XamarinDecouplingDemo.MainPage\"&gt;    &lt;ContentPage.Content&gt;        &lt;StackLayout&gt;            &lt;Button                Text=\"Load second page\"                Clicked=\"OnLoadButtonClick\"/&gt;            &lt;Label                x:Name=\"lblInputText\" /&gt;        &lt;/StackLayout&gt;    &lt;/ContentPage.Content&gt;&lt;/ContentPage&gt;InputPage.xaml&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;&lt;ContentPage xmlns=\"http://xamarin.com/schemas/2014/forms\"             xmlns:x=\"http://schemas.microsoft.com/winfx/2009/xaml\"             x:Class=\"XamarinDecouplingDemo.InputPage\"&gt;    &lt;ContentPage.Content&gt;        &lt;Grid                Padding=\"30\"                BackgroundColor=\"White\"&gt;            &lt;Grid.RowDefinitions&gt;                &lt;RowDefinition Height=\"Auto\" /&gt;                &lt;RowDefinition Height=\"Auto\" /&gt;                &lt;RowDefinition Height=\"Auto\" /&gt;            &lt;/Grid.RowDefinitions&gt;            &lt;Grid.ColumnDefinitions&gt;                &lt;ColumnDefinition Width=\"*\" /&gt;                &lt;ColumnDefinition Width=\"*\" /&gt;            &lt;/Grid.ColumnDefinitions&gt;            &lt;Label                    Grid.ColumnSpan=\"2\"                    Grid.Row=\"0\"                    HorizontalOptions=\"Start\"                    Text=\"Text to return\"/&gt;            &lt;Entry                    Grid.ColumnSpan=\"2\"                    Grid.Row=\"1\"                    x:Name=\"txtTextToReturn\"/&gt;            &lt;Button                    Grid.Column=\"0\"                    Grid.Row=\"2\"                    x:Name=\"cmdCancel\"                    Text=\"Cancel\"                    Clicked=\"OnCancel\"/&gt;            &lt;Button                     Grid.Column=\"1\"                    Grid.Row=\"2\"                    x:Name=\"cmdConfirm\"                    Text=\"Confirm\"                    Clicked=\"OnConfirm\" /&gt;        &lt;/Grid&gt;    &lt;/ContentPage.Content&gt;&lt;/ContentPage&gt;The second view can be left by clicking one of two buttons, cancel and confirm. These interactions will be required by the MainPage later, which is why methods for those will be added to IRequireDialogInteraction:interface IRequireDialogInteraction{    void OnDialogConfirmation(object sender, EventArgs e);    void OnDialogCancellation(object sender, EventArgs e);}After the basic settings have been made, the actual magic will now happen in form of public EventHandler properties. MainPage needs a property of the type InputPage, which is used to interact with the second view. InputPage on the other hand will implement two event handlers, which can be accessed by MainPage. These will then be linked to the Clicked-property which is set in the xaml-file:public partial class InputPage : ContentPage{    public InputPage ()    {      InitializeComponent();    }    public EventHandler Confirmed;    public EventHandler Cancelled;    public String enteredText { get { return txtTextToReturn.Text; } }    public void OnConfirm(object sender, EventArgs e)    {        Confirmed?.Invoke(this, EventArgs.Empty);    }    public void OnCancel(object sender, EventArgs e)    {        Cancelled?.Invoke(this, EventArgs.Empty);    }}MainPage now only needs to link the event handlers to the methods which are implemented by IRequireDialogInteraction and can then access the enteredText-property of the InputPage-object:public partial class MainPage : ContentPage, IRequireDialogInteraction{    private InputPage _InputPage;    public MainPage()    {        InitializeComponent();    }    public void OnDialogCancellation(object sender, EventArgs e)    {        Navigation.PopAsync();    }    public void OnDialogConfirmation(object sender, EventArgs e)    {        Navigation.PopAsync();        lblInputText.Text = _InputPage.enteredText ?? \"No text entered.\";    }    public void OnLoadButtonClick(object sender, EventArgs e)    {        lblInputText.Text = \"\";        _InputPage = new InputPage();        _InputPage.Confirmed += OnDialogConfirmation;        _InputPage.Cancelled += OnDialogCancellation;        Navigation.PushAsync(_InputPage);    }}And that’s basically it! If you want to change the style in which user interaction happens, you’ll be able to simply swap out the specific part in the methods OnDialogConfirmation or OnDialogCancellation.Implementing DialogsFinally, I would like cover one specific detail which helped me a lot in my work with xamarin. This plugin (available on GitHub &amp; Nuget) allows you to show regular XAML-pages as dialogs. This is really helpful in combination with the decoupling shown above, since you can create custom dialogs, for example to display user prompts or general input fields to take off the load of some of the main pages. The usage looks exactly the same as that of the regular pages, except that the dialog-pages must inherit from PopupPage and are called with PushPopupAsync() instead of PushAsync(). The closing of the page takes place analogously with PopPopupAsync().",
        "url": "/2017/11/decoupling-views-in-xamarin/"
      }
      ,
    
      "2017-11-p2p-synchronization-with-syncthing": {
        "title": "P2P Synchronization with Syncthing",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Everyone has different programs and tools that they particularly appreciate. One of these programs is syncthing for me, so I will briefly discuss how it works and how it is set up in this article. Syncthing is used to synchronize files between different devices and also supports versioning of these files. Syncthing is available for Windows, Android and as cross-platform wrapper. I personally use it on Windows 10,  Arch Linux and Android (via Playstore or FDroid). It is completely open source and available on GitHub. For general problems, I recommend reading their FAQ.Syncthing transfers files over the internet, but if you use it for local transfers only, it will be restricted to LAN and won’t use the internet. However, you can also host your own relay server and contribute to the network, which is organized decentrally.In the following, I’ll be setting up a shared folder to synchronize my playlist I use for running, since my main smartphone is a Xiaomi Redmi Note 4, but since my nexus 5 is more practical by weight and size, I use this to run. My setup can be summarized as follows:  Xiaomi Redmi Note 4 (Android)  Google Nexus 5 (Android)  MacBook Air (Arch Linux)  Desktop-PC (Windows 10)Setting up and Connecting DevicesOn windows and linux, the graphical user interface of syncthing is started via browser (localhost, default port is 8384). You can set a name for your device, which is used as default on connecting devices later. Each device is uniquely addressable by an id which can be accessed via Actions – Show ID. You can add a device by clicking Add Remote Device in the lower right corner. Devices that are located in the same network are recognized automatically, otherwise they can be added by entering their id.When adding devices, there are multiple options available. One of these is to mark a device as Introducer. This allows to forward all devices that are available on the remote device to the current one, which is great for using Syncthing on a NAS-like server.Sharing FoldersAfter networking the devices with each other, directories can be created which will then be synchronized. To do this, simply click Add Folder on the web interface. On Android, this can be done by clicking the plus-button:You’ll want to specify the path of the folder, as well as the label, which will be displayed on all devices later. Since I’ll be using this folder for mp3-files, I won’t enable versioning for it, but you can select one of multiple options at this point. Finally it is specified for which of the available devices the directory should be available. After completing the setup, the devices that were selected will automatically receive a request to accept the shared folder. By doing this, a local folder needs to be set again. I’ve encountered minor problems here, where the shares won’t be recognized automatically on Android devices. I’ve solved this problem by switching to the Web GUI via settings. By using the web interface, you have the additional option of specifying the scanning interval and more (see advanced settings).After setting up everything correctly, synchronization should begin automatically. And that’s basically it! You can set up multiple folders for different devices and multiple filetypes to fit your individual needs.",
        "url": "/2017/11/p2p-synchronization-with-syncthing/"
      }
      ,
    
      "2017-10-motivation-self-discipline": {
        "title": "Motivation &amp; Self-Discipline",
        "author": "marcelAdmin",
        "category": "",
        "content": "During my participation in various software development projects, I have noticed one thing they usually have in common. While it is often very easy to find the motivation to start a new project, many of them end up unfinished or not in a way you would like them to.Laying FocusAs you can see on GitHub, I don’t see myself as an exception, where I’ve started a lot of projects, but only a few end up finished. It is generally difficult to define a software project as completed, but that’s not the point I want to describe in this article. Therefore, I’m only interested in having a functioning MVP (Minimum Viable Product) in place.But why is that? In my case, I often have the problem of easily getting enthusiastic about a new project. As soon as it reaches a certain stage of development, however, it is difficult to find further motivation to complete the project. This is not necessarily because I don’t enjoy it anymore, definitely not. I rather face the problem of having a new idea that looks more promising than the one I’m currently working on.Well, there seems to be a simple solution for this problem: Limit your focus on a smaller amount of projects at the same time. Altough this advice seems kind of obvious and easy, following this advice certainly isn’t that easy. Sure, new ideas often seem to be very promising, but just don’t forget, that the ones you’re currently working on probably also did. I solve these issues by keeping track of my ideas using a classic, physical notebook. Whenever a new idea comes to my mind, I write down all of its details. After doing so, my mind can get rid of the idea and continue working on my current project. As soon as I consider this completed, I move on to the next one I’ve written down.Although I don’t use this approach for very long, it seems to have a very positive effect. I don’t forget about cool ideas and I also keep my mind from focussing on too many things at the same time. Additionally, when there’s some time between the idea coming up and actually implementing it, the idea can be easier viewed from another perspective. Maybe it isn’t actually that great and you save yourself lots of time by not implementing it. Even if it covers a different context, I stumbled upon a great article by mark manson on this topic.The DownsidesChances are, limiting the projects you’re contributing to isn’t enough. There are times when the motivation to continue working on a project does not come by itself. It is therefore important to understand that motivation is not always self-evident. Eevery hobby, no matter how great, will suck on some days. And on these very days it is therefore important to pull yourself together and do your thing. Here is a link to this article that I published some time ago, in which I covered my way to build habits on things that aren’t that great. This can be also applied here. The goal is to be able to control your own motivation as well as to be disciplined so that you don’t just give up a personal project when it is not fun anymore.The ideas are always great. Most of the implementation will be fun too, but don’t expect every single minute of it to be fun. In these moments, try not to think about how much this task sucks, try thinking about the result of it.ConclusionGetting enthusiastic about a new project is easy. Thinking about about the implementation and design before jumping headfirst into it is something completely different. Always try to implement a project towards the planned MVP. Nothing is perfect and not everything will always be fun. You can help yourself by applying project management techniques to your personal project, as I mentioned in this article. Concentrated working on a task is much easier with a well defined goal in mind.",
        "url": "/2017/10/motivation-self-discipline/"
      }
      ,
    
      "2017-10-fix-project-file-not-loaded-visual-studio": {
        "title": "Fix &amp;#8220;project file could not be loaded&amp;#8221; in Visual Studio",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "I recently stumbled upon the problem that my solution in Visual Studio (2017) could not load all of my projects. Since the solution of the problem took a while, I decided to document my approach here.No configuration of the project has been changed, which is why I have no clue why things are fucked up. But hey, never underestimate the ability of microsoft to disappoint people. Anyway, I found the following solution working for me: First, delete all .suo files you can find and then rebuild the project. That was enough for me to get the project up and running again.",
        "url": "/2017/10/fix-project-file-not-loaded-visual-studio/"
      }
      ,
    
      "2017-10-self-organization-and-increasing-productivity": {
        "title": "Self-Organization and Increasing Productivity",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In order to get professional elements, side projects, sport and social contacts under one roof, I have recently been busy designing my daily schedule to maximize my productivity. this article presents the results of my reflections.As a software developer it is almost self-evident to work on various own side projects, which in my case are currently mostly developed in the form of Android apps. Starting with an originally simple LifeCounter for Magic the Gathering, over smaller games up to the design of websites, my GitHub profile has meanwhile reached a considerable size. But although the whole thing is a lot of fun as a hobby, there is often no time to do everything you want to do. For this reason, I have started to allocate my productive time and to reduce the time I waste with pointless activities to a minimum.Dividing Tasks: Kanban &amp; PomodoroI started with the adaptation of a Kanban board, as we use it at work. The basic functionality of such a board is the division of work steps into columns, as well as the prioritized classification of tasks into these columns, whereby each column may contain only a limited, predefined number of tasks. An example of these columns would be Analysis, Development, Test and Deploy. Each task then passes through these columns and is pulled to the next phase, once a previous phase has been completed. In my experience, this approach works quite well for smaller teams, but the work of an individual according to this principle did not really make sense, at least in my case.My next step was to combine kanban with the pomodoro technique. The latter involves dividing work into blocks, which are supposed to be doable in 25 minutes. After each such block, a five-minute should be taken. After the fourth repetion of this cycle, a pause of fifteen minutes should be taken. The idea behind this approach is the reduction of distraction during these units and the limitation of tasks to a certain period of time.The combination of both approaches resulted in the division of the kanban board into columns for each day. Weekly I sort the elements I want to do in the following week and assign them an estimated amount of time in the form of pomodoro units. I try to divide tasks so that no element needs more than three such units. I also limit the number of daily units to create time for other things. During the week I don’t want to assign more than six units to one day. On the other hand, I also want to plan no less than two units a day in order to keep a certain amount of progress. I have been using this approach for several months now and it seems to work.When creating and establishing such a technique for yourself, always try to keep in mind that time does not necessarily correlate with productivity. After defining my tasks, I achieve the set goals much faster than if I just plan to spend two hours programming in the evening. Due to the subsequent availability of more time, the time used is also perceived to be more usefully used, so that the other activities can be carried out more calmly, as I do not constantly think about what I could do at the moment, that might be more meaningful.Establish HabitsOnly by following the concept described above I have been able to see personal improvements in my productivity, but I have applied the concept only to my side projects. But I don’t just want to improve these elements, I want to improve my general lifestyle. An important element for me in this area is sport and movement in general. But I am sure that anyone who has ever tried to motivate himself to do more sport has lost his motivation quite early on. I see two ways of preventing the failure of such projects. Building motivation is much easier if you have a group, where people motivate each other. But other people are not always available, in which case self-motivation is the only way to carry out one’s plan.However, as that is easier said than done, I have also made some reflections on this. In order not to have to force oneself to do something every day, it must be achieved that this activity is fun. So my basic idea is to build up a habit, which you will follow automatically after some time. While this may require a certain amount of motivation at the beginning, this requirement is supposed to decrease over time. As an example, I use the goal to train my endurance. I want to build up a habit by going running three times a week for 30 minutes each.I consider the motivation to do that after a long day to be much less than directly after getting up in the morning. For this reason I set my alarm clock to 5:30 instead of 6:00 am, and since I know that getting up in the morning is not necessarily one of my best disciplines, the alarm clock will be placed out of range from now on. In my experience, it is easier to resist the temptation to continue sleeping when you’re already on your feet. Another advantage I get with this approach is an additional half hour of time on the days I don’t go running as I prefer a regular sleep rhythm.Supporting ToolsI also treat other things that I would like to do regularly in a similar way. Finally, however, I would like to draw your attention to a few apps and tools that have helped and still help me to build up such habits. I use Trello to organize my todo lists in the format described above. You can also use wekan if you prefer open source. To mark the planned times for my tasks, I use my own tags in the form of colored labels for one, two or three units. Completed elements also receive appropriate labels. I combine trello with Goodtime Productivity Timer (Android), which keeps track of the pomodoros I do and toggles my phone to and from flightmode automatically. This ensures that I can really focus during the current unit without any distractions.To monitor my (planned) habits I use Loop Habit Tracker (Android), which allows me to check daily activities and view history data.ConclusionAnd that’s it, actually. the above-mentioned apps and programs help me personally to increase my productivity, but you will probably have to adapt some of them to your individual requirements. as a rough guide, this overview is hopefully still helpful. Things that are already liked to be done should be planned more precisely in order to ensure efficient achievement of personal goals. Things that are reluctant to do, on the other hand, should be developed into habits, whereby the necessary motivation should be reduced over time. Everyone has his or her own preferences and possibilities to realize their plans. With certain adjustments, this overview will definitely help you with that.",
        "url": "/2017/10/self-organization-and-increasing-productivity/"
      }
      ,
    
      "2017-10-windows-package-management": {
        "title": "Windows Package Management",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "As a Windows user with Linux knowledge there are several things under Linux that I would like to have on for Windows. Since a complete switch from Windows to Linux is not feasible for me due to different requirements, I looked for alternatives. An important component of various Linux distributions is their package manager. This article discusses the implementation of such a feature under Windows and shows how it can be used.While researching this topic I came across chocolatey, a CLI-tool that acts as package manager for Windows operating systems. Chocolatey is open source, the code is available on GitHub. On the project’s website you will also find instructions for installation, which can be performed using CMD commands or via powershell.Install, Update, UninstallA list of available packages can be viewed on https://chocolatey.org/packages. As with the Arch User Repository, packages are managed by users, which means that there is a very large selection of available packages. The pattern for installing packages is  choco install &lt;/code&gt;A full list of commands can be found in the docs. Installed packages can be uninstalled using  choco uninstall &lt;/code&gt;or upgraded by using  choco upgrade&lt;/code&gt;If you want to upgrade all installed packages, simply use the keyword all instead of a specific packagename.By default, Chocolatey creates a directory under C: \\ProgramData which contains the program files. The installation locations for the individual programs depend on the configuration of the package, but usually either C:\\Program Files or C:\\Program Files (x86) is used.Further CommandsOf course, the package management does not only include installation, upgrade and deinstallation of packages, so this section is dedicated to some other features. Check out the docs for a complete list of features.You can search packages by using  choco search &lt;/code&gt;which results into something similar to the following listing.D:\\&gt;choco search jenkinsChocolatey v0.10.8jenkins 2.60.3 [Approved]gradle 4.1.0 [Approved] Downloads cached for licensed usersnotify-me-ci 1.3.3.13 [Approved] Downloads cached for licensed usersJenkinsOnDesktop 1.04 packages found.To check out the installed version of choco, you can use  choco –version&lt;/code&gt;or  choco -vTo upgrade chocolatey, just use the regular update command. To list all packages available, use  choco listIf you only want to receive the packages that are installed locally, add the -l flag.These few commands should be sufficient to enable you to get started with package management under Windows. As already mentioned, the documentation of the project conveys all further details in a simple and understandable way. And, if you’re not comfortable using the command line, there is also a graphical user interface for chocolatey available, which can be found under the name chocolateygui.",
        "url": "/2017/10/windows-package-management/"
      }
      ,
    
      "2017-09-restful-services-servicestack-part-2": {
        "title": "RESTful Services with ServiceStack &amp;#8211; Part 2",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In my last post, I’ve set up a basic RESTful service using ServiceStack. This article deals with the implementation of a corresponding functionality on the client side. The application will query the path provided by the server and apply the pre-defined authentication method, requiring the user to log in with username and password before the application delivers the desired content.Both projects, client and server are located on my GitHub-profile and can be viewed and downloaded there.The structure of the client is very simple. There are two textboxes for entering username and password, as well as one for entering a name for the hello/{name*} path. The button sends the request and the richtextbox is filled with the response.Access to the classes created for the server-side service is required. For this reason, these were also added to the project. This includes Hello and HelloResponse.[Route(\"/hello/{name*}\")]public class Hello : IReturn&lt;HelloResponse&gt;{    public string Name { get; set; }}public class HelloResponse{    public string Result { get; set; }}The same applies to the custom AuthenticationProvider.public class CustomAuthenticationProvider : CredentialsAuthProvider{    public override bool TryAuthenticate(IServiceBase authService, string userName, string password)    {        // Only checks if username equals password        // implement custom logic here        return userName.Equals(password);    }    public override IHttpResult OnAuthenticated(IServiceBase authService, IAuthSession session, IAuthTokens tokens, Dictionary&lt;string, string&gt; authInfo)    {        //session.customElement = \"Hello World\";        return base.OnAuthenticated(authService, session, tokens, authInfo);    }}An additional class has been created to control access to the service. This encapsulates the requests, which can be easily accessed from outside.using System;using ServiceStack;namespace RESTfulDemoClient{    class RESTfulServiceClient : IDisposable    {        private const String url = \"http://localhost:64424\";        private JsonServiceClient serviceclient;        private JsonServiceClient getServiceClient(String usern, String passw)        {            if(serviceclient == null)            {                serviceclient = new JsonServiceClient(url);                var authResponse = serviceclient.Post(new Authenticate                {                    provider = CustomAuthenticationProvider.Name, //= credentials                    UserName = usern,                    Password = passw,                    RememberMe = true,                });                serviceclient.AlwaysSendBasicAuthHeader = true;            }            return serviceclient;        }        public HelloResponse GetHelloResponse(Hello request, String username, String password)        {            var client = this.getServiceClient(username, password);            var response = client.Post(request);            return response;        }        public void Dispose()        {            serviceclient = null;        }    }}The class already contains all the logic required for access control, and the method GetHelloResponse can be used to retrieve a response from the Hello-path, which is implemented like this:using(var client = new RESTfulServiceClient()){    var request = new Hello() { Name = txtRequest.Text };    try    {        var response = client.GetHelloResponse(request, txtUsername.Text, txtPassword.Text);        txtResponse.Text = response.Result;    }    catch (ServiceStack.WebServiceException ex)    {        txtResponse.Text = ex.StatusCode + \" - \" + ex.ErrorMessage;    }}",
        "url": "/2017/09/restful-services-servicestack-part-2/"
      }
      ,
    
      "2017-09-creating-restful-services-servicestack": {
        "title": "Creating RESTful Services with ServiceStack",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "This articles covers the basic usage of ServiceStack, a .NET-framework for creating RESTful services. The framework has a really great documentation, where you can check out all the details.ConfigurationTo get started, you’ll want to create a new ASP.NET project, and load the ServiceStack package via NuGet. Then, you’ll have to edit your Web.config to look like the following (mentioned versions may differ from your project):&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;!--  Informationen zur Konfiguration Ihrer ASP.NET-Anwendung finden Sie unter  https://go.microsoft.com/fwlink/?LinkId=169433  --&gt;&lt;configuration&gt;  &lt;system.web&gt;    &lt;compilation debug=\"true\" targetFramework=\"4.6.1\"/&gt;    &lt;httpRuntime targetFramework=\"4.6.1\"/&gt;    &lt;httpHandlers&gt;      &lt;add path=\"*\" type=\"ServiceStack.HttpHandlerFactory, ServiceStack\" verb=\"*\"/&gt;    &lt;/httpHandlers&gt;  &lt;/system.web&gt;  &lt;!-- Required for IIS7 --&gt;  &lt;system.webServer&gt;    &lt;modules runAllManagedModulesForAllRequests=\"true\"/&gt;    &lt;validation validateIntegratedModeConfiguration=\"false\" /&gt;    &lt;handlers&gt;      &lt;add path=\"*\" name=\"ServiceStack.Factory\" type=\"ServiceStack.HttpHandlerFactory, ServiceStack\" verb=\"*\" preCondition=\"integratedMode\" resourceType=\"Unspecified\" allowPathInfo=\"true\" /&gt;    &lt;/handlers&gt;  &lt;/system.webServer&gt;  &lt;system.codedom&gt;    &lt;compilers&gt;      &lt;compiler language=\"c#;cs;csharp\" extension=\".cs\"        type=\"Microsoft.CodeDom.Providers.DotNetCompilerPlatform.CSharpCodeProvider, Microsoft.CodeDom.Providers.DotNetCompilerPlatform, Version=1.0.5.0, Culture=neutral, PublicKeyToken=31bf3513ad364e35\"        warningLevel=\"4\" compilerOptions=\"/langversion:default /nowarn:1659;1699;1701\"/&gt;      &lt;compiler language=\"vb;vbs;visualbasic;vbscript\" extension=\".vb\"        type=\"Microsoft.CodeDom.Providers.DotNetCompilerPlatform.VBCodeProvider, Microsoft.CodeDom.Providers.DotNetCompilerPlatform, Version=1.0.5.0, Culture=neutral, PublicKeyToken=31bf3513ad364e35\"        warningLevel=\"4\" compilerOptions=\"/langversion:default /nowarn:41008 /define:_MYTYPE=\\\"Web\\\" /optionInfer+\"/&gt;    &lt;/compilers&gt;  &lt;/system.codedom&gt;&lt;/configuration&gt;The second step is the configuration of the file Global.asax.cs. I’ve created a new class HelloAppHost which inherits from AppHostBase.public class HelloAppHost : AppHostBase{    public HelloAppHost() : base(\"Hello Web Services\", typeof(HelloService).Assembly) { }    public override void Configure(Container container)    {        SetConfig(new HostConfig        {            DefaultContentType = MimeTypes.Json        });        // Authentication        Plugins.Add(new AuthFeature(() =&gt; new AuthUserSession(),            new IAuthProvider[] {                new CustomCredentialsAuthProvider()            }        ));        Plugins.Add(new RegistrationFeature());        container.Register&lt;ICacheClient&gt;(new MemoryCacheClient());        var userRep = new InMemoryAuthRepository();        container.Register&lt;IUserAuthRepository&gt;(userRep);    }}I’ve added a authentication functionality, which will be covered later in this post. The other thing I set up, is to return JSON-formatted data as default. The last thing to do in this file is creating an instance of the above class:protected void Application_Start(object sender, EventArgs e){    var appHost = new HelloAppHost();    appHost.Init();}Adding RoutesAfter configuring the service, routes can be added. The general structure consists of three elements: RequestDTO, ResponseDTO and a Service. The following example shows how to set up a route following this approach:[Route(\"/hello/{name*}\")]public class Hello : IReturn&lt;HelloResponse&gt;{    public string Name { get; set; }}public class HelloResponse{    public string Result { get; set; }}public class HelloService : IService{    public object Get(Hello request)    {        var name = request.Name ?? \"World\";        return new HelloResponse { Result = $\"Hello, {name}!\" };    }}This service responds to requests on /hello/{name*}. The curly brackets indicate a variable, the star is a wildcard to indicate, that this variable is optional. This way, the service will also respond if no name is submitted (it will use the default ‘World’ for the response).While you can use the notation above to mark routes, you can also set these up in your configuration (Global.asax.cs). Just add the following contents after container.register…Routes    .Add&lt;Hello&gt;(\"/hello\")    .Add&lt;Hello&gt;(\"/hello/{Name}\");HTTP VerbsAs shown in the example above, HelloService only implements the method Get(). This can be supplemented or extended by any other HTTP verb or Any, which will then respond to all requests on this path. ServiceStack also has a nice documentation about the usage of each verb.Fallback RoutesYou can use fallbacks to cover routes, that are not handled explicitly. In my case, I return information about the unhandled path and a timestamp. Again, wildcards are used.[FallbackRoute(\"/{Path*}\")]public class Fallback : IReturn&lt;FallbackResponse&gt;{    public String Path { get; set; }}public class FallbackResponse{    public string Message { get; set; }    public string Path { get; set; }    public String Timestamp { get; set; }}public class FallbackService : IService{    public object Any(Fallback request)    {        return new FallbackResponse {            Message = \"No matching path specified\",            Path = request.Path ?? \"/\",            Timestamp = DateTime.Now.ToString()        };    }}AuthenticationThe last element I’d like to cover is the authentication of a user. ServiceStack offers the class CredentialsAuthProvider, from which custom providers can be derived. The following example covers two methods, TryAuthenticate, which tries to log in by checking username and password against custom logic, and OnAuthenticated, which will be used to assign session variables.public class CustomCredentialsAuthProvider : CredentialsAuthProvider{    public override bool TryAuthenticate(IServiceBase authService,    string userName, string password)    {        // Only checks if username equals password        // implement custom logic here        return userName.Equals(password);    }    public override IHttpResult OnAuthenticated(IServiceBase authService,        IAuthSession session, IAuthTokens tokens,        Dictionary&lt;string, string&gt; authInfo)    {        session.customElement= \"Hello World\";        return base.OnAuthenticated(authService, session, tokens, authInfo);    }}After creating this functionality, you can try to log in using the /auth route via POST and adding a username and password parameter. If you want any of your routes to require authentication, just add the [Authenticate] attribute above its response (above the [Route…]). After doing so, requesting this route without earlier authentication will lead to an empty response.To log out, simply send a request (GET or POST) to /auth/logout.Further InformationAs I mentioned above, ServiceStacks documentation is really well written and maintained. I don’t think you’ll need any information besides what you can find there.",
        "url": "/2017/09/creating-restful-services-servicestack/"
      }
      ,
    
      "2017-09-bitcache-k-im": {
        "title": "Bitcache &amp;#038; K.im",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "After Kim Dotcom announced his new service, I just had to sign up for an invitation. After receiving it an hour later, I tried it out. In this article, I’ll document my experience with k.im.I have to admit that I didn’t exactly know what I was getting into. After clicking the received URL, a very minimalistic website is displayed.So, the service allows you to upload files. I never would have thought of that. But really, this service is different that what you’re used to. After clicking the Upload File Button, you’re prompted to enter a price, which will be required to pay for downloading your file. The default currency is displayed in USD. The value is automatically converted to Bits, which basically are Bitcoin units.After confirming the value, you’ll have to enter some information about the file you just uploaded. This includes a header image, filetype description, title and textual description.The process is almost completed now, but to be able to receive the money, you’re required to have a bitcache wallet. After creating a new one, you receive a welcome bonus of $10.After completing all the required steps, you can select several platforms to upload your file. You’ll receive a link from where the file can be downloaded, like this one: https://k.im/1505667384189.K.im and Bitcache look pretty interesting. Altough everything is still in a demo version, I think the approach is really interesting for people to market their stuff by themselves. For further information and updates, check out Kim Dotcom on Twitter.",
        "url": "/2017/09/bitcache-k-im/"
      }
      ,
    
      "2017-09-sublime-text-3-atom-users": {
        "title": "Sublime Text 3 for Atom Users",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "Due to the release of Sublime Text 3, I thought I’ll give this editor a shot. Currently, I’m using both Notepad++ and Atom. Altough I really like atom and the several useful plugins, it has one huge problem: speed. The initial loading time is one thing, over 100 mb. of RAM in idle mode is another. For quickly editing stuff, this is not acceptable.Sublime Text seems to be a nice alternative, this article documents my switch from Atom to Sublime Text.Download and InstallationAs opposed to Atom, Sublime Text is not free. The per-user-licenses are $80 each, which I think is a very price for a tool, that you work with each day.Also, I think the most users are developers themselves and share the same mindset of willing to pay for good software.Plugins and ThemesYou can use plugins and themes in Sublime as well as you’re used to in Atom. The easiest way to do this is to install package control (Tools – Install package control, https://packagecontrol.io). After that, you can use it via CTRL + SHIFT + P. Enter install, and it will autocomplete to Package Control: Install Package. After that, you can install whatever package you like.One of the things I really liked the most on Atom is the built-in markdown preview. Another option I really enjoyed while using atom is the infinite scrolling mode, which is automatically enabled in Sublime Text. I quickly found alternatives for all of my favourite plugins. The installation of themes is easy as well. You’ll first install whatever package you like, and the activate it by using the CTRL + SHIFT + P shortcut. A theme I really like for Sublime is Brogrammer.SettingsThe last thing I’d like to mention here are the file based user settings. Under Preferences – Settings, you can add your customized settings for an individual look &amp; feel. Any config-element is also listed in the default settings, displayed on the right, from where you can copy and edit the specific items. For example, I set my default font to Fira Mono.",
        "url": "/2017/09/sublime-text-3-atom-users/"
      }
      ,
    
      "2017-09-building-android-app-scratch-using-mvp": {
        "title": "Building an Android App from Scratch using MVP",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In this article, I’ll document the process of building an android app from scratch by using the MVP approach of clean architecture. The app itself will represent a minimalistic umpire indicator for tracking baseball games. Please consider using this in the dugout only. Since this will be a longer post, you can use the following links to jump between sections.  What is MVP?  Background on the app to be built  Constructing the GUI  Managing interfaces  Building the model  Connecting view and model by adding the presenter  1. What is MVP?MVP is a design pattern which helps you to build clean, modular code, that can easily be tested. It consists of the model, the view and the presenter. The view just displays your GUI and can be represented by an activity. The model contains your business logic. The presenter connects these parts. This approach has the advantage, that you can build your model using pure Java, without any Android compontents.Usually, guides on how to implement MVP are based on several frameworks, like dagger2 for dependency injection. I found these guides very hard to get started as a beginner, so I implemented my interpretation of MVP without using any third-party framework.  2. Background on the app to be builtFor anyone who is not familiar with baseball, this section gives a short summary of the concept of an umpires indicator. A baseball game usually consists of nine innings. Each team has a offensive half of an inning and a defensive half. After scoring three outs, the teams switch places. By scoring three outs, a player receives an out. By scoring four balls, a player receives a walk, which allows him to continue to the first base. The mentioned balls and strikes only apply to the batter, the player who is currently located on the home plate and tries to hit a pitch.The umpires indicator is used to track outs, balls and strikes (in this case also innings). The tool is usually a small mechanical gadget. The app will contain a simple GUI which covers this functionality. To keep this post simple, the functionality of the app will be quite minimalistic. Balls, Strikes, Outs and Innings will be represented by a number. The value range of each of these will match the pendant in real baseball games. The values will increase by tapping the text, when the value is higher than the maximum, it will reset to the minimum.The full sourcecode to this project is available on GitHub.  3. Constructing the GUIYou can use several tools for GUI-prototyping. I’ve stumbled across Pencil on GitHub, which looks pretty neat for this job. This wonderful example also shows, that I’m a talentless designer.Like the physical umpire indicators, this one will only be able to increase the counts. Each element will have a maximum value, after which the value will reset to its minimum value. I’ve decided to add TextViews above the different numbers to be able to differentiate between them.This layout has been realised in my MainActivity.xml file:&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;RelativeLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"    xmlns:app=\"http://schemas.android.com/apk/res-auto\"    xmlns:tools=\"http://schemas.android.com/tools\"    android:layout_width=\"match_parent\"    android:layout_height=\"match_parent\"    tools:context=\"com.jurtz.marcel.umpireindicator.MainActivity\"&gt;    &lt;!-- Outs --&gt;     &lt;TextView        android:id=\"@+id/txtOuts\"        style=\"@style/ScoreTextView\"        android:layout_centerHorizontal=\"true\"        android:layout_centerVertical=\"true\"         android:layout_marginBottom=\"@dimen/margin_main\"        android:text=\"O\" /&gt;    &lt;!-- Innings --&gt;    &lt;TextView        android:id=\"@+id/txtInnings\"        style=\"@style/ScoreTextView\"        android:layout_centerHorizontal=\"true\"        android:layout_alignParentBottom=\"true\"        android:layout_marginBottom=\"@dimen/margin_main\"        android:text=\"I\" /&gt;    &lt;!-- Balls --&gt;    &lt;TextView        android:id=\"@+id/txtBalls\"        style=\"@style/ScoreTextView\"        android:layout_alignParentLeft=\"true\"        android:layout_alignParentTop=\"true\"        android:layout_marginTop=\"@dimen/margin_main\"        android:layout_marginLeft=\"@dimen/margin_main\"        android:text=\"B\" /&gt;    &lt;!-- Strikes --&gt;    &lt;TextView        android:id=\"@+id/txtStrikes\"        style=\"@style/ScoreTextView\"        android:layout_alignParentRight=\"true\"        android:layout_alignParentTop=\"true\"        android:layout_marginTop=\"@dimen/margin_main\"        android:layout_marginRight=\"@dimen/margin_main\"        android:text=\"S\"/&gt;    &lt;!-- Descriptions --&gt;    &lt;TextView        android:id=\"@+id/lblBallsDescription\"        style=\"@style/DescriptionTextView\"        android:layout_alignLeft=\"@+id/txtBalls\"        android:layout_alignStart=\"@+id/txtBalls\"        android:layout_alignRight=\"@id/txtBalls\"        android:layout_alignEnd=\"@id/txtBalls\"        android:layout_alignTop=\"@+id/txtBalls\"        android:text=\"Ball\" /&gt;    &lt;TextView        android:id=\"@+id/lblStrikesDescription\"        style=\"@style/DescriptionTextView\"        android:layout_alignLeft=\"@+id/txtStrikes\"        android:layout_alignStart=\"@+id/txtStrikes\"        android:layout_alignRight=\"@id/txtStrikes\"        android:layout_alignEnd=\"@id/txtStrikes\"        android:layout_alignTop=\"@+id/txtStrikes\"        android:text=\"Strike\" /&gt;    &lt;TextView        android:id=\"@+id/lblOutsDescription\"        style=\"@style/DescriptionTextViewCenter\"        android:layout_alignTop=\"@+id/txtOuts\"        android:text=\"Out\" /&gt;    &lt;TextView        android:id=\"@+id/lblInningsDescription\"        style=\"@style/DescriptionTextViewCenter\"        android:layout_alignTop=\"@+id/txtInnings\"        android:text=\"Inning\" /&gt;&lt;/RelativeLayout&gt;I use stylings in here for minimizing duplicate entries:&lt;resources&gt;    &lt;!-- Base application theme. --&gt;    &lt;style name=\"AppTheme\" parent=\"Base.Theme.AppCompat.Light.DarkActionBar\"&gt;        &lt;!-- Customize your theme here. --&gt;        &lt;item name=\"colorPrimary\"&gt;@color/colorPrimary&lt;/item&gt;        &lt;item name=\"colorPrimaryDark\"&gt;@color/colorPrimaryDark&lt;/item&gt;        &lt;item name=\"colorAccent\"&gt;@color/colorAccent&lt;/item&gt;    &lt;/style&gt;    &lt;style name=\"ScoreTextView\"&gt;        &lt;item name=\"android:layout_width\"&gt;wrap_content&lt;/item&gt;        &lt;item name=\"android:layout_height\"&gt;wrap_content&lt;/item&gt;        &lt;item name=\"android:layout_gravity\"&gt;center_horizontal&lt;/item&gt;        &lt;item name=\"android:textSize\"&gt;64dp&lt;/item&gt;        &lt;item name=\"android:padding\"&gt;@dimen/padding_main&lt;/item&gt;    &lt;/style&gt;    &lt;style name=\"DescriptionTextView\"&gt;        &lt;item name=\"android:layout_width\"&gt;match_parent&lt;/item&gt;        &lt;item name=\"android:layout_height\"&gt;wrap_content&lt;/item&gt;        &lt;item name=\"android:gravity\"&gt;center&lt;/item&gt;    &lt;/style&gt;    &lt;style name=\"DescriptionTextViewCenter\"&gt;        &lt;item name=\"android:layout_width\"&gt;match_parent&lt;/item&gt;        &lt;item name=\"android:layout_height\"&gt;wrap_content&lt;/item&gt;        &lt;item name=\"android:layout_centerHorizontal\"&gt;true&lt;/item&gt;        &lt;item name=\"android:gravity\"&gt;center&lt;/item&gt;    &lt;/style&gt;&lt;/resources&gt;Also, I’m using a dimen.xml file to store size-related values:&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;resources&gt;    &lt;dimen name=\"margin_main\"&gt;50dp&lt;/dimen&gt;    &lt;dimen name=\"padding_main\"&gt;25dp&lt;/dimen&gt;&lt;/resources&gt;The next part will be separating the GUI from the logic by creating interfaces.  4. Managing InterfacesI’ll add two interfaces for this project. One for the presenter, and one for the view. The interface that will be implemented by the presenter needs to be able to handle user interactions. Therefore, the following methods will be contained in this interface:public interface IUmpIndicatorPresenter {    void onCreate(IUmpIndicatorView view);    void onPause();    void onResume();    void onDestroy();    void onBallClick();    void onStrikeClick();    void onOutClick();    void onInningClick();}The first four methods are for general activity lifecycle handling. The onCreate()-method receives an instance of the IUmpIndicatorView interface, which will be implemented by the view (represented by the MainActivity). The other four methods are used to handle user interactions with the TextViews.The view implements the interface IUmpIndicatorView, which is shown below:public interface IUmpIndicatorView  {    void setBallText(String text);    void setStrikeText(String text);    void setOutText(String text);    void setInningText(String text);}This interface defines methods of the view, that will be accessed by the presenter. These methods are used to change the values of the TextViews.  5. Building the modelThe model is responsible for managing the game itself. Therefore, it has values for the current balls, strikes, outs and inning. It also defines maximum values for each of these, as well as getter-methods to wrap the private properties.public class Game {    private int balls;    private int strikes;    private int outs;    private int inning;    private final int BALLS_MIN = 0;    private final int BALLS_MAX = 3;    private final int STRIKES_MIN = 0;    private final int STRIKES_MAX = 2;    private final int OUTS_MIN = 0;    private final int OUTS_MAX = 2;    private final int INNINGS_MIN = 1;    private final int INNINGS_MAX = 9;    public Game() {        balls = BALLS_MIN;        strikes = STRIKES_MIN;        outs = OUTS_MIN;        inning = INNINGS_MIN;    }    //region Getter    public int getBalls() {        return balls;    }    public int getStrikes() {        return strikes;    }    public int getOuts() {        return outs;    }    public int getInning() {        return inning;    }    //endregion    //region Increase Values    public void increaseBalls() {        balls++;        if(balls &gt; BALLS_MAX) balls = BALLS_MIN;    }    public void increaseStrikes() {        strikes++;        if(strikes &gt; STRIKES_MAX) strikes = STRIKES_MIN;    }    public void increaseOuts() {        outs++;        if(outs &gt; OUTS_MAX) outs = OUTS_MIN;    }    public void increaseInnings() {        inning++;        if(inning &gt; INNINGS_MAX) inning = INNINGS_MIN;    }    //endregion}  6. Connecting view and model by adding the presenterThe last part is the combination of both elements. An instance of the presenter-interface needs to be built. This class sets the content of each of the views elements and updates the different properties on user interaction:public class UmpIndicatorPresenter implements IUmpIndicatorPresenter {    Game game;    IUmpIndicatorView view;    //region Activity Lifecycle Methods    @Override    public void onCreate(IUmpIndicatorView view) {        game = new Game();        this.view = view;        view.setBallText(String.valueOf(game.getBalls()));        view.setStrikeText(String.valueOf(game.getStrikes()));        view.setOutText(String.valueOf(game.getOuts()));        view.setInningText(String.valueOf(game.getInning()));    }    @Override    public void onPause() {    }    @Override    public void onResume() {    }    @Override    public void onDestroy() {    }    //endregion    //region View Click Handlind    @Override    public void onBallClick() {        game.increaseBalls();        view.setBallText(String.valueOf(game.getBalls()));    }    @Override    public void onStrikeClick() {        game.increaseStrikes();        view.setStrikeText(String.valueOf(game.getStrikes()));    }    @Override    public void onOutClick() {        game.increaseOuts();        view.setOutText(String.valueOf(game.getOuts()));    }    @Override    public void onInningClick() {        game.increaseInnings();        view.setInningText(String.valueOf(game.getInning()));    }    //endregion}The view will be covered by the existing MainActivity.java file and just forward user interactions to the presenter:package com.jurtz.marcel.umpireindicator;import android.support.v7.app.AppCompatActivity;import android.os.Bundle;import android.view.View;import android.widget.TextView;import com.jurtz.marcel.umpireindicator.Interface.IUmpIndicatorPresenter;import com.jurtz.marcel.umpireindicator.Interface.IUmpIndicatorView;import com.jurtz.marcel.umpireindicator.Interface.UmpIndicatorPresenter;public class MainActivity extends AppCompatActivity implements IUmpIndicatorView {    TextView txtBalls;    TextView txtStrikes;    TextView txtOuts;    TextView txtInnings;    IUmpIndicatorPresenter presenter;    @Override    protected void onCreate(Bundle savedInstanceState) {        super.onCreate(savedInstanceState);        setContentView(R.layout.activity_main);        txtBalls = (TextView)findViewById(R.id.txtBalls);        txtStrikes = (TextView)findViewById(R.id.txtStrikes);        txtOuts = (TextView)findViewById(R.id.txtOuts);        txtInnings = (TextView)findViewById(R.id.txtInnings);        presenter = new UmpIndicatorPresenter();        presenter.onCreate(this);        //region TextView onClickListeners        txtBalls.setOnClickListener(new View.OnClickListener() {            @Override            public void onClick(View view) {                presenter.onBallClick();            }        });        txtStrikes.setOnClickListener(new View.OnClickListener() {            @Override            public void onClick(View view) {                presenter.onStrikeClick();            }        });        txtOuts.setOnClickListener(new View.OnClickListener() {            @Override            public void onClick(View view) {                presenter.onOutClick();            }        });        txtInnings.setOnClickListener(new View.OnClickListener() {            @Override            public void onClick(View view) {                presenter.onInningClick();            }        });        //endregion    }    @Override    protected void onDestroy() {        presenter.onDestroy();        super.onDestroy();    }    @Override    protected void onPause() {        presenter.onPause();        super.onPause();    }    @Override    protected void onResume() {        super.onResume();        presenter.onResume();    }    @Override    public void setBallText(String text) {        txtBalls.setText(text);    }    @Override    public void setStrikeText(String text) {        txtStrikes.setText(text);    }    @Override    public void setOutText(String text) {        txtOuts.setText(text);    }    @Override    public void setInningText(String text) {        txtInnings.setText(text);    }}",
        "url": "/2017/09/building-android-app-scratch-using-mvp/"
      }
      ,
    
      "2017-09-set-ssh-git": {
        "title": "How to set up ssh for git",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "When using github, you usually have to enter your login credentials each time you push. You could solve this problem by saving the credentials or by setting up ssh for your account. In this post, the process of adding and using ssh keys will be explained.I’m using git bash, if you use git gui/sourcetree/etc. you should consider switching, at least for this process.At first, SSH keys are generated. The command for this is the following:ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"The flag t is used to describe the type, which is rsa. The next flag, b, describes the amount of bytes which is 4096. The last flag, C, describes the label of the key pair. Just set this email to the one you use to push to github.After pressing enter, you are prompted to add a location to where the files should be saved. Just use the defaults here by pressing enter. After that, you can enter a passphrase. This will encrypt your key. I recommend doing that, if you’d like to read more about why to do that, you can go on here.After a short time, you have two files in an .ssh-folder inside your home directory. The public key is marked by the .pub-ending. Enter the following commands to add the key to your ssh-agent, so you won’t have to enter the passphrase each time the keys are used:eval $(ssh-agent -s)ssh-add /path/to/private-keyThis is all you need to do on your computer. You now need to add the public key to your github account. Log in on https://github.com and go to settings – SSH and GPG keys – New SSH key. Enter a title to be able to recognize the key later. After that, enter the content of your public keys file. You can log this to your terminal and copy and paste it usingclip /path/to/public-keyOn Mac, you can use pbcopy instead of clip. On Linux, just use cat or similar. (I think you basically know your stuff then.) Save the key to complete the process.That’s basically it, your keys are now linked and you can push to github. Note that github uses different urls for https and ssh, looking like this:# HTTPShttps://github.com/username/repo.git# SSHgit@github.com:username/repo.gitYou can check your url using git remote -v and eventually change this by using git remote set-url origin url. (Use your specific url here).",
        "url": "/2017/09/set-ssh-git/"
      }
      ,
    
      "2017-09-getting-started-git": {
        "title": "Getting started with Git",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "This post represents an overview of version control with git. The mentioned commands and parameters are only a small part of what’s possible. Git is a popular system for version control. Projects on git are called Repositories. Repositories can be used local or with a server. There are several free hosters, for example:  Github  GitLab  BitBucketInstallation  Linux (Debian-based)apt-get install git-all  Windows  MacElementsGit-Repositories are separated into working directory, staging area and repository. The working directory is the local copy of the repository.Changes on the files are saved here. The repository is the shared project of all contributing persons. Using the staging area, a developert can decide, which elements he/she wants to save from the working directory to the staging area.Basic administration of a repositoryAll commands are initiated with the keyword git.Initialization of a folder as repository:# New repositorygit init# Download (clone) of an existing repositorygit clone path/to/repositoryEditing / creating files: test.txt# Overview of the current status of the repositorygit status# test.txt is displayed red# Splitting into separate parts:# Untracked Files: New files# Changes not staged for commit: Edited files# Parameters:# -u: Add all edited files, but no new ones.# -A: Add all files (alternative: git add . )# Adding files to the indexgit add test.txt# test.txt ist now displayed green# Adding files to the repositorygit commit -m \"Add test\"Each commit is commented with the -m-flag.This gives the developers a fast overview about the changes made.Git has some naming-conventions, that tells you to write a commit  short (&lt;50 characters)  written in present tense  expressive# Print all commits including details in chronological ordergit logThe output of this command looks like the following:  SHA1-checksum  Name of the author  Email of the authorConfiguring names and emailsThis configuration is global for every repository (set it up once per device).git config --global user.name \"Marcel Jurtz\"git config --global user.email jurtzmarcel@gmail.comYou can set this for each project individually, just leave out the –global-flag.HEADIn the following, HEAD is often mentioned. HEAD is the most recent commit of the current branch.Using RemotesA remote is a repository on a server / different pc, for example hosted on Github.In the following, I use Github as remote server.After creating an account on Github, available repositories are shown and new ones can be created.When creating a new repository, you can select to add a README- and/or license- &amp; .gitignore-file.When creating a new repository (of course this can be done later as well), you are prompted to create a README-, license- and .gitignore-file:  README is a file that represents general information about the project. When hosted on GitHub, this file can be imagined as landing page for visitors. README-files are usually written in markdown. Markdown is similar to HTML, but has lesser functionality and better readability (in my opinion).  license: All repositories on Github (free accounts) are publicly available. With a license-file, the usage of the repository can be adjusted to different preferences. GitHub offers some pre-defined licenses, for example MIT and GPLv3, along with information on the differences.  .gitignore: Gitignore-files list files and directories, that will be ignored by git. You can add files and folders, to, for example, prevent temp- or meta-files from being added to the repository.The following screenshot shows an exemplary repository on Github.The lading page offers some overview of a repository, for example the files and folders in the root-directory, amount of commits, branches, licensing-info and so on.After a repository has been created, it can be added as a remote:git remote add origin urlYou can set individual names for the remote, I use origin here.To upload changes commited in the working directory, use the following:git push origin masterAnd this to download changes from a remote:git pull origin masterPlease know that if you have an existing project on your pc and want to add it to a remote, which already contains files, for example README, license, or .gitignore,youll have to merge the repositories. If you don’t have any of these files locally, you’ll have no problems, since the files will be automatically implemented.If you do, this will result into a merge-conflict. Continue reading, to find out more about merging.MergingFor example, user A and user B are editing the same repository, both users can work with the above mentioned methods.A problem comes up, when both users push the same file: merge conflicts.Think of a file in the remote repository named test.txt, which has the following content:  HelloUsing pull, both users get this file to their working directories.Now, both users edit the file to the following:Version A:  Hello, I am A!Version B:  Hello, I am B!Both users now push their version to the remote. The user submitting first will have no problems doing so. In my example, this will be user B.When user A pushes his updates, the push will result in an error like the following:  CONFLICT (content): Merge conflict in test.txtAutomatic merge failed; fix conflicts and then commit the result.Git now modified the mentioned files, test.txt now has the following content:  &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD:test.txt Hello, I am B! ======= Hello, I am A! &gt;&gt;&gt;&gt;&gt;&gt;&gt; commit-text:test.txtA now has to decide, which version is preferred and then commit the changes.A updates the file to the following:  Hello, we are A and B!After that, he creates a new commit to document the merge:git add test.txtgit commit -m \"Resolve Merge Conflict\"BranchingGit uses branches to support developing new features. This supports developing new functionality, without the need to edited the working current version of the project.Use this to create a new branch:git branch branch_nameAnd this to view all existing branches:git branchThe current branch is marked by an asterisk. Usually, this is master in new projects. As you may notice, we used this branch earlier to push commits. Replace this to push to other branches.Changing branchesgit checkout branch_nameCreating a branch and switching to it:git checkout -b branch_nameWhen a branch is changed, files in the working directory are automatically updated to match that branch. This way, you don’t have to use different folders for different branches and save space on your harddrive.To merge two branches, switch to the branch you want to merge to (using git checkout) and merge them:git merge branch_nameTo view differences in branches, you can usegit diff source_branch destination_branchBranches, that are no longer needed, can be deleted:git branch -d branch_nameTagsTags can be added to commits, to highlight completed versions of a project. To select a commit, the first 10 characters of the checksum are needed (git log).# Creating a new taggit tag 1.0.0 d525ac9ddf# Show all tagsgit tag# Creating a commented taggit tag 1.0.0 d525ac9ddf -m \"Commented Tag\"# Show commit using its taggit show 1.0.0Resetting changesTo reset contents of the working directory, you can use the following:git reset -- filenameThis command obtains changes from HEAD and overwrites the content of the working directory to match HEAD. Changes that have been added to the staging area are not overwritten!To reset contents of the directory, use this:git reset --hard d525ac9As shown earlier, you need to add the first characters of the commits checksum to identify the commit. This command should only be used with caution, since it changes the commit-history.Conventions &amp; Good PracticesTo keep repositories as clear as possible, you should follow some general rules in naming commits and branches.CommitsCommits should be written under considering the following:  Keep it short and simple  Begin with a normalized set of verbs, written in present tense, for example: add, remove, updateBranchesIt is useful to use a short and precise formulation here as well. Often, a verb as prefix is used to describe the purpose of the branch. For example: add/feature_a, remove/feature_b.When contributing to public projects, you should also check the previous commits to adjust to the organization of the other authors.AlternativesIf you don’t like using the terminal, there are some GUI-clients. For example:  SourceTreeLinks  Git Reference  Git Cheat Sheet  Markdown Tutorial",
        "url": "/2017/09/getting-started-git/"
      }
      ,
    
      "2017-09-making-video-games-concepts-part-1": {
        "title": "Making Video Games - Concepts - Part 1",
        "author": "Marcel Jurtz",
        "category": "",
        "content": "In this series, I’ll be creating a videogame from scratch using unity. I hope that I’ll be able to keep everything understandable for beginners, but if something gets too complex, just contact me and I’ll update the specific post.This first part covers the basic concepts of what I’ll be building, and what tools you may need.About the gameI’d like to build an arcade style, shoot ’em up, top down shooter like space invaders. Building the game will include topics like:  coding the game (obviously)  creating models / sprites  making music and sound effectsAll these elements will be covered in future parts. I’m planning on supporting both mobile (android) and browsers. Additional planned features are customizing of your ship / weapons. I’d also like to include two different game modes. One with endless spawning enemies for a highscore-based experience, and one level-based mode with end bosses.ToolsAs I mentioned above, the game will be based on unity. This also means, that I’ll code in C# which requires Visual Studio. For modelling, I plan on using MagicaVoxel, and for the music I’ll be using Linux Multi Media System (LMMS). All of these programs are free, but you can use alternatives as well, of course.Downloads:  https://unity3d.com/  https://www.visualstudio.com/  https://ephtracy.github.io/  https://www.lmms.io/Stay tuned for the next part, which will cover the basics on game programming in unity!",
        "url": "/2017/09/making-video-games-concepts-part-1/"
      }
      
    
  };
</script>
<script src="/js/lunr.min.js"></script>
<script src="/js/search.js"></script>

    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h3 class="footer-heading">Marcel Jurtz</h3>

    <div class="site-navigation">

      <p><strong>Site Map</strong></p>
      <!--
      <ul class="pages">
        
        
          <li class="nav-link"><a href="/about/">About</a>
        
        
        
        
        
        
        
        
        
          <li class="nav-link"><a href="/posts/">Posts</a>
        
        
        
        
        
          <li class="nav-link"><a href="/typography/">Typography</a>
        
        
        
          <li class="nav-link"><a href="/tag/gamedev/">gamedev</a>
        
        
        
          <li class="nav-link"><a href="/tag/unity/">unity</a>
        
        
        
          <li class="nav-link"><a href="/tag/git/">git</a>
        
        
        
          <li class="nav-link"><a href="/tag/programming/">programming</a>
        
        
        
          <li class="nav-link"><a href="/tag/tools/">tools</a>
        
        
        
          <li class="nav-link"><a href="/tag/android/">android</a>
        
        
        
          <li class="nav-link"><a href="/tag/app/">app</a>
        
        
        
          <li class="nav-link"><a href="/tag/baseball/">baseball</a>
        
        
        
          <li class="nav-link"><a href="/tag/development/">development</a>
        
        
        
          <li class="nav-link"><a href="/tag/editor/">editor</a>
        
        
        
          <li class="nav-link"><a href="/tag/bitcache/">bitcache</a>
        
        
        
          <li class="nav-link"><a href="/tag/bitcoin/">bitcoin</a>
        
        
        
          <li class="nav-link"><a href="/tag/cryptocurrency/">cryptocurrency</a>
        
        
        
          <li class="nav-link"><a href="/tag/dotnet/">dotnet</a>
        
        
        
          <li class="nav-link"><a href="/tag/asp-dotnet/">asp-dotnet</a>
        
        
        
          <li class="nav-link"><a href="/tag/csharp/">csharp</a>
        
        
        
          <li class="nav-link"><a href="/tag/rest/">rest</a>
        
        
        
          <li class="nav-link"><a href="/tag/servicestack/">servicestack</a>
        
        
        
          <li class="nav-link"><a href="/tag/software/">software</a>
        
        
        
          <li class="nav-link"><a href="/tag/windows/">windows</a>
        
        
        
          <li class="nav-link"><a href="/tag/efficiency/">efficiency</a>
        
        
        
          <li class="nav-link"><a href="/tag/productivity/">productivity</a>
        
        
        
          <li class="nav-link"><a href="/tag/network/">network</a>
        
        
        
          <li class="nav-link"><a href="/tag/p2p/">p2p</a>
        
        
        
          <li class="nav-link"><a href="/tag/syncthing/">syncthing</a>
        
        
        
          <li class="nav-link"><a href="/tag/xamarin/">xamarin</a>
        
        
        
          <li class="nav-link"><a href="/tag/clean-code/">clean-code</a>
        
        
        
          <li class="nav-link"><a href="/tag/design/">design</a>
        
        
        
          <li class="nav-link"><a href="/tag/layout/">layout</a>
        
        
        
          <li class="nav-link"><a href="/tag/sideproject/">sideproject</a>
        
        
        
          <li class="nav-link"><a href="/tag/dotnet-core/">dotnet-core</a>
        
        
        
          <li class="nav-link"><a href="/tag/linux/">linux</a>
        
        
        
          <li class="nav-link"><a href="/tag/3d-printing/">3d-printing</a>
        
        
        
          <li class="nav-link"><a href="/tag/raspberry-pi/">raspberry-pi</a>
        
        
        
          <li class="nav-link"><a href="/tag/email/">email</a>
        
        
        
          <li class="nav-link"><a href="/tag/encryption/">encryption</a>
        
        
        
          <li class="nav-link"><a href="/tag/self/">self</a>
        
        
        
          <li class="nav-link"><a href="/tag/blog/">blog</a>
        
        
        
          <li class="nav-link"><a href="/tag/web/">web</a>
        
        
        
          <li class="nav-link"><a href="/tag/ruby/">ruby</a>
        
        
        
          <li class="nav-link"><a href="/tag/javascript/">javascript</a>
        
        
        
          <li class="nav-link"><a href="/tag/jekyll/">jekyll</a>
        
        
        
          <li class="nav-link"><a href="/tag/motivation/">motivation</a>
        
        
        
          <li class="nav-link"><a href="/tag/discipline/">discipline</a>
        
        
        
          <li class="nav-link"><a href="/tag/fitness/">fitness</a>
        
        
        
          <li class="nav-link"><a href="/tag/asp-net/">asp.net</a>
        
        
        
          <li class="nav-link"><a href="/tag/css/">css</a>
        
        
        
          <li class="nav-link"><a href="/tag/html/">html</a>
        
        
        
          <li class="nav-link"><a href="/tag/tfs/">tfs</a>
        
        
        
          <li class="nav-link"><a href="/tag/svn/">svn</a>
        
        
        
          <li class="nav-link"><a href="/tag/docker/">docker</a>
        
        
        
          <li class="nav-link"><a href="/tag/containers/">containers</a>
        
        
        
          <li class="nav-link"><a href="/tag/book/">book</a>
        
        
        
          <li class="nav-link"><a href="/tag/review/">review</a>
        
        
        
          <li class="nav-link"><a href="/tag/ferriss/">ferriss</a>
        
        
        
          <li class="nav-link"><a href="/tag/life/">life</a>
        
        
        
          <li class="nav-link"><a href="/tag/business/">business</a>
        
        
        
          <li class="nav-link"><a href="/tag/methodology/">methodology</a>
        
        
        
          <li class="nav-link"><a href="/tag/scrum/">scrum</a>
        
        
        
          <li class="nav-link"><a href="/tag/management/">management</a>
        
        
        
          <li class="nav-link"><a href="/tag/agile/">agile</a>
        
        
        
          <li class="nav-link"><a href="/tag/project/">project</a>
        
        
        
          <li class="nav-link"><a href="/tag/kanban/">kanban</a>
        
        
        
          <li class="nav-link"><a href="/tag/pattern/">pattern</a>
        
        
        
          <li class="nav-link"><a href="/tag/ioc/">IoC</a>
        
        
        
          <li class="nav-link"><a href="/tag/di/">DI</a>
        
        
        
          <li class="nav-link"><a href="/tag/csharp/">CSharp</a>
        
        
        
          <li class="nav-link"><a href="/tag/learn/">learn</a>
        
        
        
          <li class="nav-link"><a href="/tag/prototyping/">prototyping</a>
        
        
        
          <li class="nav-link"><a href="/tag/typescript/">typescript</a>
        
        
        
          <li class="nav-link"><a href="/tag/cross-platform/">cross-platform</a>
        
        
        
          <li class="nav-link"><a href="/tag/self-disciplin/">self-disciplin</a>
        
        
        
          <li class="nav-link"><a href="/tag/sports/">sports</a>
        
        
        
          <li class="nav-link"><a href="/tag/running/">running</a>
        
        
        
          <li class="nav-link"><a href="/tag/challenge/">challenge</a>
        
        
        
          <li class="nav-link"><a href="/category/game-development/">game-development</a>
        
        
        
          <li class="nav-link"><a href="/category/tools/">tools</a>
        
        
        
          <li class="nav-link"><a href="/category/android/">android</a>
        
        
        
          <li class="nav-link"><a href="/category/cryptocurrency/">cryptocurrency</a>
        
        
        
          <li class="nav-link"><a href="/category/csharp/">CSharp</a>
        
        
        
          <li class="nav-link"><a href="/category/csharp/">csharp</a>
        
        
        
          <li class="nav-link"><a href="/category/productivity/">productivity</a>
        
        
        
          <li class="nav-link"><a href="/category/tips/">tips</a>
        
        
        
          <li class="nav-link"><a href="/category/xamarin/">xamarin</a>
        
        
        
          <li class="nav-link"><a href="/category/hobby/">hobby</a>
        
        
        
          <li class="nav-link"><a href="/category/security/">security</a>
        
        
        
          <li class="nav-link"><a href="/category/linux/">linux</a>
        
        
        
          <li class="nav-link"><a href="/category/blog/">blog</a>
        
        
        
          <li class="nav-link"><a href="/category/windows/">windows</a>
        
        
        
          <li class="nav-link"><a href="/category/life/">life</a>
        
        
        
          <li class="nav-link"><a href="/category/web/">web</a>
        
        
        
          <li class="nav-link"><a href="/category/programming/">programming</a>
        
        
        
          <li class="nav-link"><a href="/category/development/">development</a>
        
        
        
          <li class="nav-link"><a href="/category/books/">books</a>
        
        
        
          <li class="nav-link"><a href="/category/learn/">learn</a>
        
        
        
          <li class="nav-link"><a href="/category/running/">running</a>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
      </ul>
    -->
    <ul class="pages">
        <li class="nav-link"><a href="/">Home</a></li>
        <li class="nav-link"><a href="/about/">About</a></li>
        <li class="nav-link"><a href="/posts/">Posts</a></li>
        <li class="nav-link"><a href="https://mjurtz.com/Impressum.html">Impressum</a></li>
      </ul>
    </div>

    <div class="site-contact">

      <p><strong>Contact</strong></p>
      <ul class="social-media-list">
        <li>
          <a href="mailto:marcel@mjurtz.com">
            <i class="fa fa-envelope-o"></i>
            <span class="username">marcel@mjurtz.com</span>
          </a>
        </li>

        
          
          <li>
            <a href="https://twitter.com/MarcelJurtz" title="Follow me on Twitter">
              <i class="fa fa-twitter"></i>
              <span class="username">MarcelJurtz</span>
            </a>
          </li>
          
        
          
          <li>
            <a href="https://github.com/MarcelJurtz" title="Fork me on GitHub">
              <i class="fa fa-github"></i>
              <span class="username">MarcelJurtz</span>
            </a>
          </li>
          
        
          
        

      </ul>
    </div>

    <div class="site-signature">
      <form action="/search.html" method="get">
        <label for="search_box">Search Posts</label>
        <input type="text" id="search_box" name="query">
        <input type="submit" value="search">
      </form>
    </div>

  </div>

</footer>

<!-- Scripts -->
<script src="//code.jquery.com/jquery-1.11.2.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/js/lightbox.min.js"></script>

<script type="text/javascript">
$(document).ready(function() {
  // Default syntax highlighting
  hljs.initHighlightingOnLoad();

  // Header
  var menuToggle = $('#js-mobile-menu').unbind();
  $('#js-navigation-menu').removeClass("show");
  menuToggle.on('click', function(e) {
    e.preventDefault();
    $('#js-navigation-menu').slideToggle(function(){
      if($('#js-navigation-menu').is(':hidden')) {
        $('#js-navigation-menu').removeAttr('style');
      }
    });
  });
});

</script>




<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-118762636-1', 'auto');
  ga('set','anonymizeIp',true);
  ga('send', 'pageview', {
    'page': '/search.html',
    'title': 'Marcel Jurtz'
  });
</script>



  </body>

</html>
